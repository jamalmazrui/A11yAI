

OECD Working Papers should not be reported as representing the official views of the OECD or of its member countries. The opinions expressed and arguments employed are those of the authors. 
Working Papers describe preliminary results or research in progress by the author(s) and are published to stimulate discussion on a broad range of issues on which the OECD works. Comments on Working Papers are welcomed and may be sent to Directorate for Employment, Labour and Social Affairs, OECD, 2 rue André-Pascal, 75775 Paris Cedex 16, France. 
This document, as well as any data and any map included herein, are without prejudice to the status of or sovereignty over any territory, to the delimitation of international frontiers and boundaries and to the name of any territory, city or area. 
Cover image: (c) Kjpargeter/Shutterstock.com 
(c) OECD 2023 

The use of this work, whether digital or print, is governed by the Terms and Conditions to be found at http://www.oecd.org/termsandconditions. 

Using AI to support people with disability in the labour market: Opportunities and challenges 
Chloé Touzet 

People with disability face persisting difficulties in the labour market. There are concerns that AI, if managed poorly, could further exacerbate these challenges. Yet, AI also has the potential to create more inclusive and accommodating environments and might help remove some of the barriers faced by people with disability in the labour market. Building on interviews with more than 70 stakeholders, this report explores the potential of AI to foster employment for people with disability, accounting for both the transformative possibilities of AI-powered solutions and the risks attached to the increased use of AI for people with disability. It also identifies obstacles hindering the use of AI and discusses what governments could do to avoid the risks and seize the opportunities of using AI to support people with disability in the labour market. 

Keywords : Employment, Disability, Artificial Intelligence 
JEL codes : J14, J18, J20 
Résumé 

Les personnes handicapées sont confrontées à des difficultés persistantes sur le marché du travail. Sans les garde-fous appropriés, l'IA pourrait exacerber ces difficultés davantage. Pourtant, l'IA a aussi le potentiel de créer des environnements plus inclusifs et plus accommodants et pourrait contribuer à éliminer certains des obstacles rencontrés par les personnes handicapées sur le marché du travail. Ce rapport s'appuie sur des entretiens avec plus de 70 parties prenantes pour explorer le potentiel de l'IA en matière d'emploi des personnes handicapées, en tenant compte à la fois des possibilités de transformation offertes par les solutions utilisant l'IA et des risques liés à son utilisation accrue. Il identifie les obstacles qui entravent l'utilisation de l'IA, et discute des pistes d'action pour les gouvernements afin d'éviter les risques et de saisir les opportunités de l'IA pour soutenir les personnes handicapées sur le marché du travail. 

Acknowledgements 
This report benefited from financial support from the United Kingdom Economic and Social Research Council.  
The report was carried out under the supervision of Stijn Broecke (Team Lead for the Future of Work) and Mark Keese (Head of the Skills and Employability Division of the Directorate for Employment, Labour and Social Affairs). It has benefited from contributions from Kyungmin Noh and Takahiro Toda who identified relevant case studies and conducted written interviews in Korea and Japan respectively. Arron Rabbitte provided helpful research assistance in the early phase of the project. The report also benefitted from helpful comments from colleagues from the Directorate for Employment, Labour and Social Affairs including Stijn Broecke, Anna Milanez, Christopher Prinz and Annelore Verhagen, as well as colleagues from the Directorate for Science, Technology and Innovation and from the Directorate for Education and Skills. Particular thanks to Anna Milanez, who provided much-appreciated help verifying quotes, improving and polishing the report in its last phase. Thank you to Assa Fofana for support during the research process.  
This report would not have been possible without the input from the many people listed in Annex C who lent their time and expertise in speaking to the OECD for this project. Not all participants wanted to be publicly acknowledged; gratitude is also extended to participants who wish their participation to remain anonymous. Particular thanks are due to Yonah Welker for help vetting the repository of solutions.  
Thanks also to the participants and speakers of the session titled "Can AI improve access to the labour market for people with disability?" at the International Conference on AI in Work, Innovation, Productivity and Skills held on 27-30 March 2023, and to the participants and discussants of the session "Using AI to help people with disability in the labour market: opportunities and challenges" at the 17th International Conference of the Association for the Advancement of Assistive Technology in Europe (AAATE) held on 30 August - 1 September 2023.  
Table of contents 
Résumé 	4 
Acknowledgements 	5 
Executive summary 	8 
Principaux résultats 	10 
Introduction 	12 
1 Evaluating the potential: Could AI foster employment of people with disability? 	15 
1.1. State of the technology: What is out there? 	15 
1.2. Evaluating opportunities: How transformative could AI be in fostering the employment of 
	people with disability? 	24 
1.3. What could go wrong? Understanding the risks of AI for people with disability 	28 
2 From development to user adoption: Challenges to AI supporting people with 
	disability in the labour market 	31 
2.1. What is hindering the research and development of AI-powered solutions? 	31 
2.2. Understanding barriers in the commercialisation phase 	35 
2.3. What is hindering adoption by end users? 	37 
2.4. Making the most of AI to reduce the disability employment gap: the role of mainstream 
	solutions 	39 
3 Seizing the potential, addressing the risks: what role for governments? 	42 
3.1. Are policies at the intersection of AI and disability rights/accessibility fit for purpose? 	42 
3.2. Going forward: what can governments do? 	50 
References 	61 
Annex A. Repository of AI-powered solutions 	70 
Annex B. Interview guide used with accessibility experts 	89 
Annex C. List of participants 	91 
Glossary 	93 
Notes 	95 
 
Tables 
Table A A.1. Repository of identified AI-powered solutions 	70 
 
Figures 
Figure 1. The report considers both mainstream AI-powered solutions and specialised ones 	14 
Figure 1.1. Where on the path to employment do most AI-powered solutions intervene? 	20 
Figure 1.2. Academia and small firms are responsible for the largest shares of AI-powered accessibility-
enhancing solutions 	22 
 
Boxes 
Box 1.1. Examples of disability-centred solutions 	16 
Box 1.2. AI-powered solutions to make environments accessible 	17 
Box 1.3. Will automated vehicles foster employment of people with disability? 	27 
 
 
Executive summary 
People with disability face persisting difficulties in the labour market. In 2019, across OECD countries, they were 2.3 times more likely to be unemployed than people without disability, and their employment rate was 27 percentage points lower. The disability employment gap has remained stubbornly stable during the last decade. These large gaps are a challenge for equity as well as for the efficiency of the labour market, as skills and talent of many people remain undervalued and underused.  
There are concerns that artificial intelligence (AI), if managed poorly, could further exacerbate these disparities. The increasing use of AI-powered tools in the workplace bears several risks. Their lack of reliability might lead to errors for people who are underrepresented in training datasets, such as people with disability. AI could also be discriminatory if it magnifies embedded ableist biases. Risks to privacy are heightened for people with disability, who may be more easily identifiable because of their uniqueness, and AI tools might exclude people with disability by design if user interfaces are inaccessible to them.  
However, AI could also support people with disability in the labour market. The UN Convention on the Rights of Persons with Disabilities states that "technologies, assistance, and services available" have the capacity to affect "the perception and reality of disability", since the latter results "from the interaction between persons with impairments and attitudinal and environmental barriers that hinders full and effective participation in society on an equal basis with others". As this report shows, AI has the potential to create more inclusive and accommodating environments and might help remove some of these barriers.  
The effect of AI on labour market accessibility could be transformative. Building on desk research and interviews with over 70 stakeholders, this report identifies 142 examples of AI-powered solutions that could support people with disability in the labour market. Over 75% of these would not exist without AI. Contrary to pre-existing assistive technology devices which tended to be single-purposed, AI could accelerate change by catering to different scenarios and types of disabilities at the same time. AI-powered solutions can be more personalised, they can learn from crowdsourced feedback, and are thus well-suited for collaborative development taking into account the perspective of users. They are also easier to integrate into mainstream technology, which could help to scale accessibility faster. Many of the solutions identified in this report are productivity-enhancing in general, meaning that they might be less stigmatised than previous pieces of assistive technology. Finally, AI can reduce the cost of solutions fostering employment for people with disability. 
AI-powered solutions that support people with disability in the labour market fall into four categories. Over half of the tools identified in the report are disability-centred solutions, that either provide workarounds to people with disability (such as live captioning for individuals who are deaf, or speech recognition algorithms for people with dysarthric speech) or that address disabilities directly (such as gaitcorrection prosthetics, or mental health conversational agents). A quarter of the tools are environmentadaptation solutions, making content and workplaces more accessible to persons with disabilities. Examples range from algorithms that make texts accessible to neurodiverse individuals, to labour market matching tools designed to avoid exclusion and discrimination based on disability. Other tools improve accessibility at a meta-level, enhancing processes that themselves foster accessibility - for example, increasing the efficiency of the workplace accommodation process. A final set of AI tools identified in this report unlock work opportunities that were previously inaccessible to people with disability.  
While AI could help close the disability employment gap, it is unlikely to be sufficient on its own. Some stakeholders interviewed worried that AI is not always mature enough and/or might be overpromising. Some argued that AI-powered solutions can only have a limited effect as they will not be able to change social attitudes and combat the stereotypes fueling the disability employment gap.  
Making the most of AI comes with challenges.  
• Research & development (R&D) in AI for accessibility is hindered by a lack of private funding beyond initial seed funding and compounded by a scarcity of public funding for research into niche and often unprofitable issues. Public research in fundamental AI, necessary to develop solutions supporting people with disability, is also underfunded. The cost to access relevant data and computing power are barriers to R&D for small firms and university research labs. The difficulty of attracting AI talent in the field and the lack of accessibility training among developers are other limits to R&D.  
• In the commercialisation phase, scarcity of funding means that few accessibility-enhancing innovations make it beyond the prototype phase. Securing long-term sustainable funding is another difficulty: selling tools directly to end users results in inequalities in access and limits scaling to those who can afford to pay only; procedures to integrate existing public reimbursement pathways can be too long and onerous for small firms; selling to employers is limited by a lack of awareness of accessibility issues. In all cases, discoverability is an obstacle, as potential buyers do not know of emerging solutions.  
• The most cited barrier to adoption is a lack of user engagement in developing solutions, which results in solutions being irrelevant (failing to answer to actual needs) and impractical (when solutions are disconnected from existing policies, actors, and support systems). Adoption by people with disability is also hindered by low levels of IT literacy among end users, and/or a lack of interoperability between new AI-powered solutions and existing hardware and assistive technology devices.  
• Encouraging the development of accessible mainstream AI solutions that also enhance labour market accessibility could help guarantee interoperability and secure long-term funding, but these remain marginal, and reimbursement policies are often restricted to specialised solutions, excluding mainstream ones. 
Going forward, governments could do more to address the risks of AI for people with disability. Stakeholders call on governments to implement policies explicitly outlawing uses of AI that result in discrimination against people with disability. Some suggest revising liability laws and procurement guidance to give developers and buyers incentives to ensure that AI products are safe for marginalised groups before they are deployed, and that mainstream AI products are accessible and interoperable by default. This could also be done through accessibility standards, regularly updated to remain relevant as technology evolves. Stakeholders would also welcome better systems of quality control and enforcement.    
Government policies could also help seize the opportunities of AI. To foster R&D, stakeholders call for government-backed venture capital streams and for additional earmarked public funding. To overcome obstacles in the commercialisation phase, they suggest implementing simplified reimbursement mechanisms, using accessibility-related regulatory obligations to sustain private markets, and introducing accessibility clauses in public procurements. To favour discoverability and facilitate user choice, stakeholders call for certification mechanisms and quality standards for AI-powered solutions. To improve the participation of people with disability in the innovation process, they suggest the creation of metrics on disability representation. Working with universities to include accessibility and inclusive design training into computer science curricula would help improve the relevance of specialised solutions, and the accessibility of mainstream AI. It might also help firms develop specialised solutions to recruit AI talents.  

Principaux résultats 
Les personnes handicapées sont confrontées à des difficultés persistantes sur le marché du travail. En 2019, dans les pays de l'OCDE, elles étaient 2.3 fois plus susceptibles d'être au chômage que les personnes non handicapées, et leur taux d'emploi était inférieur de 27 points de pourcentage. Cet écart d'emploi est resté obstinément stable au cours de la dernière décennie. Il représente un enjeu en matière d'équité, ainsi qu'une sous-valorisation et une sous-utilisation inefficaces des compétences et talents.  
L'intelligence artificielle (IA), si elle est mal gérée, pourrait exacerber encore ces disparités. L'utilisation croissante d'outils utilisant l'IA sur le marché du travail comporte plusieurs risques. Le manque de fiabilité de ces outils pourrait entraîner des erreurs pour les personnes sous-représentées dans les données d'apprentissage, telles que les personnes handicapées, et l'IA pourrait être discriminatoire si elle amplifie les préjugés validistes présents dans ces données. Les risques pour la vie privée sont accrus pour les personnes handicapées, qui peuvent être plus facilement identifiables et les outils d'IA peuvent exclure les personnes handicapées par leur conception si les interfaces utilisateur leur sont inaccessibles.  
Toutefois, l'IA pourrait également aider les personnes handicapées sur le marché du travail. La Convention des Nations unies relative aux droits des personnes handicapées stipule que "les technologies, l'assistance et les services disponibles" ont la capacité d'affecter "la perception et la réalité du handicap", puisque le handicap résulte "de l'interaction entre des personnes présentant des incapacités et les barrières comportementales et environnementales qui font obstacle à leur pleine et effective participation à la société sur la base de l'égalité avec les autres". L'IA pourrait créer des environnements plus inclusifs et plus accommodants et pourrait contribuer à éliminer certaines de ces barrières.  
L'IA pourrait avoir un effet transformateur sur l'accessibilité du marché du travail. À partir d'entretiens avec plus de 70 parties prenantes, ce rapport identifie 142 exemples de solutions utilisant l'IA qui pourraient aider les personnes handicapées sur le marché du travail, dont plus de 75% n'existeraient pas sans l'IA. Contrairement aux outils d'assistance préexistants, souvent à fonction unique, l'IA pourrait accélérer le changement en répondant à différents scénarios et types de handicaps à la fois. L'IA peut être facilement personnalisée et est propice à un développement inclusif des perspectives usagers. Elle est également plus facile à intégrer dans les technologies généralistes. Bon nombre de solutions améliorent la productivité en général et pourraient de ce fait être moins stigmatisées que les technologies d'assistance antérieures. Enfin, l'IA peut réduire le coût des solutions favorisant l'emploi des personnes handicapées. 
Quatre types de solutions peuvent aider les personnes handicapées sur le marché du travail. Plus de la moitié des outils recensés dans le rapport visent à fournir des solutions aux personnes handicapées (par exemple via le sous-titrage en direct pour les personnes sourdes, les algorithmes de reconnaissance vocale pour les personnes souffrant de dysarthrie, ou encore les agents conversationnels pour la santé mentale). Un quart des outils sont des solutions d'adaptation de l'environnement, qui rendent le contenu et les lieux de travail plus accessibles aux personnes handicapées - par exemple, les outils d'appariement entre travailleurs et emplois conçus pour éviter la discrimination fondée sur le handicap. D'autres outils améliorent l'accessibilité en renforçant les processus qui favorisent eux-mêmes l'accessibilité - par exemple, en augmentant l'efficacité du processus d'aménagement du lieu de travail. Une dernière série d'outils d'IA identifiés dans ce rapport débloque des opportunités de travail qui étaient auparavant inaccessibles aux personnes handicapées. 
L'IA peut contribuer à combler le déficit d'emploi des personnes handicapées - mais probablement pas résorber totalement l'écart d'emploi. Certains experts mettent en question la maturité de l'IA ; d'autres estiment que les solutions utilisant l'IA n'auront qu'un effet limité, car elles ne pourront pas lutter contre les stéréotypes qui alimentent le sous-emploi des personnes handicapées.  
Tirer le meilleur parti de l'IA implique de surmonter une série de difficultés.  
• La recherche et le développement (R&D) sont entravés par un manque de financement privé, aggravé par un déficit de financement public pour la recherche sur les questions de niche, souvent non rentables. La recherche fondamentale publique dans le domaine de l'IA, nécessaire pour développer des solutions spécialisées, est également sous-financée. Le coût de l'accès aux données et à la puissance de calcul constitue un obstacle à la R&D pour les petites entreprises et les laboratoires de recherche universitaires. Le manque de formation à l'accessibilité chez les développeurs sont d'autres limites à la R&D en matière d'IA facilitant l'accès à l'emploi des personnes handicapées.  
• Dans la phase de commercialisation, peu d'innovations dépassent la phase du prototype, par manque de moyens. La mise en place d'un mode de financement durable est une autre difficulté : la vente d'outils directement aux utilisateurs finaux entraîne des inégalités d'accès et limite la diffusion à ceux qui ont les moyens de payer ; les procédures d'intégration des voies de remboursement publiques existantes peuvent être trop longues et onéreuses pour les petites entreprises ; la vente aux employeurs est limitée par un manque de sensibilisation aux questions d'accessibilité. Les solutions émergentes manquent de visibilité auprès des acheteurs potentiels. 
• L'obstacle à l'adoption des solutions par les personnes handicapées le plus souvent cité est le manque d'engagement des utilisateurs dans l'élaboration des solutions, qui finissent souvent par manquer de pertinence (en ne répondant pas aux besoins réels) et de praticité (lorsque les solutions sont déconnectées des politiques et des systèmes de soutien existants). L'adoption par les utilisateurs est également entravée par le manque de familiarité des utilisateurs finaux à l'outil et d'interopérabilité entre les nouvelles solutions et les outils existants.  
• Encourager le développement de solutions d'IA grand public accessibles qui améliorent également l'accessibilité du marché du travail pourrait contribuer à garantir l'interopérabilité et à assurer un financement à long terme, mais ces solutions restent marginales, tandis que les politiques de remboursement excluent souvent les solutions grand public. 
À l'avenir, les gouvernements pourraient faire davantage pour éviter les risques. Les experts interrogés appellent à interdire explicitement les utilisations de l'IA qui génèrent des discriminations à l'égard des personnes handicapées. Certains suggèrent de réviser les lois sur la responsabilité et les recommandations en matière de marchés publics afin d'inciter les développeurs et les acheteurs à garantir la sécurité des produits pour les groupes marginalisés avant leur déploiement, ainsi que l'accessibilité et l'interopérabilité par défaut des produits d'IA généralistes. D'autres appellent à la mise en place de normes d'accessibilité, régulièrement mises à jour à mesure que la technologie évolue, assortis de meilleurs systèmes de contrôle de la qualité et de respect des règlementations.    
Des politiques dédiées permettraient de mieux utiliser l'IA pour favoriser l'emploi durable des personnes handicapées La création de flux de capital-risque soutenus par les pouvoirs publics et davantage de financement public dédié favoriseraient la R&D. Les mécanismes de remboursement simplifiés, l'introduction de clauses d'accessibilité dans les marchés publics et la création d'obligations réglementaires liées à l'accessibilité pour soutenir les marchés privés faciliteraient la commercialisation. La certification des solutions utilisant l'IA améliorerait leur visibilité. L'introduction de modules sur l'accessibilité et la conception inclusive dans les parcours d'études en informatique permettrait d'améliorer la pertinence des solutions spécialisées et l'accessibilité de l'IA généraliste, et pourrait également aider les entreprises développant des solutions spécialisées à recruter des talents en IA.  
Introduction 
The road to work remains fraught with difficulties for people with disability.1 In 20192, across a set of 32 OECD countries, the employment rate of people with disability was 27 percentage points lower than for people without disability, a statistic that has remained stubbornly stable for the last decade. That same year, people with disability were still 2.3 times more likely to be unemployed than people without disability - up from about two times after the global financial crisis in 2008-09 (OECD, 2022[4]). The stability of the disability employment gap(*)a sheds light on the inequalities and barriers that people with disability still face in the labour market today, as well as on the waste of talent related to these persisting difficulties.  
The increased use of artificial intelligence (AI) is transforming labour markets for all (Milanez, 2023[5]; Lane, Williams and Broecke, 2023[6]). People with disability are also affected. The emerging world of work might be a "boon or a bane for people with disability" (OECD, 2022[4]). On the one hand, as stated in the UN Convention on the Rights of Persons with Disabilities, "technologies, assistance, and services available" have the capacity to affect "the perception and reality of disability" (United Nations, 2008[3]). Disability is "an evolving concept", resulting "from the interaction between persons with impairments and attitudinal and environmental barriers that hinders full and effective participation in society on an equal basis with others" (United Nations, 2008[3]). A biological difference (an impairment or functional limitation) only becomes disabling if the environment does not allow the person to function according to their capacities" (OECD, 2022[4]). Technology might be able to transform that interaction between individuals and their environment and thus might help push the frontier after which disability starts further. Technological advances and AI notably have "the potential to create a more inclusive and accommodating environment" (OECD, 2022[4]). On the other hand, technology itself cannot be a "quick fix for labour market inclusion of people with disability"; in fact, it "may even exacerbate existing disparities" if managed poorly, according to a recent OECD report calling on "OECD countries to harness the promise of a better future of work for all, including people with disability" (OECD, 2022[4]).  
The present report explores these issues, discussing both the opportunities and challenges of using AI to support people with disability in the labour market.3 To do so, it addresses the following three overarching research questions:  
• What is the potential of AI to foster employment of people with disability? What is the state of the technology? How can AI-powered solutions support people with disability in the labour market? How transformative could these solutions be? And what could go wrong? What risks might the increased use of AI pose for people with disability?  
• What is preventing this potential from being fully used? What obstacles might be hindering research and development, commercialisation, and adoption of AI-powered solutions fostering employment of people with disability?4  
• How can governments help to avoid the risks and seize the opportunities of AI to support people with disability in the labour market? To what extent are existing policies adequate to 
 
a
 Terms marked with an (*) the first time they are used are defined in the glossary. 
make the most of AI? Going forward, what kind of policies could help steer the development of AI towards solutions fostering employment of people with disability?   
In answering these questions, the report builds on the definition of an AI system established by the OECD's AI Experts Group (OECD, 2022[7]):  
"An AI system is a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments. It uses machine and/or human-based inputs to perceive real and/or virtual environments; abstract such perceptions into models (in an automated manner e.g. with machine learning or manually); and use model inference to formulate options for information or action. AI systems are designed to operate with varying levels of autonomy."  
Yet, recognising that there is no universally accepted definition of AI5 (Lane and Saint-Martin, 2021[8]), the report follows Milanez (2023[5]) in "casting a wide net" to identify solutions falling within its scope. Solutions that are either based on technology that fits the definition above or which are explicitly described as using AI are included. While there are examples of AI-powered solutions targeting children with disability6 and the elderly, the report focuses on those designed to serve working-age adults only. The report focuses on examples from OECD member countries as well as accession countries7.  
AI-powered solutions considered in this project can be used by people with a variety of temporary or longterm impairments, including "mental, physical, intellectual or sensory" ones (United Nations, 2008[3]). Solutions included support people with disability in the labour market either:  
• directly (in the case of labour market-specific solutions), or indirectly (in the case of generalist solutions with labour market applications);  
• at various points on the path to employment, from skills acquisition to career development;   
• intentionally (when solutions are developed in order to support people with disability) or as a byproduct of a mainstream AI-powered solution. In addition, mainstream AI is included in the scope to the extent that it might create risks for people with disability in the labour market (Figure 1). 
To answer the research questions listed above, the report builds on data collected through 71 semistructured interviews (see Annex C for the full list of interviewees who agreed to be named in the report) with a variety of stakeholders, namely:  
• 34 interviewees from the "innovator" side, employed in organisations developing AI-powered solutions that can foster employment for people with disability, across OECD countries. These include business strategists, technology leads, as well as hands-on developers.  
• 31 interviewees from the "user" side, including: 10 academic experts, 8 disability rights advocates, 4 professional accessibility(*) experts, 4 disability policy specialists, 3 interviewees in charge of accessibility within their companies, and 2 representatives from professional associations in the assistive technology sector.  
• 6 policymakers working in the field of disability employment and accessibility in OECD governments. 
Interview guides specific to each stakeholder type were developed.8 Stakeholders were interviewed in oneto-one settings for periods ranging from 60 to 90 minutes; these mostly took place virtually as video conference interviews. Interviews were recorded and transcribed. Interview data were completed with a literature review and a policy review in OECD countries as well as with extensive desk research to identify relevant AI-powered solutions. Notable entry points for this desk research were AI-related industry newsletters and experts' word-of-mouth. The resulting repository of solutions was also vetted by experts in the field. One limitation of the research methods used here is inherent to interview-based research: while efforts were made to include all viewpoints in the list of interviewees and to map the field as comprehensively as possible, omissions and missed cases are always a possibility. Another limitation is related to the fact that the object of study itself is evolving while the research is being conducted: the report therefore represents the best of the author's knowledge at the time of writing.  
Figure 1. The report considers both mainstream AI-powered solutions and specialised ones  
Mainstream AIAI intentionally designed to support 
PWD Not supporting PWD in the labour market
(A)Supporting 
PWD in the labour market 
(by-product)
(B)Supporting PWD in the 
Accessibility enhancing (first labour market (first intent)
intent)
(C)
	Risks	Opportunities & risks
 
Note: PWD stands for "People With Disability".  
The report proceeds as follows: Chapter 1 evaluates the potential of AI to foster employment of people with disability. It starts by mapping the field, identifying, and classifying relevant AI-powered solutions, describing how they can support people with disability in the labour market, as well as the actors, business models and innovation flows at play behind them. It then discusses the extent to which these solutions could be transformative to reduce the disability employment gap, compared to previous technologies. It then reviews the risks posed by the development of both mainstream and specialised AI-powered solutions for people with disability. Chapter 2 identifies the challenges that hamper the use of AI to support people with disability in the labour market, from obstacles hindering the research and development of AI-powered solutions (notably related to accessing funding, data, and human resources), to barriers in the commercialisation phase (related for instance to the affordability and discoverability of solutions), and difficulties slowing down the adoption of solutions by end users (e.g. lack of usability and lack of user engagement in the developing phase). Chapter 2 also discusses the role of mainstream solutions in making the most of AI to reduce the disability employment gap. Finally, Chapter 3 discusses the role of governments in both seizing the potential and addressing the risks posed by the development of AI described in previous chapters. It starts by reviewing policies, existing or emerging, at the intersection of AI and disability rights/accessibility and considers the extent to which they are up to the task. It shows that: 
i) regulations on both subjects tend to be too siloed and to focus exclusively on addressing risks; ii) emerging AI standards are often general and do not address the specific risks to people with disability; and iii) industry self-regulation and strategies put in place by organisations to mitigate these risks often face technical and practical limitations. Building on this assessment, the chapter then presents suggestions emerging from interviews with stakeholders as to what governments could do, going forward, to both address the risks and seize the opportunities of AI to support people with disability in the labour market. 
1 Evaluating the potential: Could AI foster employment of people with disability?  
To measure the potential of AI to support people with disability in the labour market, this first chapter maps the field of AI-powered solutions that could help and answers the following questions: What can AI already do today? What solutions are currently in development? Which actors are driving innovation? Where do AI-powered solutions intervene on the path from non-employment to employment? The chapter then considers the extent to which AI-powered solutions might be game-changers when it comes to fostering sustainable employment for people with disability. The last part of the chapter discusses the risks for people with disability posed by the increasing adoption of AI in the labour market and in society at large, which is essential to paint a complete picture of AI's capacity to support their labour market participation. 
1.1. State of the technology: What is out there?  
1.1.1. Classifying relevant AI-powered solutions  
This report builds on insights from 71 interviews with various stakeholders (including 34 case studies of specific AI-powered solutions), as well as extensive desk research, to understand how to make the best of AI to support the employment of people with disability. The research identified 142 AI-powered solutions as relevant to labour market accessibility(*) (see Annex A for a full repository). Although these examples do not constitute an exhaustive list,9 mapping what exists is useful to gauge the future potential of AI. It is also suggestive of how that potential could evolve. 45% of the examples listed concern technologies that are still in development, from research and prototyping to commercialisation and widespread use, indicating that the potential of these solutions is poised to grow.  
The solutions analysed address a range of disabilities, from vision (about one-fifth of cases), hearing and motor (about 15% each), cognitive, speech (around one-tenth of cases each), and mental health (just over 5%). In just under a quarter of cases, solutions can help with multiple disabilities at the same time. Overall, examples can be classified into four groups:   
• Disability-centred solutions 
• Environment adaptation solutions 
• Solutions improving accessibility at a meta-level 
• Solutions unlocking new work opportunities for people with disability 
"Disability-centred" solutions (Box 1.1) make up the largest group (about three-fifth of cases). Most of the solutions in this group provide workarounds to people with disability, for instance by offering an alternative to an action that cannot be performed easily. Examples include: live captioning algorithms for individuals who are deaf or hard-of-hearing; image recognition solutions allowing blind or low-vision individuals to hear descriptions of the world around them; self-driving wheelchairs using computer vision to move autonomously; speech-to-text solutions for people with dysarthric(*) speech or for people who cannot type on a keyboard; or, more generally, AI-powered accessible interfaces using face, gaze or lip movements, or even brain signals, to control devices. The rest of the "disability-centred" cases, solutions do not provide alternatives but address disabilities directly. Examples include AI-powered hearing aids; mental health treatment using conversational AI;10 AI-powered gait-correction prosthetics; voice synthesis solutions; or AI-powered interview coaching systems for neurodiverse individuals.  
Box 1.1. Examples of disability-centred solutions 
Examples of "disability-centred" AI-powered solutions listed in Annex A span a variety of disabilities and technologies, with image and speech recognition algorithms featuring prominently. For example:  
• The French company RogerVoice offers an application allowing deaf users to read phone calls through an automated captioning system based on speech-to-text algorithms.  
• The solution developed by Voiceitt, a company based in Israel, lets people with dysarthric speech train their own voice-recognition algorithm, allowing them to communicate more easily via speech-to-text, and to use voice activation to control intelligent devices.  
• Several solutions use image recognition algorithms to allow people with vision impairments to hear descriptions of the world around them. For instance, the Dutch company Envision, has developed Envision Glasses, building on Google Glasses as hardware support. Together with a companion phone-based application, Envision Glasses allow blind users to read typed and handwritten text, recognise humans in front of them, or hear descriptions of objects and landscapes in their vicinity. The application Google Lookout offers a similar service, using the camera of a user's phone as input.  
• Together with academic research teams in Canada and the United Kingdom, Solar Ear, a company based in Brazil and specialised in providing solar-powered hearing aids to people who are deaf in the Global South, is developing an AI-powered hearing loss test and a companion AI-powered app that can act as a personalised hearing aid based on the test's diagnosis. The hearing aid functions with a phone's receiver and microphone without any additional equipment needed, making it more accessible to people with hearing loss in low-income countries. 
• Researchers at the Frist Center for Autism and Innovation at Vanderbilt University in the United States have used virtual reality technology and AI to create a job interview coaching system designed to train people on the autism spectrum in social and communication skills.11  In the second group of solutions, termed "environment adaptation solutions", AI is used to make an environment accessible to all, regardless of disability status (Box 1.2). Just over one-fifth of all cases identified fall into this group. Some environment adaptation solutions use technologies already cited above, such as live captioning, text-to-speech algorithms or accessible interfaces. However, an important difference is that these solutions allow content and workplaces to be made accessible rather than expecting persons with disabilities to adapt. These innovations contribute to a necessary evolution, according to Rylin Rodgers, disability policy advisor at Microsoft, because "It shouldn't be the disabled employee's job to find out that there's a solution they could be using"; rather, workplaces and environments, in general, should be accessible by default (Rodgers, 2023[9]). Other examples in this group include plain language and text simplification algorithms that make texts accessible to neurodiverse individuals, or algorithms automatically suggesting alternative text ('alt text' (*)) to describe pictures.12,13  In yet other solutions, AI powers indoor positioning systems to make buildings accessible to blind and low-vision individuals. Finally, this second group of solutions includes alternative labour market matching tools using AI to match individuals with jobs in ways that aim to prevent exclusion and discrimination based on disability (Box 1.2).  

Box 1.2. AI-powered solutions to make environments accessible 
While "disability-centred" AI-powered solutions focus on individuals with disabilities themselves, "environment adaptation solutions" are designed to make environments inclusive of and accessible to people with disability.  
• The chatbot developed by the American company Zammo.ai is designed to make job boards, such as LinkedIn or Indeed, accessible for people with vision impairments and neurodiverse individuals. Zammo's chatbot is designed to sit on top of traditional job boards and provides an alternative and accessible interface for users, who can access information about job postings in a conversational manner, via text or speech queries and answers. 
• The French company Okeenea's indoor positioning system for blind and low-vision individuals currently uses a system of Bluetooth beacons to guide users inside equipped buildings via audio cues. The company is working on a next version that will instead rely on an AI algorithm fed by data from captors already present in every phone to locate users very precisely in any building mapped into their system.  
• RogerAccess is the environment adaptation solution developed by the company RogerVoice mentioned in Box 1.1. This version of the solution allows companies to make their customer service accessible using RogerVoice's live captioning algorithm. 
• Capito and U31 are companies based in Austria and in France, respectively, which both offer browser add-ons and desktop applications add-ins using natural language processing to support the automated translation of written content into plain language, easily understandable by all, fostering content accessibility for neurodiverse individuals.  
Alternative job-matching tools 
AI is being developed and used at various stages of the labour market matching process. As documented in Broecke (2023[10]), applications in this domain are varied. They include tools for optimising job descriptions and CVs; tools for sourcing applicants; tools for facilitating job search and making tailored job recommendations to jobseekers; and tools for screening applications, shortlisting candidates, and interviewing them on behalf of employers.  
Some have argued that these AI-powered job matching tools could help decrease the disability employment gap by "neutralising the subjectivity of the interview process", during which ableist(*) stereotypes are likely to be activated (Walkowiak, 2023[11]). Some AI tools used in optimising job descriptions may also help promote greater diversity in applicants by helping recruiters avoid language which might deter minority candidates from applying (Broecke, 2023[10]). 
However, these "mainstream" AI-powered matching tools also bear concrete risks for people with disability (Broecke, 2023[10]; Allen QC and Masters, 2020[12]; Australian Human Rights Commission, 2020[13]; Orwat, 2020[14]; Quinn, 2021[15]; Engler, 2019[16]; Nugent et al., 2020[17]), as explained in more details in section 1.3 below. For instance, the lack of reliability of tools using face and voice recognition may result in discriminatory outcomes for people with disability (Broecke, 2023[10]; Fruchterman and Mellea, 2018[18]; Guo et al., 2020[19]); the use of data such as past job tenure or resume contents might lead algorithms to screen out people with disability who often have to go through career and education interruptions because of their disabilities; more generally, algorithms trained with data reflecting past human biases in hiring are likely to perpetuate the disability employment gap, or, worse, to increase it if the efficiency of automated decision making magnifies the bias (Ajunwa, 2016[20]). People with disability are also more likely to be excluded from training datasets while the interfaces of AI-powered job-matching tools are sometimes inaccessible and can exclude them by design. 
Faced with these risks, several actors are developing alternative job-matching tools using AI in deliberate attempts to screen in people with disability. Some of these initiatives are listed in Annex A. The common denominator behind these examples is that they rely on alternative input data, other than e.g., the resume and past hires data used in many mainstream models, that could be correlated to disability status.14  
In some cases, the input data used is of an entirely different nature. For instance, the job-matching platform developed by researchers at Vanderbilt University uses eye movement data from autistic candidates (collected while they are solving a puzzle) to identify their cognitive strengths and predict the kind of jobs in which they would be most successful. Similarly, the matching algorithm developed by Cogmap.ai uses data on candidates' automaticity15 (collected while they play a short game). According to the creators, this algorithm does not discriminate and leads to better matches, improving job retention and workers' well-being, notably among neurodiverse individuals (Farahani, 2022[21]).  
In other cases, algorithms rely on more fine-grained data about candidates' skills profiles. For instance, the start-up Mentra is matching neurodiverse individuals with jobs using data collected through detailed questionnaires about candidates' competencies. The algorithm will then be refined using data on job retention and user feedback following successful and unsuccessful placements. JobsAbility, the matching algorithm developed by the start-up OurAbility, uses data from a detailed questionnaire about what candidates with disabilities would like to and can do. Inclusively's algorithm aims at better matches and avoiding discrimination through a combination of better job description data, augmented with possible accommodations for each job, and self-declared physical and mental abilities on the candidates' side.  
These examples illustrate how AI can be used to "identify uniqueness" at scale, instead of, as is most often the case, identifying average patterns. According to Jutta Treviranus, Director of the Inclusive Design Research Center at OCAD University in Toronto, using AI "for data exploration" is more promising to foster employment of people with disability than "data exploitation" that seeks to extract average patterns (Treviranus, 2022[22]). Data about individuals' particularities is used to produce more meaningful, long-lasting, and, importantly, non-discriminatory job matches (Nichols, 2019[23]). 
The third group of solutions uses AI to improve accessibility at a meta-level (8% of examples). In these cases, AI helps improve accessibility indirectly by facilitating or enhancing processes that themselves improve accessibility. For instance, AI can help improve the efficiency of the workplace accommodation process(*). As explained by Melanie Jones from the University of Cardiff, workplace accommodation "is often costly to an employer" and is also hindered by a lack of awareness among employees of their right to request reasonable accommodation and a lack of information about available solutions among employees and employers alike. In addition, "Once people are aware of [their right], there are also often long delays in implementation" (Jones, 2023[24]). AI can help smooth that process. Recommendation algorithms can match employees with assistive technology solutions based on their self-declared ability profiles, historical data on workplace adaptation, as well as user feedback data on the solutions themselves. For example, the British company Microlink PC, specialised in workplace accommodation and assistive technology, is training an AI algorithm using a corpus of past workplace accommodation recommendations to create a portal where employees onboarding into new firms will be able to confidentially self-declare their needs and the barriers that they face16 and be matched with recommended solutions. This solution aims to simplify the lengthy and costly process of workplace adaptation assessment. The company also hopes that its system will help reduce the fear of stigma and discrimination that often leads employees with disabilities to self-censor and renounce asking for reasonable accommodations to which they are entitled. Other examples of "meta-level" solutions to foster employment of people with disability use AI to prevent the onset of disability. For instance, AI is used to identify individuals most at risk of age-related macular degeneration and to prevent the onset of musculoskeletal diseases linked to bad positions while working. In yet other examples, AI is used to monitor the evolution of a person's disability status, which helps existing human-based support systems adapt as the disability evolves.17 
Finally, the fourth group of solutions uses AI to unlock new work opportunities for people with disability (in about 5% of examples). These examples span cases where new job opportunities in the field of AI are created specifically for people with disability (for instance, some data labelling companies aim to recruit neurodiverse individuals, who might have an enhanced capacity to focus and hence be particularly wellsuited for the job).18 In other cases, progress in AI unlocks job opportunities that were previously inaccessible to people with disability. For instance, the US-based company Phantom.auto develops AIpowered remote operation technologies in logistics and transportation, which can make jobs such as forklift operator accessible to people with physical disabilities. Another example is the "Quiet Mobility" application developed by the Korean company Co:Actus. Using AI for live conversation captioning, it aims to facilitate employment opportunities in the taxi trade for deaf and hard-of-hearing individuals. 
Data collection initiatives 
In addition to existing solutions or those in development, 7% of the examples listed in Annex A are cases of inclusive data(*) collection initiatives, designed as the first step in the process of training AI-powered solutions for people with disability. Some of these also use AI to facilitate data collection. Given that people with disability tend to be outliers with regard to many variables in mainstream datasets (which often fail to oversample on the disability dimension in compensation) (Kamikubo et al., 2022[25]), or to be left out altogether, expanding data collection on this population is a key initiative and indeed an important step in the development of many of the solutions discussed in this report. The expansion of data collection to include people with disability is termed "inclusive data".  
Inclusive data can be data on persons with disabilities themselves: for instance, the aim of Project Understood, a joint venture by Google and the Canadian Down Syndrome Society, is to collect speech samples from individuals with Down Syndrome to train speech recognition algorithms to recognise their particular speech patterns. Another example is the Speech Accessibility Project led by the University of Illinois in collaboration with various big tech firms, which also aims to collect a wide variety of samples from individuals with dysarthric speech in order to train inclusive speech recognition algorithms.  
Other initiatives aim to collect data about the environment that will allow training AI-powered solutions for people with disability. For instance, the Exonet database is a publicly available database maintained by researchers at the University of Waterloo that contains 5.6 million images of walking environments, collected with the objective of training environment recognition algorithms for robotic leg prostheses and exoskeletons. The Orbit and VizWiz datasets, which respectively contain videos and images recorded by individuals who are blind using mobile phones, were developed by academics with the aim of training image recognition algorithms for blind users.  
In some cases, data collection of inclusive data is also facilitated by AI. For instance, accessibility-relevant mobility data (e.g. the presence of curbs, ramps, elevators, but also measures of pavement width, street slope, etc.) used to be collected manually through a "lot of painstaking work", explains Jean-Marie Favreau, lecturer in computer science at the Université Clermont-Auvergne. "The data entry capacity for a person is six kilometres of information per day. Bearing in mind that there are hundreds of kilometres of pavements in a city like Paris, for example, this means an enormous amount of time" (Favreau, 2022[26]). In this context, he argues, data entry automated using image recognition technologies can boost efforts to make maps and itinerary calculators more inclusive. Some actors have already started doing so: for instance, the community-led mapping organism OpenStreetMap is developing a scalable image recognition algorithm to facilitate the addition of accessibility-relevant mobility data to its existing maps. Another example is the French start-up Andyamo, which already uses AI to collect data in Paris on the accessibility of public spaces and transportation systems and to integrate these data into existing GPS guidance solutions. AI can also be used to facilitate the sharing of such data (for instance, by automatically recognising and blurring faces and number plates to avoid infringing privacy rights), or to reconstruct simplified street plans19 on which to input accessibility-relevant mobility information (Larrouy, 2022[27]).  
1.1.2. How could these solutions help foster employment of people with disability?  
Figure 1.1. Where on the path to employment do most AI-powered solutions intervene?   
A. Generalist solutions / solutions with second-order labour market effects 
Share of examples
25%
20%
15% 10%
5%
0%
Disability prevention	Improving data	Equal digital access	General	General independent	General mobility	General well-being availability	communication	living

 
Note: Data in panel B correspond to labour market-specific solutions specifically developed for workplaces or with the objective of closing the disability employment gap. Data in panel A correspond either to generalist solutions not developed with the specific aim of closing the disability employment gap but that nonetheless have immediate labour market applications,20 or to solutions that only have second-order labour market effects.21 The latter were not developed to reduce the disability employment gap and have no immediate labour market applications, but they are still included in the list of examples compiled in this report because they could decrease the disability employment rate further down the line. 
As shown in Figure 1.1, most of the solutions identified in this report are likely to foster employment of people with disability through their larger effect of improving communication (20% of total cases), independent living (21%), or mobility (18%). These innovations are generalist, meaning that they improve communication and/or mobility and independence in all spheres of life, including employment-related ones. Solutions that extend beyond the labour market include those fostering digital accessibility (10%), improving data availability (6%), improving general well-being (4%), and those that aim to prevent the onset of disability (3%). Solutions that are labour market-specific intervene at various points on the path from non-employment to employment: only 2% of examples are directly concerned with helping at the point of skill acquisition; 4% of cases focus on job search, and 1% on interview preparation. In 4% of identified solutions, AI helps unlock new job opportunities for people with disability. 2% of cases facilitate commuting, 4% foster workplace accommodation and 1% of examples improve workers' well-being.  
Few of the solutions identified are designed to help with skills acquisition - even though there is evidence that the disability employment gap "is aligned with a persistent disability gap in education and skills" (OECD, 2022[4]). Similarly, examples of solutions using AI to foster career advancement for people with disability are missing from Figure 1.1. Yet, according to Shea Tanis from the Kansas University Centre on Developmental Disabilities, AI would be particularly well-placed, for instance, to "build and monitor individualised skill-building strategies for career advancement". Tanis identifies a general lack of attention to the later part of the employment journey in the assistive technology field. In particular, she sees "the job retention piece and the career advancement piece missing" (Tanis, 2023[28]). This is problematic because, as explained by Melanie Jones from Cardiff University, most people with disability "are not born with them" but rather are already "in the labour market at the onset of disability". For this reason, ensuring job retention might be even more crucial than fostering access to jobs: "We always think about getting a job, or about barriers to education; but the time before somebody drops out of the labour market is also critical" (Jones, 2023[24]). More generally, accessibility specialist David Banes argues that the measurement of success when it comes to policies designed to reduce the disability employment gap tends to be too narrowly focused on employment rather than on broader indicators of quality of life (Banes, 2023[29]). Céline Cagnon, disability representative at TotalEnergies, insists on the importance of monitoring "the experience of people who are currently in work with a disability". In the context of ageing societies, she argues, in which employees are working longer in life, the prevalence of disabilities among employees will increase. Solutions "helping them with things that will spare their body or spare their cognitive fatigue" would thus be welcome (Cagnon, 2023[30]).  
There are no data on the actual use of these accessibility-enhancing AI-powered solutions by sector and/or occupation. Interviewees anecdotally note that usage could be varied and spread across occupations and skill levels. While these innovations may still be more likely to remove barriers to work in occupations that rely on ICTs (where, for instance, solutions fostering digital accessibility might be particularly helpful), Microsoft's Rylin Rodgers estimates that AI tools currently being developed could also help remove barriers to, e.g. client-facing service jobs. For instance, built-in desktop applications for AI-supported offline captioning could allow someone with hearing loss to work in a retail shop, at "no additional cost" than that of a laptop open on the counter (Rodgers, 2023[9]). 
1.1.3. Actors, business models and innovation flows 
Among the 142 solutions identified, a majority (24%) are developed in academic settings,22 closely followed by small firms of less than 50 employees (distinguished from start-ups23) which account for 23% of examples. Big tech firms and start-ups are behind 18 and 14%, respectively, of the examples identified (Figure 1.2). However, big tech companies are indirectly involved in a higher share of solutions through support offered to start-ups via dedicated incubation programmes and grants, as well as through providing 
AI services (access to computing power, training data, coding sandboxes, etc.) to smaller firms.24,25 
Most of the inventors interviewed had no pre-existing ties to the traditional assistive technology industry.26 Relatedly, although some interviewees from the traditional assistive technology industry identified AI as a potentially promising technology, it was often described as being peripheral to their field. However, as explained above, AI is already used in disability-centred solutions that could qualify as assistive technologies. Overall, interviews revealed a lack of integration and mutual awareness between the established assistive technology field and the emerging realm of AI-powered solutions that could help foster employment of people with disability.  
Figure 1.2. Academia and small firms are responsible for the largest shares of AI-powered accessibility-enhancing solutions  
30%
25%
20%
15% 10%
5%
0%
	Other	Large firms (250+	Medium-size-firms	Start-ups	Big tech companies	Small firms (<50	Academia (including
empl.)	(<250 empl)	(including	empl.)	partnership and spinpartnerships)	offs)
 
Note: Other is a residual category consisting of governmental programmes, volunteer-based organisations, free apps, and apps created by individual developers. "Including partnerships" means that in some cases innovation is led by a big tech company / an academic research lab in collaboration with other actors (e.g. start-ups, big tech companies, academic labs). The distinction between small firms and start-ups is explained in endnote 23.  
87% of the solutions identified are "first-intent" tools(*), i.e. tools developed in order to help people with disability. In the 13% remaining cases, the disability-friendly solution is a by-product of a generalist solution. For instance, generalist solutions such as ChatGPT or Grammarly can provide concrete solutions for neurodiverse(*) individuals who might struggle with writing and/or reading long texts, even though they were not developed with that specific aim in mind. Built-in features such as Android LiveTranscribe or the live meeting notes solution developed by Otter.ai can also "incidentally" provide live captioning for deaf and hard-of-hearing individuals. Another example is the technology behind automated vehicles which, although it was not developed as a first-intent accessibility solution, has the potential to enhance accessibility as a by-product (see Box 1.3 below).  
Conversely, "first-intent" solutions might end up having other, more mainstream applications. In fact, interviewees often insist on the historical role of the accessibility field as a testing ground for more mainstream solutions and of people with disability as technology pioneers, for instance, in areas such as speech recognition and live captioning. Thus, many of the "first-intent" solutions listed in Annex A have applications beyond disability. For instance, the AI-powered driving instruction system at Vanderbilt University developed primarily for the neurodiverse population would also be very useful for driving rehabilitation following a stroke or a traumatic brain injury (Stassun, 2023[31]). The lip-reading technology developed by Liopa has applications for speech and hearing disabilities but also in cases where a vocal command would be rendered ineffective by a noisy environment. The voice recognition algorithm developed by Voiceitt for the particular use case of people with dysarthria could also be useful in the case of "dialects, accents, minority resource languages, or ageing adults" (Smolley, 2022[32]). In the words of Haley Hataway, data analyst at Mentra, the start-up developing a job-matching algorithm for neurodiverse individuals using data from detailed questionnaires rather than traditional CV data,  
"While Mentra's inclusive approach aims to level the playing field for neurodivergents and other underprivileged groups, it could also benefit everyone. Avoiding reliance on traditional work experience and education and trying to find non-traditional factors that are indicators of success in a given position or in a given field would allow us to match based on natural aptitude and unique cognition, instead of just 'what university did you go to and what job did you land afterwards'. This would be an overall better approach to recruitment than what's currently in place" (Hataway, 2022[33]).  
More generally, Dimitri Kanevsky, a research scientist at Google behind Google Relate, a speech recognition algorithm for people with dysarthric speech, argues that accessibility-related research can be a "maturing space" for more mainstream solutions (Kanevsky, 2022[34]). As explained by Melissa Moran, product manager for the product development team behind Google Lookout, the image recognition application for blind individuals, "We are a team that focuses on disability first solutions, but there's a lot of overlap with other teams on how to get our research and innovation into other core product areas" to make these additional features standard and used both by users who are blind and sighted (Moran, 2022[35]). This innovation flow from accessibility specific to mainstream applications is even part of the business model for the actors with the biggest investment capacity: they have an incentive to finance in-house research into AI-powered accessibility features, in part because future applications are likely to extend beyond disability. 
Most of the solutions identified that are already in the commercialisation phase27 follow a "business-tobusiness" (B-to-B) business model. Some companies sell their solution to employers, who then provide it to their employees with disabilities. This is the model, for instance, behind the Envision for Enterprise programme imagined by Envision, the Dutch start-up building an image recognition algorithm onto Google Glasses and offering them as a wearable solution for blind individuals. Employers purchase Envision Glasses and "offer them to their visually impaired employees to enable them to have full accessibility of their workspace along with the traditional screen reader that they would otherwise be given". Envision also provides customer support and maintenance and answers to "a lot of custom needs for each employer because everybody's operations are a bit different" (Goonewardhane, 2022[36]). Similarly, the business model behind alternative job-matching tools such as OurAbility or Mentra is that employers looking for candidates pay to access the platform while the service is free for candidates. Other companies following a B-to-B logic sell their solution to companies as a means of making their product or service accessible to people with disability. For instance, the AI-powered driving instruction system for neurodiverse individuals developed by researchers at the Frist Center for Autism and Innovation at Vanderbilt University will be sold to driving schools seeking to make their own offer more inclusive. RogerAccess, the captioning solution mentioned in Box 1.2, is sold to companies that want to make their customer service more accessible. Voiceitt sells its voice recognition algorithm as an API to other companies using voice recognition on their website or in their system. According to accessibility specialist David Banes, this model of "Licensing your technologies to others so that it gets integrated into a wider range of products" is particularly promising for AI-powered accessibility-enhancing solutions (Banes, 2023[29]).  
Another B-to-B model consists of selling solutions to not-for-profit disability stakeholder organisations such as rehabilitation centres, clinics, or disability rights associations. For instance, WeWalk sells its products through "established B-to-B sales channels" with partners such as the Canadian National Institute for the Blind (CNIB), the Royal National Institute of Blind people (RNIB) in the United Kingdom, the Chicago Lighthouse in the United States and Vision Australia in Australia, who then subsidise access to end users through their own networks. As explained by WeWalk's Jean-Marc Feghali, these not-for-profits are not "standard distributors" but rather act as "validators":  
"Their main interest is keeping their communities safe. Unlike in normal distribution agreements, we wouldn't just give them a margin and ask them to sell our product. It is the complete opposite. They would take the product, they would then review it, and then they would let us know if they want to work with us, which is very different to usual distribution". "We started building a real reputation with these communities. (...) Instead of conducting academic studies, we get the CNIB and the RNIB's endorsement of the product. They are visually impaired people that work for the benefit of visually impaired people, not individual companies that are selling to them" (Feghali, 2022[37]). 
In some cases, the solution is sold directly (although not exclusively) to end users following a business-toclient (B-to-C) logic. In these contexts, companies often try to get their solution approved for reimbursement in the context of public policies supporting access to assistive technology. Yet in some contexts this route is not seen as viable. For instance, RogerVoice's founder Olivier Jeannel explains that in France, B-to-C is more of a "driver, a way of entering the market, of allowing people to discover the solution, but it's not much revenue-wise, it's not sustainable" (Jeannel, 2022[38]).  
1.2. Evaluating opportunities: How transformative could AI be in fostering the employment of people with disability?  
Compared to pre-existing technologies, how significantly could AI change the prospects of reducing the disability employment gap? When asked this question, many interviewees insist on the revolutionary nature of AI in many fields including that of accessibility-oriented solutions and assistive technology. According to accessibility expert David Banes, AI will be as innovative in that field as the invention of the internet and mobile technology before it (Banes, 2023[29]). One way in which AI might be transformative is linked to its ability to "push the frontier of disability further". According to Open Inclusion founder Christine Hemphill, "disability is the point at which design fails humans". This means that "we can move disability, it is not a fixed thing, but a designable, circumstantial point". AI can help to move disability "in a transformational as opposed to an incremental way" by bringing a new tool "to that point of design failure" (Hemphill, 2022[31]). AI-powered solutions represent a shift compared to previous accessibility solutions because of the jump in speed and scale at which they can help, linked to both the quantity of data that AI can handle and its capacity to predict and automate responses. This has expanded the realm of possibilities for accessibility solutions. In 77% of the examples listed in Annex A, AI plays a crucial enabling role, meaning that the solution could not exist in its present form without AI and the underlying computing capacity powering it. As explained by Keivan Stassun, Director of the Frist Center for Autism and Innovation at Vanderbilt 
University, "[some things] we would not have been able to do without AI". As an example, he mentioned "collecting eye movement data, millisecond by millisecond and then translating these data streams into an understanding of the cognitive capabilities of an individual" (Stassun, 2023[31]).  
Intrinsic features of AI bring new possibilities to the field. It could be a catalyst for change in terms of labour market accessibility since a single algorithm or coding approach can be deployed to cater to many different scenarios and types of disabilities, while pre-existing assistive technology devices tended to be single-purposed. According to Shea Tanis from Kansas University, "The value of AI is that it can be applied in multiple ways which allow it to cover a wide range of needs". For instance, advances in the field of autonomous vehicles can be used to improve navigation tools for blind and low-vision individuals (Global Disability Innovation Hub, 2021[39]). Zammo, the chatbot aiming to improve the accessibility of job boards mentioned above, uses "one interface [to] serves different user groups" including blind and neurodiverse individuals (Gilligan, 2022[40]). 
AI also allows for greater customisation and personalisation than previous assistive technology solutions (Global Disability Innovation Hub, 2021[39]), creating "individual aids more tailored to one person's particular needs" (Noori, 2023[41]). AI-powered interfaces can adapt to users (Marzin, 2018[42]), which is particularly valuable in the diverse and intersectional disability community where standardised products are of limited relevance. According to Axel Leblois, President and Executive Director of G3ICT, AI's intrinsic adaptability to the user may also help integrate people struggling to interact with new interfaces, such as the elderly (Marzin, 2018[42]). Algorithms can be trained based on individual needs, with the ability to evolve as needs evolve. Adaptability over time is particularly valuable, explained Disability Rights UK CEO Kamran Mallick: "What I needed ten years ago is different to what I need today and will no doubt change in the future. You need technology that can adapt to needs throughout users' lives" (Mallick, 2023[43]). Annex A contains several examples that fit this description, from customisable speech recognition to customisable image recognition algorithms.  
AI is also particularly well-suited for co-design and collaborative development since it can learn from interacting with people and from crowdsourced feedback, allowing it "to build a more generalised and inclusive view of needs" (Global Disability Innovation Hub, 2021[39]). This capacity of AI to learn from user inputs is notably useful at a meta-level to build recommendation systems for assistive technology drawing not only on experts' opinions but on a much larger pool of insights, including from people with disability themselves. This means of crowdsourcing helps to better identify needs for assistive technology and gaps in provision and improving the match between users and technology. 
Emerging AI solution differ from previously existing solutions, in potentially transformative ways, in several regards. First, it is "much easier now with AI to integrate accessibility solutions into consumer technology". For example, voice assistants like Siri and Alexa "are designed for all but have massive implications and potential implementation for people with disability" (Banes, 2023[29]). The integration of accessibility-enhancing features into mainstream applications, facilitated by AI, might also help foster accessibility on a larger scale. For instance, interviewees see the integration of AI-powered accessibility features into computers by default as transformational. As explained by TotalEnergies's head of accessibility Christine Hamot:  
"The progress in accessibility through remote transcription and interpretation functionalities following Covid and the jump to online meetings has led to a huge improvement. Before, to guarantee accessibility for deaf employees, every meeting had to be attended by a paid typist, it was so cumbersome (...) What AI is doing there is revolutionary" (Hamot, 2023[44]).  
This "revolutionary" aspect is arguably reinforced by the contemporary shift to teleworking. Once people are working from home, explains accessibility specialist David Banes,  
"Some of the traditional barriers to employment, such as the physical environment, such as transport, become less of a barrier (...) The barriers that are significant to employment become digital. AI plays a huge role in reducing those barriers. It's not going to make the physical world overnight more accessible; it's not going to make office blocks and buses more accessible, but if you're going to work from home, it can make a huge difference" (Banes, 2023[29]). 
Second, many solutions can be described as "productivity tools", with the capacity to help non-disabled people as well (Wald, 2022[45]). "Many folks who don't identify as disabled are using accessibility features", and that is "starting to create a shift", according to Microsoft's Rylin Rodgers. She explained:  
"They're seeing these features as productivity features. I recently talked to a business executive who had no idea that captions were an accessibility feature. He believed that it was a productivity feature, to make his job easier (Rodgers, 2023[9])".  
Because of this, AI-powered solutions are likely to be "more ubiquitous than previous assistive technology" and therefore less stigmatised (Sharma, 2023[46]). According to interviewees, this characteristic of AIpowered tools might have a very concrete effect on the disability employment gap. People without disabilities may increasingly use "productivity-enhancing tools", thereby mainstreaming them - think, for example, of the increasing use of ChatGPT in workplaces. "[In] the job search context, it might help people with disability to feel confident about applying for jobs and it might lead recruiters to change their perspectives about what an applicant with disabilities can do" (Cagnon, 2023[30]). As explained by Victoria Wass from the University of Cardiff, "However skilled a disabled person is and however much support they get looking for work, if the employer isn't prepared to look at somebody with a disability, the disability employment gap will not decrease" (Wass, 2023[47]). One policymaker in the field of disability employment interviewed for this report concurs: "some employers are still very reluctant to hire persons with disabilities", and "do not understand disability". In this context, AI-powered solutions are described by interviewees as able to "boost the confidence of employers that solutions to employing people with disability can be found. (...) more efficient technology being available means more confidence from the side of employers" (Hammersley, 2023[48]), which may help foster recruitment of people with disability. Beyond "people's perceptions of what they can and can't do", the experience of people with disability in the labour market is also affected by the relative space they are given, "to demonstrate within a job interview that they can do something", as explained by Disability Rights UK CEO 
Kamran Mallick. AI may be able to help on both fronts.  
Interviewees also mention the fact that AI brings the cost of assistive technology down or, in other words, improves the affordability of solutions to close the disability employment gap. For instance, while a prohibitive cost was one of the three barriers to selling hearing aids in the Global South according to Solar Ear founder Howard Weinstein, using AI allowed his company to overcome that obstacle by shifting from a device-based solution to a cheaper app-based one.28 As David Banes argues,  
"[AI] makes us shift away from the idea that assistive technology is a device or a product and towards the concept that assistive technology is a feature or function (...) many of the features and functions that were provided in an expensive handheld device can now be put into a free or 99 cent app on a mobile phone" (Banes, 2023[29]).  
Emphasising how lower cost has enabled the development of solutions as well as their take-up, Susan Mazrui, Director of Public Policy at AT&T and disability advocate, explains:  
"The ability to customise devices through algorithms and to use a variety of interfaces has brought down the cost of features that are essential for people with disability. 20 years ago, to unlock your door, to turn off your lights, you might have had to put a USD 40 000 system in place. Now you can do it with Alexa or with Siri or any of the Google Home devices" (Mazrui, 2023[49]).  
Lower costs may also help reduce the disability employment gap. "Early in my career I would hear 'deaf talent is expensive because we need to have interpreters and captioners'", recalls Microsoft's Rylin Rodgers, wondering if the development of AI-powered captions that has driven the cost down "has changed employers' concerns about hiring yet".  
In contrast, other interviewees downplay the transformative power of AI, notably by highlighting that the principles behind it are not new, although they have been turbocharged and mainstreamed by increases in available computing power and data. Others worry that AI developers might be overpromising when it comes to how much AI can do to help foster accessibility and reduce the disability employment gap (Box 1.3). They worry that the phrase "AI" might have become a mere marketing argument (as suggested in the warning recently issued by the Federal Trade Commission in the United States calling on developers to "keep their AI claims in check") (Atleson, 2023[50]). Some experts question the current maturity of AI to help reduce the disability employment gap as long as the technology is not perfectly accurate. Indeed, 45% of the examples listed in Annex A are still in development. In some cases, this lack of AI maturity comes down to the availability of good training data: "Originally, we thought we'd start using AI right away", explains Mentra's data scientist, Haley Hataway, but the time necessary to build good training data based on successful and sustainable placements was under-estimated internally:  
"We see AI as a very strong tool in the long run, to facilitate the work we're doing [increasing neurodiversity employment] at scale", yet it still requires "a lot of manual intervention in the beginning" (Hataway, 2022[33]).  
In other cases, the state of research in computer science and the performance of algorithms themselves are seen as slowing down the development of some solutions. For instance, Okeenea's Chief Technical Officer, Yohann Tschudi, explains that the development of a guiding solution for blind individuals using AI to analyse smartphone sensors data is complicated both by the quality of sensors but also the state of AI development, which is "not good enough to be able to achieve the goal we want to" (Tschudi, 2022[51]). While the issue of maturity is likely to depend on the type of AI,29 in many cases, "even though AI may take you 98% of the way there, you may still need human help30 with the last 2%" explains Mike Wald from the University of Southampton (Wald, 2022[45]). Finally, some interviewees argue that while they might help, AI-powered solutions are bound to have a limited effect on the disability employment gap due to societal attitudes:  
"AI is not going to combat stereotypes. We still have a big job of awareness-raising and acculturation. You have to convince people, deconstruct prejudices and train them. It's a tough job, it's a job of conviction, it's a job of acceptance, it's a day-to-day job. I am not convinced that AI on its own can do that very well" (Hamot, 2023[44]). 

Box 1.3. Will automated vehicles foster employment of people with disability? 
The development of automated vehicles (AVs) has been described for years as a potential game changer for accessibility in general and labour market accessibility in particular. AVs could help remove an important barrier1 to employment for people with disability, namely transportation (Department of Labor, ODEP, 2019[52]). On-demand AVs could provide a cheaper alternative to the expensive paratransit options (i.e., to the individualised accessible rides without fixed routes or timetables supplementing public transit systems) currently available to people with disability for "first and last mile" transportation to and from fixed-line transit options (Fiol and Weng, 2022[53]). The absence of steering wheels and dashboards means that AVs could more easily be built to accommodate assistive devices such as wheelchairs than more traditional vehicles. Increasing transportation options for people with disability would help reduce commuting time and give them greater control over where to work, potentially leading to better job opportunities (Claypool, Bin-Nun and Gerlach, 2017[54]). Modicamore et al. (2022[55]) estimate that the development of driverless AVs would lead to a 15% increase in the employment rate of people with disability in the United States in the first year after roll-out. 
However, people with disability are still waiting for these promised benefits to materialise (Reardon, 2021[56]). One reason for this is that the technology is not yet safe enough to allow the deployment of fully autonomous self-driven vehicles for door-to-door operations on a large scale. Although the technology behind self-driving cars (regardless of their accessible status) has improved a lot in recent years, most efforts are still concentrated on going from advanced driver support features to conditional autonomous driving, in which human driver oversight is still necessary. Progress to fully autonomous driving with no human supervision, which would be the most useful from an accessibility standpoint, could still be far off (Autocrypt, 2023[57]). Current use cases of conditional autonomous driving are largely limited to last-mile transits in known and relatively safe environments such as campuses and airports. Because autonomous shuttle companies with accessible vehicles often still must employ humans to ensure safety on board, their costs remain high and several have been driven out of business in the past few years (Bellan, 2022[58]; Templeton, 2022[59]). Beyond technical considerations, gains to employment linked to the development of AVs depend on the fact that mainstream driverless AVs are designed accessibly from the start, which is not a given (Reardon (2021[56]); Claypool et al. (2017[54]); (PEAT, 2023[60])). If, on the contrary, inaccessible AVs (e.g. AVs without wheelchair access or adaptation for deaf passengers) are put on the market, discrimination faced by people with disability in accessing transportation would further increase. 
To guarantee accessibility and build user trust, the disability stakeholder community should be closely involved in the development and deployment of AVs. Governments also have a role to play in setting accessibility standards, enforcing clear accessibility requirements in public procurement (Department of Labor, ODEP, 2019[52]; Claypool, Bin-Nun and Gerlach, 2017[54]; Fiol and Weng, 2022[53]), creating safe pickup and drop-off curb spaces for AVs, guaranteeing their accessibility beyond the design of the vehicle (Fiol and Weng, 2022[53]), as well as through subsidies to ensure the affordability of public transit AVs in the future (Department of Labor, ODEP, 2019[52]; Fiol and Weng, 2022[53]). 
1: Claypool et al. (2017[54]) estimate that removing transportation-related barriers to employment for people with disability would allow approximately 2 million individuals with disabilities to access jobs in the United States. Reports frequently cite commuting difficulties as one of the most important barriers to employment for people with disability (National Council on Disability, 2015[61]). Although this barrier might have become less important since COVID-19 due to the expansion of teleworking, it is likely to remain a substantial barrier in the age of mostly hybrid (rather than fully remote) work. 1.3. What could go wrong? Understanding the risks of AI for people with disability  
This chapter aims to evaluate the potential of AI to help close the disability employment gap. To do that, the risks that AI (both specialised and mainstream) pose to people with disability, particularly in labour market contexts, must be factored in. The relative opacity and complexity of algorithms, as well as their dependency on data and autonomous behaviour, have been identified as potentially dangerous for fundamental rights (European Commission, 2023[62]) - including the rights of people with disability. In a 2021 report, the United Nations Special Rapporteur on the Rights of People with disability called on "States, business, national human rights institutions, civil society and organisations of persons with disabilities" to "openly acknowledge and rectify" the "well documented negative impacts of artificial intelligence on persons with disabilities" (Quinn, 2021[15]).  
A first series of risks is linked to the development of mainstream AI applications. First, the lack of reliability and the risk of errors attached to mainstream AI-powered tools, while not exclusive to people with disability, might be particularly consequential for them. For instance, as mentioned in Box 1.2, tools using face and voice recognition may lead to discriminatory outcomes for people with disability whose faces and voices might be more likely to deviate from the statistical norms on which models are trained (Broecke, 
2023[10]; Fruchterman and Mellea, 2018[18]; Guo et al., 2020[19]; Whittaker, 2019[63]). More generally, while AI is "helpful in recognising common objects and patterns (...) it is frustrating when things become uncommon" (Treviranus, 2022[22]), which is the case with disability. For instance, AI used to analyse interview videos might discriminate against people with disability whose means of communication stray from the average in terms of pace, clarity, and pronunciation, or who are non-verbal and/or have difficulties with social interactions. Sorting algorithms behind automated video interviews might screen out an applicant with "severe hearing loss, whose voice goes up and down" since it is "out of the norm" (ScottParker, 2022[64]).  
Second, risks to privacy, while not limited to people with disability, might be heightened for them (Whittaker, 2019[63]). Indeed, as explained by Salvi del Pero and Verhagen (2023[65]), "the personal data processed by AI systems are often more extensive than data collected by humans or through other technologies, thereby increasing the potential harm if something goes wrong". This potential harm is even larger for people with disability since "the current privacy protections don't work if you are highly unique" (Treviranus, 2022[22]): anonymised individuals might be reidentified using highly specific data corresponding to unique needs. There are concerns in the disability community that the algorithms behind AI applications might infer their disability status against their will (Trewin, 2018[66]). According to Haydn Hammersley, from the European Disability Forum, "Persons with certain disabilities, especially invisible disabilities, who might not want to disclose this to an employer (...) fear that the technology might pick up and diagnose them or pass on information about their condition" (Hammersley, 2023[48]).31  
Third, mainstream AI applications bear the risk of propagating built-in ableist biases and discriminating against people with disability. The risk of algorithmic bias against people with disability has been documented (Broecke, 2023[10]; Allen QC and Masters, 2020[12]; Australian Human Rights Commission, 2020[13]; Orwat, 2020[14]; Quinn, 2021[15]; Center for Democracy and Technology, 2020[67]; Whittaker, 2019[63]). It might materialise because people with disability are excluded from the training datasets of mainstream AI tools. Indeed, since, data-wise, "disability manifests as a divergence from the average or norm" (Treviranus, 2022[22]), people with disability are, if represented at all, often clustered at the extremes in datasets and "extremes tend to be removed in AI-based systems" (Fitzpatrick, 2023[68]). Algorithmic bias against people with disability might also manifest if the training data reflect embedded ableist biases that are being scaled and magnified through AI (Hutchinson et al., 2016[69]; Whittaker, 2019[63]). For instance, the use of resume data in automated hiring contexts is likely to reproduce and amplify hiring discrimination against people with disability since their resumes are likely to reflect past hiring discrimination as well as episodes of career and education interruption linked to their disabilities.  
Fourth, mainstream AI might generate inequity of use and further the exclusion of people with disability in the labour market if built in an inaccessible manner. "Once AI becomes mainstream" in the labour market, says Bong-Keun Jung from Seoul National University, if it is inaccessible, it will "create some gap in access between able-bodied and disabled individuals" and lead to more exclusion (Jung, 2023[70]). As mentioned above, if the user interfaces of AI-powered job-matching tools are inaccessible to people with disability (e.g. if they are incompatible with screen readers used by blind people, if there are no captions for deaf users, if there are no alternatives to recorded video interviews for any user not wanting their facial expressions or speech to be analysed, etc.) people with disability will be excluded by design (Center for Democracy and Technology, 2020[67]). As stressed by Bill Curtis-Davidson, co-director of the Partnership on Employment & Accessible Technology (PEAT),  
"You could design the most equitable algorithm for a chatbot-enabled system used for candidate interviews, but if speech is required to use it, then it's not accessible. The matching algorithm may be designed to avoid biases, but if you don't have an accessible user interface you will exclude people who may not use the same modality of interaction" (Curtis-Davidson, 2023[71]).  
In its 2021 report, the UN Special Rapporteur highlighted the risk of AI-powered hiring tools "short-circuiting the obligation of reasonable accommodation" in cases where, for instance, automated interview interfaces do not provide an alternative to voice for deaf or non-verbal individuals or do not factor in the additional delay in response caused by using a screen reader. Exclusion through inequity of use would also increase if productivity-enhancing generative AI tools used to edit text or produce code become widely used in workplaces but are inaccessible to some groups with disabilities. "When you have a lot of little companies developing resources and you don't know what's going to be adopted, accessibility can fall off" explains AT&T's Susan Mazrui. "And if it is adopted quickly and it becomes a primary tool within a workplace, it can be problematic for people with disability" (Mazrui, 2023[49]). 
These four main types of risk can also manifest in solutions specifically designed to enhance accessibility. In the case of AI for people with disability, the risk of error can lead to catastrophic consequences. For instance, consider an AI-powered mental health coaching solution that fails to provide relief or leads to a worsening of symptoms.32 As put by Jean-Marc Feghali from WeWalk, a firm using AI to analyse the data collected from blind users' connected white canes to help health professionals better monitor their conditions: "If your iPhone stops working, you restart it, but if your smart assistive technology solution stops working, you end up getting hit by a car" (Feghali, 2022[37]). Errors in live-captioning tools, while they might seem acceptable to hearing individuals, can exclude deaf users depending on it to follow a conversation. More generally, as argued by Draffan (2019[72]), "Where individuals need to use certain technologies rather than just want to use them, there is a requirement to have understandable systems that offer as accurate results as possible". Finally, if AI becomes "the cure-all" and ends up crowding-out33 human-powered alternatives in some areas, inaccuracies pose a real problem according to a disability policy researcher interviewed for this report.34 As argued by Bennett and Keyes (2019[73]), "technology is often pedestalised", and ""scientific ways of knowing (...) assumed to be far more accurate than they are". For example, some experts worry that the development of sometimes inaccurate "accessibility overlays" might do more harm than good for people with disability in the labour market (see also endnote 13). AI-powered solutions intentionally designed to help people with disability can also propagate biases and lead to exclusion through inequity of use due to the internal diversity that characterises the disability community (physical/mobility, sensory, cognitive, mental health, and health conditions). As explained by Jutta Treviranus, "People with disability tend to be more different from each other than people within the average population" (Treviranus, 2022[22]). This internal diversity, argues David Banes, heightens the challenge of "bringing in all those different needs into the dataset, into the design process" (Banes, 2023[29]). Rather, solutions tend to "solve issues for the majority within the disability group" (Treviranus, 2022[22]). As explained by Christine Hemphill, founder of the inclusive design consultancy Open Inclusion, "contexts of use differ a lot across people with disability", and "the greatest failures occur when you've got multiple marginalities or very unusual contexts of use" (Hemphill, 2022[74]). In other words, intersectionality also multiplies the possibility of discrimination and exclusion through inequity of use. 
In addition to these four main risks, the UN Special Rapporteur on the Rights of People with disability insists on the fact that the opacity of AI, its lack of transparency and explainability, "compounded by intellectual property laws and international trade agreements that effectively hide any inbuilt discriminatory design (...) is a real barrier to the right to equal treatment of persons with disabilities (...) If one does not even have the ability to identify discriminatory decisions that are being made on the basis of an individual's disability status, then it becomes exceptionally difficult to challenge such practices" (Quinn, 2021[15]).  
Finally, interviewees caution against the risk of techno-solutionism that might deprive people with disability of the freedom to choose the tool that best fits them (Hammersley, 2023[48]) and impose a one-size-fits-all perspective in which disabilities are considered as issues to solve. For instance, "computer vision (...) cements vision as a superior sense", to the detriment of non-visual sensemaking according to Bennett and Keyes (2019[73]). Further, the techno-optimism brought about by AI-induced progress in the field of accessibility might lead to overlooking the risks attached to it. According to Jutta Treviranus,  
"The wonderful things that AI can do in terms of bridging gaps are often used for reputation washing to some extent. (...) There is a lack of recognition that while AI helps people with disability that face average barriers, it becomes problematic for those who deviate from the average, and in some cases, it risks driving disparities further" (Treviranus, 2022[22]). 
Can these risks be mitigated? Several scholars notably challenge the notion that bias can be completely avoided (Trewin, 2018[66]; Bennett and Keyes, 2019[73]). One of the difficulties in doing so is linked to the internal diversity of the disability community: while avoiding bias implies using training datasets that are as inclusive as possible, experts concur that perfect representation - and, relatedly, the elimination of all risk of biases - is an elusive target. In short, bias can be largely reduced but probably not fully eradicated - see Chapter 3 for a more thorough discussion of how policies could help neutralise some of the risks mentioned above, as well as the limitations of these mitigation approaches. Does this limited effectiveness of bias mitigation mean that AI should not be used to build accessibility-enhancing solutions? Interviewees argue that this is not the case. Rather, they suggest that the most opportune ways of using AI to reduce the disability employment gap might reside in designs that do not call for ex-post efforts to improve data representativeness. In fact, Annex A contains numerous examples of solutions where the use of AI is not affected by data gaps. This is the case, for instance, of many of the solutions that aim to improve the accessibility of the environment. According to Jutta Treviranus, AI could also be used to consciously diversify workforces, by "tweaking algorithms" so that they maximise diversity within teams (Treviranus, 2022[22]). In that sense, using AI might allow "doing a better job of identifying discriminatory practices than we are with human beings, by collecting data that shows where the discrimination points are in a way that's better than we've ever been able to" (Mazrui, 2023[49]). According to Mike Wald, "we're often holding AI to much higher standards than we are humans (...) the good thing about AI is it's making you question biases" (Wald, 2022[45]). 
2 From development to user adoption: Challenges to AI supporting people with disability in the labour market 

Both mainstream AI solutions and those intentionally designed to support people with disability bear risks, as explained in the previous chapter. Chapter 3 discusses ways of addressing these challenges and the role of policy. At the same time, the survey of existing technologies presented in Chapter 1 sheds light on the many opportunities for AI to reduce the disability employment gap: AI can power technical solutions to specific impairments; it can help make environments more inclusive of all regardless of disability status; it can enhance the process of making environments accessible, at a meta-level; and it can open new job opportunities for people with disability. In short, the potential of AI to reduce the disability employment gap is real.  
This potential, however, has not yet been realised. While only 10% of the population needing assistive technology has access to it, the share of those with access to AI-powered technologies is even lower. In addition, many solutions reviewed in Chapter 1 are still in development or only available on a limited scale. All in all, AI-powered solutions fostering accessibility are still "underdeveloped and under-adopted" (Welker, 2023[75]). This second chapter seeks to understand why that is. Better seizing the potential of AI to reduce the disability employment gap requires identifying the obstacles currently hindering it, both at the point of product development and commercialisation and at the point of adoption by users. 
2.1. What is hindering the research and development of AI-powered solutions?  
2.1.1. Lack of sustainable funding for R&D 
During the research and development phase, most of the solutions that help people with disability as a first intent rely on two sources of funding: grants from public entities (e.g. from the European Union in the context of the Horizon 2020 programme, from national governments) and/or from Big Tech companies' incubation programmes dedicated to AI and accessibility. However, applications to, and maintenance of, these grants can require resources that might not be available to all accessibility-oriented start-ups (McConnell, 2022[76]). More generally, non-profit-driven sources of funding tend to be limited.  
For-profit sources of funding are even harder to come by according to interviewees. In fact, most accessibility-oriented innovators identify the lack of traditional investors and venture capital as an important challenge in the research and development phase. While some accessibility-oriented start-ups do manage to secure some private capital in their initial round of fundraising, many highlight the difficulty of securing such funding past the initial seed funding and point to the lack of "patient investors" in the field. Because of that, explains Richard McConnell (CEO and founder of Liopa, a start-up that develops visual speech recognition algorithms based on lip movements), it is very difficult to fund investment in solutions that "don't have a short-term (i.e., 3 to 5 years) commercial viability". Many of the companies that get through a first round of funding "never get to the second one, and they could not reach profitability in that short amount of time", explains Maël Fabien, founder and CEO of Biped - a start-up that develops a wearable mobility aid for visually impaired individuals (Fabien, 2022[77]). 
This lack of sustainable private funding is partly attributable to investors' perception that accessibilityenhancing AI would yield meagre and uncertain returns. Technology that "could help people" tends to be seen as "not necessarily very commercially lucrative" and thus generates scarce funding (McConnell, 2022[76]). The market size for these solutions is perceived to be too small, notably because of the internal diversity of the disability community. Some of these solutions are described as "orphan drugs" and thus "very hard to develop" because "they affect too small a customer base" (Mazrui, 2023[49]). This is especially true where disability interacts with other characteristics such as a relatively small pool of users in a particular language. For instance, the "small market size" issue was described as particularly acute in the case of the Korean language live captioning solution developed by the firm Co:actus (Lee, 2022[78]). Conversely, many traditional investors appear to be unconcerned by accessibility requirements, so accessibility is not always a selling point. It is important to note, however, that the field is not necessarily unprofitable. Some segments of the disability population do in fact represent sizable markets. As explained by WeWalk's Jean-Marc Feghali, while "getting investors to understand our market size is always a challenge, (...) there are 253 million visually impaired people worldwide with a moderate to severe visual impairment. It is not a small number by any means" (Feghali, 2022[37]). Similarly, SolarEar's Howard Weinstein explains that "there are 625 million people who need a hearing aid, and there are only 10 million sold every year, mainly to wealthy people. We're there for the other 615 million" (Weinstein, 2022[79]).  
The shortage of private investment identified by innovators could have less to do with an inherent lack of profitability and more with a lack of knowledge of disability among investors. According to Kamran Mallick, Chief Executive of Disability Rights UK, investors tend to underestimate the size of disability groups and their spending power (Mallick, 2023[43]), while Rylin Rodgers, Disability Policy Advisor at Microsoft argues that "the selling power of accessibility in a digitalised age is huge" (Rodgers, 2023[9]). Jean-Marc Feghali wishes there were more "specific social impact investors as opposed to standard venture capitalists" in AIpowered accessibility solutions, because the message behind these tools is "more complicated to explain to investors" (Feghali, 2022[37]). Further, as explained by Bong-Keun Jung, rehabilitation scientist and Professor at Seoul National University, companies could "learn from history", and recognise that the development of disability-oriented technology is likely to lead to mainstream commercial applications (Jung, 2023[70]). Susan Mazrui, Director of Global Public Policy at AT&T, similarly argues that "there is a business case for [investing in disability-oriented AI research and development] because of the concept of electronic curb cuts (...) the idea that sometimes you can come up with generalist solutions that have been practised and tried with a community" (Mazrui, 2023[49]). As discussed in Chapter 1, the versatility of AI means that one solution can end up serving diverse needs beyond the originally targeted community, and spill over into mainstream applications.  
While some interviewees deplore the lack of private investors, others insisted on "the need for specialised financing because there will always be cases which may not be profitable to design for" (Noori, 2023[41]). Further, Jean-Marie Favreau, a lecturer in computer science at Université Clermont-Auvergne, criticises the lack of funding for fundamental AI research as a "strategic mistake on the part of governments for many years". Such fundamental research, he argued, is an indispensable first step in the development of solutions fostering the sustainable employment of people with disability:  
"You need fundamental research, you need application research, and you need industry. People working on accessibility often need to wait for those doing application research to come up with prototypes, things that themselves depend on what is being done with data in fundamental research."  
Yet governments have tended to neglect this issue, leaving fundamental research "in the hands of the big tech companies", while public sources of funding are tied to unrealistic expectations: 
"To get [public] financial support for a project", he explains, "you need to promise that you're going to change society, hence doing both fundamental research and application research at the same time. But on average, projects only last four years. Changing society while at the same time developing fundamental things in such a short amount of time is not realistic" (Favreau, 2022[26]).  
In other words, while more private investment in the field is necessary, public funding streams for research into niche issues (Jung, 2023[70]) and fundamental research should be maintained and developed. 
2.1.2. Difficulty to access data and computing power 
Difficulty in accessing data also features prominently in innovators' list of obstacles. Indeed, as explained by Jean-Marie Favreau, data are "the key ingredient" for AI: without it, "it's really difficult to come up with something that's relevant" (Favreau, 2022[26]). Data collection is complicated by the existence of a "chicken and egg" problem (Favreau, 2022[26]; Larrouy, 2022[27]), namely: investments in data collection are dependent on the demonstration of their usefulness in concrete solutions, but data are necessary to develop these solutions and establish proofs of concept in the first place. For instance, Muriel Larrouy, from the Ministerial delegation to accessibility in the French Ministry of Ecological Transition and Territorial Cohesion faced a dilemma in her mission to foster public transport accessibility, "between waiting for the accessible itinerary calculators to be ready to collect accessibility data or incentivising the creation of calculators by collecting the underlying data" (Larrouy, 2022[27]). In this context, two types of actors can get ahead with data collection, according to Jean-Marie Favreau: on the one hand, public actors and researchers who can collect data for the public good, outside of commercial constraints; and, on the other hand, for-profit firms that can afford to buy data before it is proven useful. This is the case of Google, as explained by Pan-Pan Jiang, one of the research scientists involved in the development of Google Relate, an algorithm that can be trained to recognise dysarthric speech. "The first two or three years of our project was just collecting data to train speech models to understand impaired speech. This was a proof of concept." (Jiang, 2022[80]). For independent start-ups, however, the cost associated with access to correctly annotated data can be high and represent a very tangible barrier to entry (Fabien, 2022[77]). Interestingly, as discussed in Chapter 1, AI itself might become part of the solution in the future, as it helps to scale data collection and lower its cost through automation. 
Interviewees mentioned difficulty in accessing generalist datasets used in the training of algorithms (e.g. image recognition algorithms) as well as other types of data underlying innovation (e.g. accessibilityrelevant map data about cross-roads, curbs, ramps, etc. used in accessible mobility apps) and datasets representative of people with disability to train specialised algorithms (e.g. those to recognise dysarthric speech). Kamikubo et al. show that even "accessibility datasets" sourced from people with disability are often plagued with persisting representation gaps (Kamikubo et al., 2022[25]). For that reason, firms often have to spend time collecting their own data. As explained by Mentra's Haley Hataway (Hataway, 2022[33]):   
"The more I investigated external data sources [on successful job placements among neurodivergent individuals] the more I realised that they don't exist, that no one has really done extensive data collection on unemployment for this population in particular. So now we're collecting our own". 
Some interviewees mentioned compliance with data regulations such as the European Union General Data Protection Regulation (EU GDPR)35 as another hurdle when it comes to accessing data. For start-ups or SMEs with limited resources, the process of complying with such regulations can be perceived as disproportionately costly (McConnell, 2022[76]). Compliance with data protection regulations is also seen as limiting the possibilities of R&D for accessibility-enhancing AI. As explained by Bob McDonald from Google Research, while technically the speech recognition technology developed for Google Relate could be used to train algorithms to understand children born with Down syndrome, this is not doable because "collecting speech data from people who are under 18 is a herculean task" given that data protection regulations are particularly stringent. "So, we're paralysed in our ability to make progress on something like that because of well-intended policies" (McDonald, 2022[81]). On the contrary, according to Mark Hasegawa Johnson, from the University of Illinois, "the general increased attention to data privacy in legal frameworks has caused people to become much more precise in their specification of exactly what can and can't be done with the data, and it's made it possible for people without legal training to nevertheless understand those specifications". This, he argues, has been beneficial for data collection projects such as the Speech Accessibility Project, because "everybody in the world now knows that they have the right to control what's done with their own data", and what it means to give consent, which is facilitating participants' recruitment in data collection exercises (Hasegawa Johnson, 2022[82]). 
Another technical obstacle mentioned by interviewees is access to machines and computing power. According to Liopa's Richard McConnell, "high performance, cloud-based computing platforms that are required to do the training data and compute power are absolute barriers in terms of developing AI for accessibility" (McConnell, 2022[76]). Others note that their progress has been very dependent on supply chain delays in obtaining machines, the cost of which has increased a lot in the last few years. While many of the solutions identified originate in university research labs (see Chapter 1), the latter are also affected by the difficulty in accessing hardware. Academic research projects are "very dependent on these tools", leaving interviewees to wonder "whether they'll be able to keep up with the need for increased computing power" in the future (Favreau, 2022[26]).36  
2.1.3. Human resources challenges 
The difficulty of attracting AI talent in the accessibility field is another obstacle identified by innovators. "Getting brains is the most difficult part" according to the CEO of a firm using AI to produce an accessibility solution interviewed for this report:  
"There is an aristocracy of AI engineers and machine learning PhDs, they know they are highly sought after, they are approached by most of the big tech organisations (...) and so they ask for high salaries. And for us, as an SME, it is a challenge to get them to join us".  
Jean-Marie Favreau, from Université Clermont-Auvergne, concurs: "We are losing the expertise of young researchers who are relevant to these issues, who go work in big tech companies because that's where the money is and that's where the nice projects are" (Favreau, 2022[26]). Beyond salaries, recruiting difficulties might also have a regional dimension: Masashi Oikawa from IBM Japan identifies the lack of AI engineers in Japan as a barrier to the research and development of AI-powered accessibility solutions there.  
The lack of accessibility training among developers is seen as another barrier to the use of AI to power accessibility. AI developers are perceived as lacking in their knowledge of how to code accessibly and more generally in how much they understand disability and the principles of inclusive and universal design (Placencia Porrero, 2023[83]). According to a report commissioned by the European Disability Forum, "one of the root causes of poor accessibility in ICT product and services" is that "accessibility is rarely taught on computer science, design, or user experience courses. Axel Leblois of G3ICT stated 'the biggest gap is not in technology but in awareness and training'" (Marzin, 2018[42]). As put by Mentra's Haley Hataway,  
"The fact that someone can have an entire degree and career focused on technology that impacts end users, sometimes with really profound life impacts, without having any background, guidance, or training in the ethical implications of those systems is a little bit troubling to me" (Hataway, 2022[33]).  
This lack of accessibility training among developers leads to inaccessible product design even when regulations are in place. Christine Hamot, in charge of disability affairs at TotalEnergies, explains that "some software on the market still doesn't abide by regulations on the subject (...) even among big software editors" (Hamot, 2023[44]). This in turn limits the power of buyers, even when they include dedicated clauses to foster accessibility. The tendency for developers to be incompletely trained in accessibility issues is worsened by the lack of disability representation in product development teams to influence the design of solutions (Mazrui, 2023[49]). 
2.2. Understanding barriers in the commercialisation phase 
2.2.1. Lack of earmarked funding for the go-to-market phase  
AI-powered solutions originating in academic research labs face difficulties in transitioning from research projects to marketable solutions. Again, the lack of funding is an issue. "The journey from a university project to spin-off supported by some public spending, to privately financed start-up can be really long, sometimes up to 15 years", according to Yonah Welker, neurodiversity advocate and board member of several AI-powered, neurodiversity-oriented start-ups. Welker stresses the need for dedicated financing streams to help "quickly bring technology from university campuses to the real world" (Welker, 2023[75]). As explained by other interviewees, most of the existing grants tend to focus on the development phase, leaving a gap for the go-to-market phase when the technology is not yet commercially viable. For instance, the Korean Employment Agency for Persons with Disabilities (KEAD) only funded the research phase in the development of Co:actus's live transcription technology. The commercialisation phase was not covered, and this funding gap is identified as an obstacle by the developing team (Lee, 2022[78]). According to Seoul National University Professor Bong-Keun Jung, "there is no continuum between technology development and industry. (...) University labs are working well, but there's no middle part connecting them to the industry" (Jung, 2023[70]).  
The scarcity of earmarked funding for the go-to-market phase is a factor behind the discontinuation of several innovations past the prototype phase. This was, for instance, a key determinant of the discontinuation of Robohon, a robot designed to live-translate sign language into speech and text using image recognition, developed by a consortium of Japanese companies). Further, while, as explained in Chapter 1, most of the solutions identified are produced by small firms, the latter usually have a harder time accessing funding to scale commercially. The scarcity of funding for commercialisation limits startups and small firms' capacity to find a large enough audience and bring prices down (Scott-Parker, 2022[64]). It might create a vicious cycle in which inventors then have a hard time finding a sustainable business model. 
2.2.2. Affordability - who pays for the solution?  
As explained in Chapter 1, firms developing for-profit AI-powered solutions with applications to reduce the disability employment gap rely on both business-to-business (B-to-B) models and business-to-customer (B-to-C) ones. The difficulty in finding sustainable business models is a frequently mentioned factor behind the discontinuation of functioning solutions.37 Irrespective of business model, the innovators mentioned difficulties in reaching sustainability linked to the affordability of the solutions and difficulty in integrating them into existing reimbursement pathways for traditional assistive technology solutions.  
B-to-C models, in which solutions are sold to users directly, are not ideal when it comes to equity, since some users will not be able to afford them on their own. This in turn limits scaling, since only those who can afford to will buy the solution. In practice, people with disability tend to be disadvantaged in terms of work opportunities and wages and hence often do not have the purchasing power to access accessibilityenhancing solutions in the absence of a reimbursement mechanism (Fabien, 2022[77]). As explained by Kamran Mallick from Disability Rights UK:  
"Assistive technology (...) is incredibly expensive. So, until you are working for a company that can afford and is willing to buy it, or that [you can rely on a public reimbursement mechanism] (...) you often don't have access to those tools" (Mallick, 2023[43]).  
Further, B-to-C models can be perceived as exploitative: "we asked people to pay, and they were not ready to do that", explains Rogervoice's CEO Olivier Jeannel. "People are used to assistive technology being subsidised, or reimbursed, and so asking people to pay a monthly fee was seen as 'making money off of the disability community'" (Jeannel, 2022[38]). For these reasons, innovators tend to see the B-to-C route as fraught. Instead, B-to-B models selling to employers or getting governments to reimburse solutions are seen as more promising avenues.  
Yet reimbursement procedures, where they exist, can be cumbersome both for firms developing AI solutions and for individual buyers. For innovators hoping to get their AI-based solution reimbursed, the formal process might not even exist. For instance, one interviewee from a start-up developing a wearable solution for blind and low-vision individuals explains that his team's attempt to get the solution reimbursed in Sweden had to be put on hold because "there wasn't yet a tender that we could apply for (...) existing tenders focused on handheld assistive devices. (...) there wasn't a category for wearable AI-based systems". Innovators operating internationally are also confronted with the heterogeneity and fragmentation of reimbursement systems. Approval procedures vary between countries, sometimes at the sub-national level, as well as between public and private insurance systems. This complexity means that start-ups must often rely on the expertise of specialised consultants to help them navigate processes, which is expensive. Finally, the length of the process is also identified as an obstacle:  
"Quite often the process of applying for funding and getting that reimbursement can take anywhere from two to four months (...) it took eight months for [the wearable solution mentioned above] to be recognised as a class one medical device in the United States. In Germany, that process has taken another six months. And those are the kind of things that can kill a lot of companies. Waiting for months for a start-up that needs to show growth can be pretty much a death sentence".  
The length of the process and delays in administration are also described as problematic from the perspective of end users, especially for devices that might become outdated and/or require an update by the time the reimbursement has finally been granted (Fabien, 2022[77]).  
When it comes to selling solutions to employers, several interviewees mentioned a lack of disability visibility within firms and a lack of employer awareness around accessibility issues as barriers to commercialisation. According to Thibaut Duchemin, founder of Ava, a start-up providing AI and human-powered live captioning for hybrid meetings to schools and companies, "the first difficulty is the absence of awareness around disability" (Duchemin, 2022[84]). Several interviewees argue that, in the absence of legislation creating accessibility requirements and therefore opening up B-to-B markets, accessibility "is always de-prioritised, the last item to fund, where you look under the mattress to see if there are some coins left to give" (Jeannel, 2022[38]). Even where reasonable accommodation regulations exist, many interviewees point out that employers often do not know exactly how many employees with disabilities are in their workforce, which further limits their involvement as potential clients paying for AI-powered solutions on behalf of their employees.  
2.2.3. Discoverability 
New companies in the accessibility space "are hamstrung by the inability to create awareness in the community" for emerging, innovative products, according to an interviewee employed in a start-up developing an AI-powered solution for blind individuals. Melissa Moran, a product manager for the Lookout product development team at Google, explains that  
"one of the challenges for standalone apps like Lookout is discoverability. (...) To download an app, you need to know about it, have a phone that can run it, be able to download it and then also understand how to adopt it and use it. (...) that definitely reduces the ability for a lot more people to use it" (Moran, 2022[35]).  
Patrick Gilligan, from Zammo.ai, a firm developing a chatbot helping blind and neurodiverse users to access online job boards, stresses the same difficulty with getting the accessibility chatbot to be "discovered", and identifies it as a barrier to scalability and successful deployment over time. 
Discoverability is an issue whether innovators are seeking to integrate public reimbursement pathways or looking to sell their solution to employers on behalf of their employees. In the former case, innovators point out that actors traditionally involved in the reimbursement of assistive technology (e.g. government agencies, private insurance companies, disability rights associations, etc.) often do not know of emerging AI-powered solutions. Accessibility activist and consultant Susan Scott-Parker recalls the case of a public administration looking to adopt an AI-powered indoor guiding solution and finding itself "lost in the millions of existing wayfinding apps". Scott-Parker sees the absence of quality standards as an obstacle to discoverability and successful deployment in the relatively new and confusing land of AI-powered solutions: "there are no standards out there that govern what constitutes a high-quality wayfinding app. Anybody can claim to have one" (Scott-Parker, 2022[64]). Even "medical staff are less informed than [people with disability] on this issue" explains Céline Cagnon from TotalEnergies, who has low vision herself.  
"I personally use my annual appointment with my specialised ophthalmologist to tell him what I know. (...) There are a lot of breakthroughs, notably in mobile apps, that he does not follow. And it's the same thing for rehabilitation centers, Orientation & Mobility specialists teaching how to use the white cane, etc. This is going way too fast, they can't follow" (Cagnon, 2023[30]). 
Similarly, employers do not know about all existing solutions and lack guidance in terms of what solutions to offer for workplace accommodations. Considering the diversity of employee needs and the fact that these needs evolve with age, employers who can afford to tend to rely on employees trying out solutions for a while and to base reimbursement decisions based on employee feedback (Hamot, 2023[44]). However, this might not be doable for all employers and does not solve the issue of discoverability. Thus, interviewees insist more generally on "a need for communication. People need to know about what solutions exist" (Jeannel, 2022[38]). Interviewees call for a public policy of communication around existing solutions: "I think the issue of innovation for disability needs to be better represented and made more visible (...) the support structures to communicate about innovations are missing, that would have helped us" (Fabien, 2022[77]). 
2.3. What is hindering adoption by end users?  
For AI-powered solutions to effectively reduce the disability employment gap, a third necessary step, after successful development and commercialisation, is adoption by end users. In that respect, interviewees identify two main obstacles: lack of usability and lack of user engagement.  
2.3.1. Infrastructure, IT literacy, inter-operability: lack of usability as a barrier to adoption  
For AI-powered accessibility-enhancing solutions to be usable, an adequate infrastructure needs to be in place. For instance, access to reliable internet and electricity is a clear prerequisite (Sharma, 2023[46]). The usability of solutions varies with the quality of available internet and electricity networks (Cagnon, 2023[30]). This also partly ties back to the issue of affordability mentioned above: "computers, smartphones and just the broadband to access the internet and the WiFi, these things all cost, and people on these fixed incomes don't always have the means to enjoy it," explains disability policy expert Henry Claypool, citing this as the biggest barrier to adoption (Claypool, 2023[85]).  
User adoption is also likely to be mediated by levels of IT literacy in the disability community. "Lack of familiarity" among users can be an obstacle to user adoption (Claypool, 2023[85]). This obstacle is made more acute by the correlation between disability and age, since IT literacy is likely to be lower among older people. Interviewees describe frequent changes to interfaces as a major barrier to adoption, as users might be discouraged by having to learn how to use a new technology too frequently (Sharma, 2023[46]). "I can't tell you how many family members and individuals, who have a technology solution that they like, get an update and they panic (...) they ask providers to not change the system" explained Kansas University professor Shea Tanis (Tanis, 2023[28]). For that reason, interviewees call for "some type of standard (...) to make the interfaces usable, not just accessible" (Mazrui, 2023[49]), including ensuring that accessibility features are not too complicated to activate and considering special needs such as, e.g. plain language guides for people with intellectual disabilities (Sharma, 2023[46]). 
Finally, the lack of norms mandating inter-operability - between systems, between software and hardware, between AI-powered solutions and other assistive technology devices - is cited as another barrier to usability and hence to user adoption. If a new solution requires a hardware or software change to be usable, the cost associated with that might deter users from adopting that new solution.  
2.3.2.  "Something about us without us": lack of user engagement as a barrier to user adoption 
Despite the disability rights movement motto being "nothing about us without us", the most cited barrier to adoption amongst interviewees is the lack of user engagement in the development of AI-powered accessibility-enhancing solutions (Smith and Smith, 2020[86]; Whittaker, 2019[63]). Interviewees argue that co-creation approaches are often missing. Shea Tanis, professor at the University of Kansas, argues that "by the time they really do user analysis", start-ups are often "well beyond the beta, the discovery (...) most don't want to go backwards" (Tanis, 2023[28]). "Innovation tends to start from the technology" before being tested with users, also deplores WeWalk's Jean Marc Feghali, rather than the other way around. Open Inclusion founder Christine Hemphill similarly stresses the importance that AI remains a means, rather than an end goal if it is to effectively foster employment of people with disability: "The solution approach should not take precedence over the outcome to individuals", she explains. "Using AI in its possibly powerful way" implies starting with affected people and finding AI as a potential solution along the way (Hemphill, 2022[74]).  
Solutions developed without engaging people with disability in a meaningful way end up falling short of relevance and practicality. For instance, "the level of accuracy of a guiding tool might be fantastic", but if "the information it ends up delivering to the user isn't sufficient to help them take a left or avoid the chair", the solution is irrelevant (Feghali, 2022[37]). "The biggest blocking thing", for European Disability Forum's Haydn Hammersley, "is if you have a piece of some technology that simply isn't useful because it's been designed by somebody who doesn't really have a knowledge of what the needs are" (Hammersley, 2023[48]). While inventors might "try to imagine what it is like to have a disability", not involving people with disability from the start leads to "a very high likelihood that you will not grasp the problem sufficiently" (Noori, 2023[41]). A recurring example in that regard is that of the numerous attempts by hearing innovators to develop a sign language glove, i.e., a glove with sensors capturing hand gestures, designed to help with live sign language translation. This solution misses the fact that facial expression and upper body positions are two other key elements of the grammar of sign language. "While well-intentioned, oftentimes such solutions are misguided or do not take into account the actual way in which people with a variety of disabilities utilise technology or communicate in different languages" (Curtis-Davidson, 2023[71]). Solutions developed without meaningful user engagement might also end up missing some "additional underlying issues" not immediately visible to a researcher without disability but that are key to building useful solutions. For instance, Yonah Welker explains that the impact of the co-morbidities associated with a disability on the solution's usability is often overlooked: "autistic children also have more digestive, immune systems and mental health issues. Until you have all these things laid out which affect how this person uses your technology, how they experience it, how they memorise it, you can't properly design the algorithm" (Welker, 2023[75]). More generally, starting from the technology rather than from the needs limits the ability of solutions to foster employment of people with disability: 
"[We're] not studying the user journey and finding out gaps in the journey. We find pain points that either never existed for the visually impaired person or for which they already have coping mechanisms in place. We're not helping them achieve their end goal any better, we're just changing the way in which they get to the end goal"38 (Feghali, 2022[37]).  
This might lead to limited buy-in from users, a major impediment given that a product's "cultural acceptance" by a disability community is a key determinant of its adoption (Welker, 2023[75]). 
Lack of user engagement is also likely to lead to solutions being built in a vacuum, disconnected from the eco-system in which they are supposed to fit, which is made up of existing solutions, policies, actors, and support systems. "Devices do not exist outside of a process", explains Susan Scott-Parker. "The tools are interventions in a journey people are taking to get somewhere", and the entire journey needs to be considered when developing the tool (Scott-Parker, 2022[64]). "The most complex thing is not even building [the solution], but how to integrate it into e.g. schools, how to explain it to teachers, how to integrate it into the budget system, etc.", explains Yonah Welker. Another element that is likely to be overlooked without the relevant user engagement is the fact that a galaxy of people is part of the support system of someone with a disability and will likely interact with the tool, e.g. "their family, their caregiver, their doctor." (Welker, 2023[75]). Sara Smolley, from the start-up Voiceitt, also highlighted the importance of "having in mind that circle of people that surround an individual with disabilities" when developing an accessibility product (Smolley, 2022[32]). Policy context is also highly relevant and often overlooked. As Shea Tanis argues:  
"[There] are a lot of solutions on discovery and matching (...) [but they often omit some of the key contextual information to make them relevant, such as] are you getting benefits and would getting this job affect that? Are you going to have transportation to be able to get there? What types of solutions will support you as your career advances?" (Tanis, 2023[28]). 
Listening to the disability community is therefore centrally important to avoid building irrelevant, impractical and/or misconceived solutions and to ensure user adoption, as stressed by John Robinson, CEO and founder of the inclusive job-matching platform "Our Ability" (Robinson, 2022[87]). According to interviewees, failure to do so is notably linked to a lack of diversity in product development teams. Disability rights organisations, on the other hand, are described as having difficulty influencing the conversation around AI, including AI for accessibility, mostly for lack of means (Noori, 2023[41]). As explained by accessibility expert Larry Goldberg, "There is no question that those advocacy organisations can and should be involved. Unfortunately (...) they're small, they're overwhelmed, and they're underfunded. I know some of them are very savvy and they have it on their to-do list, but it's there with a thousand other issues" (Goldberg, 
2023[88]). 
2.4. Making the most of AI to reduce the disability employment gap: the role of mainstream solutions  
Most of the obstacles discussed above concern solutions that are intentionally built to enhance accessibility. In addition to these, making the most of AI to close the disability employment gap requires paying attention to mainstream AI solutions that can enhance accessibility as a by-product (i.e., those zone B in Figure 1. The report considers both mainstream AI-powered solutions and specialised ones above). Encouraging the development of these solutions could go a long way in reducing cost, guaranteeing interoperability, making the financing of accessibility-enhancing solutions more sustainable, and fostering more innovation. Some people will always need a "customised solution", explains Microsoft's Disability Policy Officer Rylin Rodgers. "But if we can get more and more parts of the solution to be included in mainstream solutions, then the cost and the need for the customised solution gets smaller" (Rodgers, 2023[9]). According to Inmaculada Placencia Porrero, Senior Expert in Disability and Inclusion at the European Commission, "the tandem of accessible mainstream technology together with specialised assistive technologies is the only thing that provides real equal access" (Placencia Porrero, 2023[83]). 
According to several interviewees, mainstream solutions offer a way out of the "high price tag, low innovation accessibility rent" sometimes associated with specialised assistive technology (Duchemin, 2022[84]). Indeed, according to Microlink PC founder Nasser Siabi,  
"The disability tag brings a hefty price list. People do seem to find disabled people as a good market to try to overcharge things. (...) There is government funding, so they can just take it as far as it goes. Some are great products, but they don't deserve the price tag" (Siabi, 2022[89]). 
This accessibility rent "comes in two forms", explains Donal Fitzpatrick, a researcher at the Irish National Disability Authority's Center for Excellence in Universal Design. "One is financial. But you're also trapped by a usability constraint" (Fitzpatrick, 2023[68]). On the first point, IDRC Director Jutta Treviranus explains that "having a separate segregated market for a limited customer base increases cost" (Treviranus, 2022[22]). People with disability tend to be a "captive market". As explained by Donal Fitzpatrick,  
"[As] a disabled person, when you start to use a piece of assistive technology (...) even though something else comes along that might be slightly better, there's a huge learning curve in actually switching from what you know to using something different (...) so you won't do it."  
Because of this, innovation is described as stifled in part of the assistive technology market: "We're not seeing innovation across the traditional assistive technology sector because they don't need to. They have their captive market" (Fitzpatrick, 2023[68]). A parallel worry expressed by interviewees in cases where accessibility features are not built into mainstream technology, but are stand-alone solutions, is loss of interoperability. The latter is "extremely important to people with disabilities, who use a wide range of assistive technologies and bespoke solutions for many of their accessibility needs" (Marzin, 2018[42]). If accessibility needs are not built in but are seen as taken care of by separate, specialised devices, mainstream technology producers might not take it upon themselves to maintain interoperability over time as they update their systems (Treviranus, 2022[22]).  
Mainstream AI-powered solutions with in-built accessibility features, or enhancing accessibility as a byproduct, are seen as a way out of the accessibility rent trap, guaranteeing interoperability and offering "offthe-shelf features for persons with disabilities" (Placencia Porrero, 2023[83]). The mainstreaming path is also seen as offering more sustainable business models:  
"[While] assistive technology focused on solving disability-related issues might never draw the type of capital that's necessary for innovation to really accelerate change and break the barriers" explains disability policy expert Henry Claypool, "going in partnership with addressing the disability needs at the same time that you're building something for the broader market is more desirable". "However," he adds, "these AI systems must be built with the clear intent of removing the disability bias that is present in datasets by default. The disability bias in our society is so pervasive that it requires this additional attention for the tools to avoid perpetuating disability discrimination" (Claypool, 2023[85]). 
2.4.1. Making the most of "mainstream AI" to close the disability employment gap: what are the obstacles?  
What is preventing the large-scale development of mainstream AI solutions inclusive of people with disability and enhancing accessibility as a by-product? At first sight, there are only advantages to making sure that mainstream AI is accessibility-enhancing. As explained by Christine Hemphill, from inclusive design consultancy Open Inclusion, "there is a significant halo effect of doing an AI implementation equitably and inclusively well. We're seeing purpose-led organisations now thriving". In contrast, not doing so or doing it only superficially "could cause a lot of reputational and business value damage in the long term" (Hemphill, 2022[74]). Further, designing inclusively helps design better products and even save costs by "identifying problems early on and resolving them before the fix is a multimillion-dollar fix." (Mazrui, 2023[49]) 
Yet, according to accessibility specialist David Banes, "designing to be inclusive of disability" can be more difficult than designing for a particular disability because it entails considering "the diversity of what we mean by disability". "Universal design for all the different forms of disability does become difficult and bringing all those different needs into the data set, into the design process, is challenging" (Banes, 2023[29]). Kave Noori, from the European Disability Forum, emphasizes the challenge for innovators to fit consultations with all types of disabilities in the project they're starting up. He fears it might discourage some from making their projects accessible (Noori, 2023[41]). Part of the solution, according to Banes, resides in the stronger involvement of associations, disability rights organisations, and people with disability in general in "the codesign process for innovation". Yet, he adds, while that might be achievable "for the big players, the Microsoft, the Googles, the Amazons and so on (...) the biggest challenge is how we make it possible for people who are developing low-cost solutions to afford to engage with the breadth of disability" (Banes, 2023[29]). 
Because of the challenges linked to inclusive design, firms developing mainstream AI products often end up following a "minimum viable product" approach that can be summed up as "we'll make it accessible later (...) we'll just get it going" (Wald, 2022[45]). This approach is problematic according to accessible technology professor Mike Wald because it makes accessibility contingent on further funding. "Minimum viable product means 'just throw it out there and see if anyone likes it'", according to accessibility specialist Larry Goldberg. "I can tell you how many MVPs are accessible: it's very rare" (Goldberg, 2023[88]). According to Jutta Treviranus, "the incentives are not there: mainstream companies have no incentive at the moment [to make sure that their innovation benefits all] from a regulation or standards point of view" (Treviranus, 2022[22]). 
Interviewees argue that ensuring that mainstream AI is inclusive - and hence, potentially, accessibilityenhancing - cannot be made to depend on the "good nature of businesses" (Claypool, 2023[85]). In companies where accessibility is a by-product rather than a first intent "disability will fall off when things become difficult (...) if there is not a regulation, a legal requirement, a compliance issue, or a contract"  (Mazrui, 2023[49]). Yet, the disability angle has been so far mostly overlooked in discussions about how to regulate mainstream AI (see Chapter 3), even those focused on making it safe and trustworthy. According to disability rights advocate Susan Scott-Parker, while the risks of discrimination against gender and ethnic minorities are being acknowledged, discrimination based on ability is still largely absent from "the world view of those influencing the responsible and ethical AI debate" (Scott-Parker, 2022[64]). Klaus Höckner, from the Austrian Association for the Blind, concurs: "I'm sitting in all these standardisation groups about AI, at various levels (...) and we try to tell them 'What are we doing in the field of disability?' (...) But AI is more seen as an accelerator for jobs and industry, and persons with disabilities are seen as a peripheral group" (Höckner, 2023[90]). 
Finally, interviewees identify another obstacle to making the most of mainstream AI, namely, the fact that existing reimbursement policies tend to be narrowly focused on specialised solutions and exclude mainstream ones (Treviranus, 2022[22]). According to accessibility specialist David Banes, "we need to go back to our policy and procedures and say, what have we put into those policy and procedures that mitigates against maximising the benefits of innovation, including mainstream artificial intelligence?" (Banes, 2023[29]). For Shea Tanis, from the University of Kansas, existing policies make it  
"very hard to take advantage of what innovations exist at this stage (...) There is a protective mode, almost parentification of policy, that is (...) discouraging access to different technological advancements". When defining reimbursement policies, policymakers tend to "inadvertently set parameters (...) They want to say this is what we'll fund, and this is what we won't fund. (...) they have set parameters around a specific type of hardware, software, et cetera, rather than looking at it as a solution to serve the individual". Instead, she argues, policies "have to be flexible", more focused on what is actually helpful to individuals than on "specific types of technologies" (Tanis, 2023[28]).39 
3 Seizing the potential, addressing the risks: what role for governments?  
This chapter draws on interviewees' insights to identify concrete policy avenues for seizing the potential of AI to support people with disability in the labour market. The policies discussed aim at both addressing the risks identified in Chapter 1 and overcoming the obstacles identified in Chapter 2. It starts by reviewing policies, existing and in-development, related to AI and disability rights/accessibility in OECD countries. It discusses their effectiveness to make the most of AI to foster sustainable employment for people with disability and lays out interviewees' proposals for government intervention going forward. Finally, the chapter discusses potential policy avenues to address risks and seize opportunities, for governments to consider.  
3.1. Are policies at the intersection of AI and disability rights/accessibility fit for purpose?  
A joint review of existing and emerging policies on AI and disability rights/accessibility reveals that policies tend to be too siloed: AI and accessibility are largely treated as two distinct subjects without due consideration of regulation aimed at their intersection. Similarly, accessibility and disability rights tend to be overlooked in emerging AI standards. Measures implemented by technology developers themselves to address risks to people with disability face technical limitations. This review of policies also sheds a stark light on the lack of policies aimed at seizing the benefits of AI to foster employment of people with disability. Existing policies instead focus on addressing risks. 
3.1.1. Regulations on AI and disability rights/accessibility are too siloed and focus almost exclusively on avoiding risks 
Disability rights/accessibility regulations  
Although existing disability rights and accessibility regulations pre-date the AI boom, they do create some legal obligations for AI-powered solutions. One key reference for disability rights and accessibility regulation is the United Nations Convention on the Rights of People with Disability (UN CRPD). Adopted in 2008, many of its articles still provide a legal basis to avoid the risks and seize the opportunities of AI to reduce the disability employment gap, according to a 2021 report of the UN Special Rapporteur on the Rights of People with Disability (Quinn, 2021[15]). AI-related implications of the Convention include the requirement that AI tools acquired through public procurement do not foster discrimination and are accessible, or the obligation to engage "with persons with disabilities and their representative organisations in the development, procurement and deployment of artificial intelligence systems" (Quinn, 2021[15]). The Rapporteur also lists rights to "privacy, autonomy, independent living, employment, education, health and in particular the overall guarantee of equality and non-discrimination", inscribed in the Convention, as particularly relevant to ensure that "the unprecedented power of artificial intelligence (..) be a force for good for persons with disabilities" (Quinn, 2021[15]). For instance, the Rapporteur argues that meaningful autonomy implies the need for informed and transparent consent and therefore creates obligations for systems of automated decision-making affecting people with disability to ensure the conditions of such an informed and transparent consent for people with disability.40 Similarly, the right to privacy implies that "persons with disabilities must be able to maintain agency over their personal data". The use of, for example, hiring algorithms systematically biased against people with disability is an infringement of the right to work and employment, which also mandates reasonable accommodation in recruitment, hiring, employment continuance, and career advancement. In the context of AI, the Rapporteur explains that the duty of reasonable accommodation includes the obligation to provide "alternative testing and screening tools to accommodate applicants with disabilities in ways that do not restrict their opportunity to use their skills" as well as, more generally, the obligation to use AI "in a way that avoids the discriminatory impact of inaccessible technologies".  
When writing this report in 2021, the Rapporteur noted the lack of dedicated attention paid to the potentially discriminatory impacts of AI on people with disability in national disability rights and accessibility regulation. This is echoed in the British government white paper on AI regulation which highlights "potential gaps in the legal coverage of AI", including to prevent the risks of AI for people with disability: while "discriminatory outcomes that result from the use of AI may contravene the protections set out in the Equality Act 2010", which contains provisions related to accessibility, reasonable accommodations, and anti-discrimination, the Equality Act may not be enough to address the "safety risks specific to AI technologies" (discussed in Chapter 1), which "should be monitored closely" (UK Government, 2023[91]).  
Several of the landmark regulations in the accessibility field in OECD countries pre-date the contemporary large-scale development of AI. One of these landmarks is the 2019 European Accessibility Act (Directive 2019/882), adopted following the ratification of the UN CRPD in the European Union, and which must be implemented in Member States by 2025. The Act requires products and services, in particular digital ones, to be accessible for people with disability. But AI products and services are not at the heart of the Act, which started being discussed "in 2009, when artificial intelligence was not so much talked about" (Placencia Porrero, 2023[83]). The Accessibility Act focuses on "setting the [required] characteristics for products and services (...) to be accessible for persons with disabilities, focusing on the user interface". As explained by Inmaculada Placencia Porrero, one of the main architects of the Act, while ensuring that 
AI is accessible will imply paying attention to data, algorithms, and user interfaces at the same time, "the Accessibility Act is not so much about the first two, especially not about the data" (Placencia Porrero, 2023[83]). As the Act is currently being implemented in national contexts, its effectiveness in protecting people with disability against the risks of bias and inequity of use with respect to AI will need to be assessed in the future.  
Another landmark is the Americans with Disabilities Act (ADA), a civil rights-based41 act enshrining into law the fundamental rights of people with disability in the United States. The Act was passed in 1990 and does not mention artificial intelligence. However, as explained by the United States Equal Employment Opportunity Commission in a guidance document from December 2022 laying out the ways in which the use of AI to assess job applicants and employees could violate the ADA (EEOC, 2022[92]), the Act does contain provisions against some of the risks posed by AI for people with disability. The EEOC identifies three "most common ways that an employer's use of algorithmic decision-making tools could violate the ADA", namely: i) the failure to provide reasonable accommodation to an applicant or an employee with disability necessary to allow them to be evaluated fairly and accurately by an algorithm; ii) the use of a biased algorithm that "intentionally or unintentionally screens out an individual with a disability"; or iii) the use of an algorithm that infringes upon the ADA's restrictions on disability-related inquiries and medical examinations. The guidance also explains that the responsibility to ensure compliance with the ADA still lies with the user/deployer of the tool (i.e., the employer) even when that tool is developed by an external provider.  
Emerging AI regulations42 
In its report, alongside a lack of dedicated attention to AI in disability rights and accessibility regulation, the UN Special Rapporteur also stressed that "no national artificial intelligence strategy was identified that places particular emphasis on the human rights implications for persons with disabilities in artificial intelligence" (Quinn, 2021[15]). However, since that report was published in 2021, several national or regional regulations dedicated to AI have progressed through the legislative process.  
In the European Union, a proposal for an "Artificial Intelligence Act" (the EU AI Act) was approved by the European Parliament in June 2023. This proposal aims to "regulate AI systems made available or used in the EU 27 member states to address risks to safety, health, and fundamental rights" (Salvi del Pero and Verhagen, 2023[65]; European Commission, 2023[62]). It follows a risk-based approach differentiating between AI tools that generate: i) minimal risk; ii) low risk; iii) high risk; and iv) unacceptable risk. It proposes that "high-risk systems" be subjected to "legal requirements relating to risk management, data quality, and data governance, documentation and record keeping, transparency and provision of information to users, human oversight, robustness, accuracy, and security" (Salvi del Pero and Verhagen, 2023[65]). The proposal contains some provisions that aim to prevent disability-based discrimination. As stated in the preamble, the proposal aims to "ensure a high level of protection for the fundamental rights (...) enshrined in the EU Charter of Fundamental Rights" and to "positively affect the rights of a number of special groups" including people with disability. The Act also establishes a list of prohibited applications, including those that "have a significant potential to manipulate persons through subliminal techniques beyond their consciousness or exploit vulnerabilities of specific vulnerable groups such as (...) persons with disabilities". Providers of non-high-risk AI tools are encouraged to adopt voluntary codes of conduct related to various issues including accessibility for people with disability. The Act also explicitly mentions some specific risks that are heightened for people with disability, linked notably to faulty biometric identification algorithms used in employment contexts (e.g., in recruitment, promotion, firing, task assignment, and monitoring) (European Commission, 2023[62]). According to the European Disability Forum, however, reference to the EU Charter of Fundamental Rights and other existing EU laws protecting the rights of people with disability will be "insufficient to protect persons with disabilities from AI-induced harms", as they do not comprehensively cover all areas of life, or because they "were not developed with AI in mind"; thus risks for people with disabilities would be better addressed directly in the Regulation (European Disability Forum, 2021[93]). 
In the United States, the Office of Science and Technology Policy, part of the Executive Office of the President, published "The Blueprint for an AI Bill of Rights" in October 2022 (The White House, 2022[94]). The blueprint is made of five non-binding principles to help shape future policies related to AI and includes some specific disability-related considerations (Salvi del Pero and Verhagen, 2023[65]). Disability is explicitly mentioned as a potential source of algorithmic discrimination in relation to the first principle: "You should not face discrimination by algorithms and systems should be used and designed in an equitable way". This principle is described as creating a duty for "designers, developers, and deployers of automated systems" to take "proactive and continuous measures to protect individuals and communities from algorithmic discrimination", including through "ensuring accessibility for people with disability in design and development". In doing this, designers, developers, and deployers of AI systems should consider "a wide variety of disabilities, adherence to relevant accessibility standards, and user experience research both before and after deployment" (The White House, 2022[94]). Other proposed legislation in the US focused on automated decision-making systems - the Algorithmic Accountability Act of April 2022 (117th Congress (2021-2022), 2022[95]) - also mentions the duty of users of automated decision systems to conduct disability-related impact assessments.  
In Canada, the draft Artificial Intelligence and Data Act (AIDA) (House of Commons of Canada, 2022[96]) introduced in June 2022 proposes to "establish common requirements for the design, development, and use of AI systems, including measures to mitigate risks of physical or psychological harm and biased output, particularly of "high-impact AI systems", and "prohibit certain AI systems that may result in serious harm to individuals or their interests" (Salvi del Pero and Verhagen, 2023[65]). In its initial version, the proposal does not include specific disability considerations.43  
Other existing regulations have indirect implications for AI. This is the case for instance of the EU General 
Data Protection Regulation (GDPR). In particular, as explained by Salvi del Pero and Verhagen (2023[65]),  "the rights to transparent information and communication, as well as rights of access (Art. 12, 13, 15), rectification, erasure and restriction of processing (Art. 16-17)" are designed to protect personal data and foster transparency of data processing, and provide a legal basis to address the risks linked to privacy posed by AI-powered solutions described above. Based on Article 88 which is "specifically targeted at data protection in the employment context" member states could "enact more specific rules to protect employees' personal data". Article 22 gives individuals the right "not to be subject to a decision based solely on automated processing", which, according to some scholars, amounts to prohibiting fully automatic decision-making (Salvi del Pero and Verhagen, 2023[65]), and could limit exposure to risks of discrimination. In short, the GDPR provides a legal basis to address some of the risks in general - yet it does not directly address all the specific risks for people with disability discussed above any more than emerging regulations on AI (European Disability Forum, 2021[93]).  
Regulations are too siloed and solely risk-focused  
Although there are some bridges between AI and disability rights and accessibility regulation, the two are still mostly discussed in different arenas, by different experts. Where bridges are established, they might cover only a part of the intersection of AI and disability rights/accessibility. For instance, the EEOC guidance that explains how the ADA might be interpreted in the AI field is limited to the use of AI in employment contexts, while risks for people with disability are broader and include all AI-powered solutions if they are biased or inaccessible. For instance, as argued in Chapter 1, the development of automated vehicles inaccessible to people with disability would increase the exclusion and discrimination faced by people with disability in transportation and would further constrain their mobility if inaccessible vehicles were to form an increasing share of mainstream transportation options.   
Several interviewees highlighted what they saw as a disconnect between policymakers working on disability rights/accessibility and those working on AI. For instance, HyeongKeun Ji, from the Korean Ministry of Employment and Labour explained that although he works on improving labour market participation for people with disability, he saw "no effort yet [in the Ministry] to improve the market accessibility of the disabled by using AI", adding that "the idea that AI can help employ people with disability has not taken roots yet within the government, at least within the Ministry of Employment and Labour" (Ji, 2023[97]) One policymaker in the field of disability employment interviewed for this report echoed this view, explaining that  
"from a policy standpoint, this is still very new for a lot of people. I think a lot of us are just starting to think about AI and how we can use AI, particularly as an accessibility tool. (...) we're very much at the start of this (...) We [government officials in charge of disability employment policy] don't have a specific mandate related to AI".  
Interviewees highlighted the difficulty of bringing all relevant viewpoints into the policy discussion. For Yonah Welker, "Policymakers live in some kind of silos, and they do not bring all of the stakeholders - technologists, researchers, caregivers, patients, families - together" (Welker, 2023[75]). Welker regrets that attention paid to disability in the emerging EU regulation on AI is still too limited:  
"Disability organisations have been vocal about the necessity to bring more focus to disabilityspecific cases [in discussions about the AI Act] (...) to ensure fairness, transparency, and explainability for these groups, to address silos, negative scenarios and misuse of high-risk systems and prohibition of specific unacceptable-risk systems", which, as discussed in Chapter 1, might be particularly acute for people with disability. However, Welker argues that the disability angle is still not sufficiently covered, with some "truly high-risk scenarios affecting individuals with disabilities" ignored in the list of high-risk AI applications (Welker, 2023[98]).  
Other interviewees stated that the EU AI Act will have to be complemented with specific regulations on the accessibility of AI-powered solutions to properly address risks of e.g. inequity of use for people with disability.  
A second limitation of existing and emerging regulations is that they focus almost exclusively on neutralising risks rather than on overcoming obstacles to seizing opportunities identified in Chapter 2. Talking about emerging policies in the European context, Klaus Höckner from the Austrian Association of Blind and Visually Impaired People explains that "[AI] is sometimes talked about in terms of avoiding the bias, but very rarely in terms of seizing the potential" (Höckner, 2023[90]). More generally, the emerging regulations mentioned above focus on addressing some of the risks posed by AI for people with disability. For instance, while the European Disability Forum called for the EU AI Act to "create appropriate conditions and incentives to develop 'AI for good'", since "AI excellence for persons with disabilities means development of AI-based solutions that can actively contribute to accessibility for and participation of persons with disabilities in society" (European Disability Forum, 2021[93]), the issue of steering AI to seize its potential benefits in the realm of accessibility and disability rights has not yet been part of regulatory discussions, in the EU or elsewhere.  
3.1.2. Most existing and emerging AI standards do not focus specifically on disability  
Faced with the development of AI, several actors have launched initiatives encouraging the development of standards for safe and trustworthy AI in the last few years. For example, the EU-US Trade and Technology Council has created a working group on "technology standards" (EU-US Trade and Technology Council, 2021[99]), while the British government has tasked the Alan Turing Institute with the establishment of global AI standards (Alan Turing Institute, 2021[100]). The EU AI Act calls for standards development to implement its principles. In the United States, the National Institute of Standards and Technology (NIST) is also "establishing benchmarks and developing data and metrics to evaluate AI technologies" and "leading and participating in the development of technical AI standards" (NIST, 2023[101]).  
However, while, as explained in Chapter 1, some risks are specific to people with disability or heightened for them and are unlikely to be dealt with using generalist bias prevention approaches (see also section 1.3.3 below), most efforts to date have led to the production of general standards not specifically focused on disability-inclusive and accessible AI,44 or to roadmaps and frameworks towards the standardisation of AI. For instance, the NIST published a voluntary "AI Risk Management Framework" in January 2023 that aims to "offer a resource to the organisations designing, developing, deploying, or using AI systems to help manage the many risks of AI and promote trustworthy and responsible development and use of AI systems" (NIST, 2023[102]). That framework could be useful to avoid risks linked to disability (which are briefly mentioned when discussing fairness in AI). Yet, it is not specifically focused on AI and does not set out precise standards to abide by in order to avoid discriminating against people with disability. Another NIST publication entitled "Towards a standard for identifying and managing bias in AI" (NIST, 2022[103]) discusses bias against disability in more detail and stresses the limits of traditional bias identification techniques in the case of disability, although whether alternative means of dealing with ableist biases can be conceived remains an open question. In its Artificial Intelligence Standards Roadmap, Standards Australia calls for greater participation and better representation of people with disability in the committees involved in standards definition - a first step in ensuring that standards account for the specific risks faced by people with disability (Standards Australia, 2020[104]). One counter-example might be the upcoming standard on "Accessible and Equitable Artificial Intelligence Systems" developed by Accessible Standards Canada (Accessible Standards Canada, 2023[105]). The draft standard includes a definition of "statistical discrimination" coined by IDRC Director Jutta Treviranus, that specifically mentions people with disability:  "Statistical discrimination is the outcome of the use of statistical reasoning to make decisions. Statistical reasoning assumes that the correct decision is based on the average or majority. People with disability are more than a threshold of standard deviation from the average or mean and have a divergent set of abilities and tend to be outliers in data sets. Given the diverse and variable data characteristics of disability, people with disability cannot reach a sufficient statistical threshold to influence or achieve recognition by AI systems using statistical reasoning" (Treviranus, 2022[22]). 
Even when disability-specific issues are mentioned, however, a common point between these roadmaps to AI standardisation is that they do so uniquely through the risk avoidance angle, even though accessibility standards in AI might also be a way of seizing opportunities. The potential of AI for people with disability is barely touched upon. 
Some of the AI strategies and guidelines developed by government bodies pay more attention to opportunities. For instance, in the United States, the Partnership on Employment & Accessible Technology (PEAT), funded by the Department of Labor, created an "AI and Disability Inclusion Toolkit" for organisations developing, deploying, and using AI. The toolkit contains information about positive use cases of "Equitable AI in the workplace" as well as about "Risks of Hiring Tools"; "AI & Disability Inclusion resources"; and an "Equitable AI Playbook". 
3.1.3. Industry self-regulation efforts and organisational-level strategies to mitigate risks yield limited results  
Industry self-regulation 
Alongside regulations and standards coming from governments or international organisations, Victoria 
Austin, Associate Professor at University College London and Founder of the Global Disability Innovation Hub, highlights the need for industry self-regulation (Austin, 2023[106]). Several examples suggest that the industry has started self-regulating: for instance, the Recruitment and Employment Confederation (REC) collaborated with the UK Centre for Data Ethics and Innovation, an expert government body, to develop a practical guide for recruiters deploying AI-powered recruitment tools, to help them mitigate risks, and maximise opportunities (REC/CDEI, 2021[107]). This guide clearly lays out the different risks of automated hiring algorithms for people with disability, linked to bias and inaccessibility, and suggests ways to mitigate those risks, including through engagement with "groups that represent the interests of people with disability" before using a tool, and, if the tool is used, the provision of reasonable adjustments and alternatives and the creation of feedback channels. Other examples of industry self-regulation include the various initiatives by the Institute of Electrical and Electronics Engineers (IEEE) Standards Association, ranging from the production of AI Ethics and Governance standards,45 training and education programmes for designers, and certification programmes for firms (IEEE SA, 2023[108]), with the stated objective to "ensure that every stakeholder involved in the design and development of autonomous and intelligent systems is educated, trained, and empowered to prioritise ethical considerations so that these technologies are advanced for the benefit of humanity" (IEEE SA, 2023[109]). As argued by Rylin Rodgers, from Microsoft, "The industry is moving faster than regulations. We have AI standards, ethical standards, and we're sharing those with policymakers to help them think about future regulations" (Rodgers, 2023[9]). According to Rogers, this type of self-regulation allows better accommodating the potential trade-offs emerging in the field, for example between the risks attached to facial recognition technology and its importance as an accessibility use case for blind individuals.  
"In our updated AI ethics standards, we state that [facial recognition] has created bias and discrimination and we will not sell facial recognition software for e.g. policing. (...) At the same time, (...) we will continue to pursue its development as an accessibility tool. That's an important nuance because what would it have meant for the blind and low-vision community if the technology world stopped pursuing facial recognition altogether?" (Rodgers, 2023[9]). 
Mitigation approaches by firms and non-profit actors in the field 
Beyond government policies and industry self-regulation, a lot of the mitigation approaches discussed by stakeholders depend on organisations developing and deploying AI tools themselves (which could be firms, public entities, non-profits, etc.). For example, PEAT's Equitable AI Playbook directly encourages these organisations to engage more with people with disability in the design and implementation of AI tools. In particular, it recommends that the developers and deployers of AI pay attention to the representativeness of datasets underlying algorithms and the accessibility of user interfaces; ask vendors about inclusive design and accessibility; and create feedback processes after the tool has been implemented.  
Firms developing and deploying AI have started to create solutions.46 In some cases, these solutions take the form of internal anti-bias processes implemented by companies themselves: for instance, researchers within AT&T conceived and deployed SIFT, standing for "System to Integrate Fairness Transparently", an "operational framework to tackle fairness concerns at different stages of an industry machine learning project workflow" through "identifying potential biases and determining appropriate mitigation strategies in a participatory manner" (Dodwell et al., 2020[110]).47 Another example is IBM AI Fairness 360 toolkit (Trewin, 2018[66]). In other cases, expertise on how to be consciously inclusive when developing AI products is provided by specialised external consultants. For instance, when developing its accessible Chatbot, Zammo consulted the social enterprise Open Inclusion, which specialises in "fuelling design and innovation with more diverse perspectives so that they are more usable, practical, effective, and delightful for more people, specifically thinking about those characteristics being how people move, sense, think, and feel", as explained by its founder Christine Hemphill (Hemphill, 2022[74]). Academics and disability rights organisations also provide resources to encourage developers to take on the challenge. For instance, Raising the Floor International, in collaboration with the University of Maryland Trace Research and Development Centre has created DeveloperSpace, a "one-stop shop" providing elements of accessible codes for various disability categories, from text-to-speech to alternative methods to a mouse pointer to point on a computer, as well as tutorials, and connections between developers and testers, to develop and test digital accessibility solutions (GPII, 2017[111]).  
Another mitigation approach consists of improving the representativeness of data underlying AI algorithms, to make sure they cover people with disability. As discussed in Chapter 1, several initiatives, both from industry and academia are dedicated to collecting data on or about people with disability to improve the representativeness of training datasets (see, e.g. the Speech Accessibility Project, or the VizWiz, Orbit or Exonet datasets). Another initiative by the University of Maryland Trace Research and Development Centre, called "Exploring the role of datasets sourced from people with disability", also aims to improve the representation of people with disability in data underlying AI-powered solutions (Trace RERC, 2023[112]). 
"AI auditing" or "algorithmic auditing" is another, increasingly popular mitigation technique implemented at the organisational level (Salvi del Pero and Verhagen, 2023[65]). This generally consists of "a third-party assessing whether an algorithm, AI system and/or the context of their use align with ethical principles or regulation" and could be extended to cover accessibility and non-discrimination (Salvi del Pero and Verhagen, 2023[65]). Some auditing processes specific to the issue of accessibility and non-discrimination against people with disability have emerged. For instance, since 2023, the non-profit charity "ForHumanity University" which provides online training to independent auditors of AI systems based on audit rules "codifying law and establishing best practices that mitigate risks to humans", is offering a class on Disability Inclusion and Accessibility auditing (ForHumanity, 2023[113]). The advantage of such auditing and certification systems, ensuring that "steps have been taken to reduce exclusion, to make things accessible, to include people with disability throughout the design development phase" is that it avoids "putting the onus on the person with a disability to ensure their rights are being met" which is "exhausting" (Mazrui, 2023[49]). 
Organisations are also developing processes to deal with the risks linked to model errors and imperfect results - although these processes tend to deal with errors in general rather than errors relating to disability in particular. Similarly, technical solutions to the general issue of data protection and privacy-related risks are also used in some of the AI-powered solutions that aim to foster employment of people with disability discussed in this report. For instance, some of the solutions presented in Annex A (e.g. Echo Speech, Orcam's MyEyes, Okeenea's AI-based guiding solution, SolarEar hearing aid etc.) rely on "edge computing" in which most of the data are processed locally on devices to avoid sending personal data to cloud-based servers. 
Limitations of existing mitigation strategies 
Risk mitigation strategies described above face a series of technical and practical limitations. For instance, efforts to improve the representativeness of training datasets to include people with disability are technically bounded. As discussed in Chapter 1, the internal diversity of the disability community means that striving for perfect representation is an elusive goal (Trewin, 2018[66]). Because disability, as explained by the UN Special Rapporteur on the Rights of People with disability, "is a more fluid, heterogenous and nuanced concept" than, e.g. age, "establishing a training data set fully representative of all the diversity of disability is challenging". Yet this challenge is "surmountable", he adds, "and serves to underscore the importance of consultation at the earliest steps of product design" (Quinn, 2021[15]). However, the hope of completely mitigating all biases through perfect datasets is unrealistic when also considering intersections with other aspects of human diversity (e.g. race, ethnicity, gender identity, sexual orientation, etc.): "There are so many different possibilities that you would never be able to design a system that works for everyone in every possible scenario" explains Bill Curtis-Davidson, Co-Director of the Partnership on Employment & Accessible Technology (PEAT) "You're always going to have a scenario where something you didn't account for will happen and go wrong" (Curtis-Davidson, 2023[71]). "Even with full proportional representation there will still be a bias against outliers" adds Jutta Treviranus (Treviranus, 2022[22]). While "you can probably fix 80% of bias, humans are complicated. There's always going to be some of us that don't fit well into the box" agrees (Rodgers, 2023[9]). Thus, while generating more inclusive data is crucial and can help reduce and contain biases, it is unlikely to be sufficient to guarantee that AI is not biased against people with disability.  
Audits and statistical tests for bias also face technical limitations. The first of these limitations is linked to data availability. For instance, testing a CV-sorting algorithm for disability bias implies comparing the proportion of people with disability in the original pile of CVs with the proportion in the list selected by the algorithm - yet applicants might not wish to disclose their disability, and hence the percentage of applicants with a disability might not be known. Indeed, people with disability "strategically choose whether and how to disclose their disabilities" (Bennett and Keyes, 2019[73]). In addition, traditional "auditing mechanisms (e.g. cluster analyses, disparate impact analyses, etc.) used for other characteristics like sex and race don't necessarily work for people with disability", especially for "low incidence groups" (Mazrui, 2023[49]). As explained in the United States EEOC guidance on AI in hiring and disability rights, techniques used in the case of race and sex - such as "[testing the AI tool] in different demographic groups (...) comparing the average results for each group [and modifying the tool] if the average results for one demographic group are less favourable than those of another" -  is likely to be insufficient in the case of disability (EEOC, 2022[92]). Indeed, applying such technique to disability "would not mean that the algorithmic decisionmaking tool could never screen out an individual with a disability. Each disability is unique. An individual may fare poorly on an assessment because of a disability, and be screened out as a result, regardless of how well other individuals with disabilities fare on the assessment" (EEOC, 2022[92]). In other words, "eliminating group discrepancies will not necessarily prevent screen out or the need for reasonable accommodation in [AI] systems. (...) those with disabilities may experience difficulties interacting with AI systems [which] cannot be mitigated by mathematical or software de-biasing approaches" (NIST, 2022[103]). Despite these limitations, efforts to keep testing for biases should be maintained and increased, notably through better accountability and feedback procedures.  Accountability rules often rely on the additional inclusion of a human "in the loop", "to approve a decision" or "on the loop (...) to view and check the decisions being made, in a deliberate attempt to ensure human accountability" (Salvi del Pero and Verhagen, 2023[65]). In practice, however, these terms have no fixed legal meaning and only uncertain effects (Salvi del Pero and Verhagen, 2023[65]).  
Practical limitations to inclusive design and co-design at every stage of the design process include the fact that small firms might lack the resources necessary to engage in it (Banes, 2023[29]). The relatively young age of the field and the fact that knowledge of algorithmic bias is still emerging is another practical difficulty according to AT&T's Susan Mazrui: "We can look at it from a process perspective, we can say 'this tool needs to go through this type of evaluation for accessibility', but we don't know what the precise steps are yet" (Mazrui, 2023[49]).  
Finally, some experts worry that the development of certifications and auditing mechanisms in the field will lead to the development of an "ethical AI industry", in which responsibility will be outsourced by AI producers, and which will perpetuate rather than solve issues. According to IDRC Director Jutta Treviranus, this "AI ethics auditing industry sprouting up will be dependent on the perpetuation of the problem" and will absolve developers from having to "look for a way to address the fundamentals of the problem" (Treviranus, 2022[22]). In the absence of a more specific definition of "what an audit should look like, who should conduct the audit, and what disclosure to the auditor and public should look like", "vendor-sponsored audits could "rubber-stamp" their own technology (Salvi del Pero and Verhagen, 2023[65]).  
3.2. Going forward: what can governments do? 
The above review of existing and emerging policies suggests that countries still lack policies to efficiently address the risks posed by AI for people with disability, while policies designed to encourage the development of AI-powered solutions fostering employment of people with disability are largely missing. The following sub-sections lay out proposals emerging from interviews with stakeholders as to what governments could do to helps address the risks and help seize the opportunities of AI. 
3.2.1. How can governments help address the risks?  
Most existing, or emerging regulations and standards so far focus on risk prevention. Yet, more could be done and interviewees generally agree with the UN Special Rapporteur on the Rights of People with disability on the need for stronger government intervention to "ensure that national artificial intelligence regulations include human rights principles and standards and an explicit prohibition against discriminatory and harmful uses or impacts of artificial intelligence in relation to persons with disabilities" (Quinn, 2021[15]). When it comes to addressing the risks, several interviewees insist on the need for a "stop-gap approach", in a context where "changes are happening fast and it is difficult to identify proactively whether someone will be excluded because of a disability" (Mazrui, 2023[49]). Several participants called for a risk-based approach, such as the one used in the proposed EU AI Act. European Disability Forum AI policy officer Kave Noori argued that "[we should] raise our expectations of when a product is safe to release in the market (...) for AI systems that actually decide who gets a job and that type of thing" (Noori, 2023[41]). Similarly, Nathan Cunningham, from the United States Department of Labor's Office of Disability Employment Policy (ODEP) argued that "The risk tolerance depends on the way the tool is being used'' (Cunningham, 2023[114]) - with tools assisting people to do their jobs requiring a different level of scrutiny than tools used to decide hirings and promotions. The EU AI Act encourages the establishment of "AI regulatory sandboxes" to develop and test AI systems in a controlled environment before they are put on the market (Salvi del Pero and Verhagen, 2023[65]); paying specific attention to disability-related risks within these regulatory sandboxes would be a promising way of avoiding harm.  
Some interviewees argue that efficiently preventing risks implies generalising liability systems in which responsibility for harm generated by AI products (including in the form of discrimination48) lies with companies deploying and using AI (for instance, firms buying and using a hiring algorithm) - i.e., generalising "buyer-beware" environments.49 This would lead AI deployers to "become much more cautious" and to require "evidence that it's been proven safe for marginalised groups", including people with disability before they use it (Scott-Parker, 2022[64]). It would also in turn incentivise developers to address risks early on before biased algorithms are put out on the market. Innovators would have a commercial incentive to make sure that AI products are accessible and interoperable by default, and that accessible and responsive customer services are in place in case of issues (Treviranus, 2022[22]). Beyond consumer protection regulations, interviewees argue that this could also take the form of procurement guidance for buyers of AI. Again, this is aligned with recommendations to States in the UN Special Rapporteur report, including that they "ensure that human rights due diligence legislation is comprehensive and inclusive of disability [and that] it is conducted by business when artificial intelligence systems are acquired, developed, deployed and operated", and that they "adhere to disability-inclusive public procurement standards" (Quinn, 2021[15]) 
Interviewees also insist on the importance of setting the right standards to ensure that the development of AI does not harm people with disability. Because AI is powerful and fast developing, "the ability for a designer (...) to absorb the knowledge [about how people with disability are affected] fast enough" is limited. In this context, it is "critically important" that clear and up-to-date standards are in place to "crystallise knowledge" (Hemphill, 2022[74]). Interviewees evoked various types of standards to make sure that AI-powered solutions are "certified accessible before they can be commercialised" (Jung, 2023[70]), spanning those setting clear accessibility requirements for user interfaces (Placencia Porrero, 2023[83]), as well as standards about the presence of persons with disabilities within AI development teams (Sharma, 2023[46]). Importantly, interviewees insist on the need to have updating mechanisms to allow standards to remain relevant given the fast-paced advance of technology: "standards are only as good as time will allow them to be (...) the advancements are so quick that by the time the standards are established, they are just the minimum bar" (Tanis, 2023[28]). One way of countering this recurring obsolescence is to have more "process-oriented" standards, ensuring that developers have followed certain steps, rather than "a very cut-and-dry boundary" definition about what is accessible and what is not, because these "just become outdated so quickly" (Tanis, 2023[28]).  
Interviewees would also welcome more guidance regarding the application of existing regulations to the case of AI - on the model of the EEOC guidelines mentioned above which clarified the implications of the Americans with Disabilities Act for AI-powered hiring tools. Guidance and support in the roll-out and implementation of emerging regulations is also called for: "the policy framework [on AI and accessibility] can exist. But how it's being adopted and used by organisations is really critical. We could put more thought into what the rollout aspect looks like" (Cunningham, 2023[114]).  
Better systems of quality control and enforcement, ensuring that stakeholders comply with existing accessibility regulations (and are sanctioned if they do not) are another avenue to consider according to interviewees. As explained by accessibility specialist Larry Goldberg, many accessibility principles "are already required by law. But then the question is enforcement (...) if there was a stated quality threshold, even if minimally enforced, it would at least raise the issue to innovators who get excited about their technology and rush it out" (Goldberg, 2023[88]). This is aligned with Kansas University Professor Shea Tanis's argument that "policies are only good with some oversight. We have a lot of policies on the books that are fantastic policies, but there is no oversight of those policies to ensure that they actually materialise. And so there has to be accountability built-in" (Tanis, 2023[28]). Unions and other bodies representing workers may play an important role in enforcing AI regulations (OECD, 2023[115]).  
Because of the technical limits of bias mitigation techniques, discussed above, addressing risks could also imply steering the development of AI towards solutions that do not depend on representative data to avoid bias - which is more often the case for solutions that aim to improve the accessibility of the environment, compared to disability-centred solutions.  
Finally, according to Tanis, part of the solution to addressing AI-related risks for people with disability is to educate users: "The solution is helping the users of AI to understand the risks, so they can then make informed decisions and help improve the outcomes." She regrets that initiatives to foster AI literacy are still lacking (Tanis, 2023[28]), even though they could help avoid the risks, as well as foster greater adoption of AI-powered solutions among those who would benefit from them.  
3.2.2. How can policymakers help seize the opportunities?  
Policies incentivising the development of AI-powered solutions fostering employment of people with disability are currently lacking. Yet, these policies are essential to make the most of AI to reduce the disability employment gap. In addition to setting up safeguards, governments can act as catalysts for the development of solutions fostering employment for people with disability. As explained by Inmaculada Placencia Porrero, policymakers must consider both "how [regulatory objects] can impact persons with disabilities" as well as "how they can benefit them" (Placencia Porrero, 2023[83]). Similarly, standard setting is not only about protecting against risks, but also about fostering inclusive innovation. For example, accessibility specialist Larry Goldberg recalled the influence of governments' standard-setting effort on the development of the closed captioning field: "Too often, you'll hear that bringing the government in just slows everything down", he explains. "But what NIST [the United States National Institute for Science and Technology, a standard-setting organisation] has done over the years is very important" (Goldberg, 2023[88]). Building on the identification of obstacles encountered by innovators discussed in Chapter 2, this section puts forward a series of potential avenues for policy action that emerged from the interviews.  
Fund research and development into commercial AI applications50  
The lack of private funding for research on AI fostering employment of people with disability - in particular, the lack of patient capital to fund early-phase research as well as prototyping and go-to-market phases - clearly surfaced in interviews, as explained in Chapter 2. This is an issue particularly for small firms, startups and university research labs. Relatedly, some interviewees call for the development of governmentbacked venture capital streams for innovation in that domain: "If there was some sort of governmentbacked investment capital based on policy that could identify good technology with long term commercial viability", explain Liopa's founder Richard McConnell, "that would really help" (McConnell, 2022[76]). Such a system would allow attributing money "based on the fact that the technology is applicable to a certain part of the population and would be commercially viable in the long term" (McConnell, 2022[76]). Government-backed venture capital streams to finance innovations in AI have already been implemented in some contexts: for instance, Italy recently introduced a state-backed fund to promote AI (Fonte, 2023[116]). The innovation here would be to earmark such funds for projects that have the potential to reduce the disability employment gap. More generally, governments could incentivise the development of more gap funding streams51 dedicated to supporting "AI for accessibility" projects successfully transition from the research to the commercialisation phase.   
In addition, public funding streams are necessary for socially beneficial innovations that are unlikely to reach profitability because they address niche issues with small customer bases. In this regard, interviewees call for more public grants such as those provided by the National Science Foundation in the United States,52 or the Horizon 2020 programme in the European Union, with some potentially simplified application procedures to avoid deterring smaller start-ups with limited resources from applying. Beyond grants, other forms of funding earmarked for "AI for accessibility" projects already exist and could be developed further, such as PhD scholarships,53 or incubation programmes dedicated to AI solutions fostering employment of people with disability. Bong-Keun Jung, from Seoul National University, also advocates for the creation of dedicated public research institutes focused on these solutions, arguing that the research outputs of these institutes "could be more smoothly transferred to the industry" (Jung, 2023[70]).  
To ensure the relevance of publicly funded solutions, and to favour their adoption by end users, funding mechanisms could also be adapted: for instance, Shea Tanis regrets that "the funding always goes to developers, engineers, who then identify partners in the disability field, rather than the money going to advocacy groups who would then select developers". If, on the contrary, "advocacy groups are the ones driving the process and identifying needs (...) the power dynamic and the outcome change significantly" (Tanis, 2023[28]). 
Beyond commercial applications, interviewees also call for more public funding for fundamental AI research in the public sector (Favreau, 2022[26]). According to a researcher in an industry AI research lab interviewed for this project, "One of the most important things is precisely that this research should be public (...) I think it's important to have public and open-source research because that's what allows us not to be dependent on one company". 
Help develop sustainable business models 
Related to funding issues, another hurdle that emerged in Chapter 2 is the difficulty for innovators to find sustainable business models. On this front, policy avenues evoked during the interviews cluster around two poles: governments subsidising a market with public funding through reimbursement policies, and governments creating a privately funded market through regulatory obligations. 
In many OECD countries, governments have some direct and/or indirect reimbursement policies in place covering assistive technology devices for people with disability. Public reimbursement mechanisms subsidising access to assistive technology for people with disability are one of the ways through which innovators can reach sustainability, through the creation of a publicly subsidised market. However, as explained in Chapter 2, many of the emerging AI-powered solutions discussed in this report might not yet be approved for reimbursement, and interviewees insisted on the need to update the lists of reimbursed solutions to include AI-powered solutions fostering employment of people with disability (both specialised solutions but also mainstream ones). For accessibility specialist David Banes, governments need to  
"rethink what they mean by assistive technology" and to "shift away from the idea that assistive technology is a device or a product, and towards the concept that assistive technology is a feature or function. (...) Because what we're interested in is not 'is it a physical device', but does it do what I want it to do?" (Banes, 2023[29]).  
Similarly, GDI Hub founder Victoria Austin argues that "the restrictive definition of what constitutes assistive technology and is therefore open to reimbursement should be updated". "Instead of a list of very technical specific devices in a World Health Organisation catalogue", these policies should include "technology which assists all of us to do lots of things, including some disabled people to do specific activities" (Austin, 2023[106]). As explained by Haydn Hammersley from the European Disability Forum,  
"the list of things that are eligible for reimbursement and subsidies has always been something that has had to be regularly updated". "It's just important for governments to be aware [of these transformations of the traditional field of assistive technology] and to ensure that the list of things and the scope of things that are subsidised for the workplace are regularly updated and new solutions are included if they're useful" (Hammersley, 2023[48]).  
Pathways to get new devices and/or solutions reimbursed could also be simplified (Steil, BullingerHoffmann and André, 2023[117]). As explained in Chapter 2, these processes tend to be long and complicated, in particular for small innovators with limited resources. Having "a bit of an overview of what can be done in terms of reimbursement for solutions fostering accessibility, with perhaps some simpler rules, some better-defined frameworks" (Fabien, 2022[77]) was deemed promising by innovators interviewed. "If the technology truly can be shown to be helpful and is requested by people with disability" argues accessibility specialist Larry Goldberg, "there should be a faster path to getting it into people's hands and reimbursed" (Goldberg, 2023[88]). In that regard, one suggestion would be to move to an "escalated model of reimbursement", whereby, for technologies under a certain price threshold, users would not need prior approval before reimbursement, but would be free to try and choose the tool that is working for them. Examples of such models include the Australian National Disability Insurance Scheme (NDIS),54 or the Assistive Technology passport, with "funding models based upon direct payments and the principles of self-determination" (Banes, 2022[118]). According to David Banes, these models challenge the "underlying value in many models of assistive technology (AT) provision (...) that professionals know about AT while potential users do not" (Banes, 2023[29]). This notion, he argues, has been largely challenged by the development of digital assistive technology and the pervasive uptake of smartphones and social media, which together have democratised access to and provision of information on available solutions for users with disabilities. Websites such as the Global Accessibility Reporting Initiative (GARI, 2023[119]), the Global Public Inclusive Infrastructure's Unified Listing (GPII, 2023[120]), as well as some AI-powered recommendation algorithms listed in Annex A,55 also facilitate the adoption of models or reimbursement allowing for greater choice for users. The reduction in prices, discussed in Chapter 1, linked to the development of digital (and AI-powered) assistive technology and to the development of accessible mainstream solutions also encourages the "growth of models of self-determination in choice-making from a range of options available" and decreases the need for intermediary professional gatekeepers (Banes, 2022[118]).  
Governments could also support the development of sustainable business models for AI-powered solutions fostering employment of people with disability through the more systematic inclusion of accessibility clauses in public procurements, and in the requirements attached to access to public funding.56 Interviewees identify a significant margin for improvement there: as explained by Rylin Rodgers from Microsoft, "Too much of what the [US] federal government is buying in the digital space isn't meeting their own standards" (Rodgers, 2023[9]). Similarly, interviewees call for the systematic introduction of an accessibility clause to access public subsidies:57 "I think there should be a clause for accessibility like there is one for gender, or sustainability" (Höckner, 2023[90]). For Kamran Mallick, from Disability Rights UK, governments should ensure that "inclusiveness is within the requirements" for research funding and that applicants must demonstrate how they intend to design their project inclusively. Such policies could be modelled on what has been done on gender: "Governments talk a lot about, for example, women in technology (...) but they haven't done the same with disability" (Mallick, 2023[43]). 
Interviewees also point to the role of governments as legislators to support the development of sustainable private markets for AI-powered accessibility-enhancing solutions.58 For instance, Our Ability funder John Robinson attributes the increase in employer demand to access Our Ability's pool of candidates with disabilities - and hence, the creation of a sustainable market for the alternative job matching start-up - to the enactment of sections 503 and 508 of the Rehabilitation Act in the United States, which created a minimum threshold of 7% of employees with disabilities for federal contractors and implemented digital accessibility requirements.  
"What we have seen since these sections have been enacted is more requests to us to work towards those numbers. What we would like to see is those types of policies continue to grow because they do have a positive effect. We would like to see these policies remain and grow and expand, which will open the opportunities for individuals with disabilities" (Robinson, 2022[87]).  
Similarly, Olivier Jeannel, founder of RogerVoice, the French firm offering phone captioning services, explains that the enactment of  the 2016 "Loi pour une République Numérique" [Law for a Digital Republic] mandating phone accessibility for large firms, administrations, and phone operators was "life-saving" as it "opened the way for B-to-B funding" (Jeannel, 2022[38]). Thus,  
"legislation is very important", according to Jeannel. "Relying on compliance versus relying on corporate social responsibility and private initiatives to develop accessibility-related businesses was a huge disappointment, but I now believe that accessibility does not progress without a law creating requirements."  This type of regulatory obligations also send a positive signal to private investors, according to Jeannel: "When business angels understand that there is a market financed by large firms and administrations because it is compulsory, they are ready to invest and support an entrepreneur offering a certified service" (Jeannel, 2022[38]). This is confirmed by employers interviewed, who must comply with accessibility requirements related to their employees. For instance, Christine Hamot from TotalEnergies explains that the firm's attention to accessibility  
"came with legislation and regulatory constraints (...) since 2019 in France, firms with a revenue higher than 250 million euros are mandated to deal with the issue, or they risk financial penalties. As a corollary to these legal obligations, consideration of the need for universal accessibility in corporate social responsibility issues also gradually increased. Legal requirements are forcing changes, and these are fueling internal reflection and innovation". (Hamot, 2023[44]).  
A similar dynamic is identified among providers of mainstream services who must make these accessible to comply with rules - thereby opening market opportunities in the accessibility field. For instance, one interviewee working in the disability policy field recalls the case of the development of wireless technology. Initially, the technology was not accessible, "until governments stepped in and said to providers, 'you have to make it accessible'. And things became possible (...) I think with AI, we're in the same situation right now". 
Facilitate the production of accessibility-relevant data59 
Data is a prominent technical obstacle to reaping the benefits of AI in the accessibility field. In that regard, interviewees mention the role of governments in providing public datasets. For instance, governments could offer financial support to the creation of inclusive datasets focused on people with disability and their needs, who have tended to be excluded from publicly available datasets. Doing this however might require reviewing and fine-tuning some of the data and privacy protection regulations currently in place, which, as explained in Chapter 2, may in some cases prevent the collection of data necessary to the development of some solutions fostering employment of people with disability, or to engage in bias testing. Some of the researchers interviewed called on governments to  
"better strike the balance between protecting against misuse of data but also opening up some of the bottlenecks for companies and research teams", for instance through convening stakeholders to arrive at "something that's much more functional for the communities that are impacted and the companies or the research teams that are wanting to do something useful" (McDonald, 2022[81]).  
Without reviewing data protection regulations, however, governments could already do a lot by producing or financing the production of accessibility-relevant data about, e.g. the environment, which are not necessarily sensitive individual data (Placencia Porrero, 2023[83]). For instance, data necessary to train accessible navigation algorithms (description of streets, roads, etc.) are not personal data and therefore not necessarily sensitive.   
Governments could also mandate other actors, such as employers, to collect data about people with disability. This could be done in collaboration with social partners and would allow better monitoring the disability employment gap and policies aimed at closing it. In many cases, employers do not have data about the prevalence of disability in their own workforce. Victoria Wass, from the University of Cardiff, suggests that governments could create compulsory disability reporting in firms (Wass, 2023[47]), on the model of the compulsory gender reporting in place in several OECD countries (OECD, 2023[121]). Legislative intervention could also mandate the collection of data specifically relevant to accessibility. For example, in France, the 2019 Loi d'Orientation des Mobilités (LOM) [Mobility Orientation law] introduced an obligation for local authorities to create databases about the accessibility of roads and transport systems. "There had been a European regulation mandating the sharing of accessibility data, but with no obligation to create the data, so it was an empty box", explains Muriel Larrouy, from the Ministerial delegation to accessibility in the French Ministry of Ecological Transition and Territorial Cohesion, who worked on the law.  
"Since 2019, local authorities in charge of roads and transport operators have to create standardised databases on accessibility in roads and transport systems, the goal being to feed into both mainstream itinerary calculators and specialised applications for people with disability" (Larrouy, 2022[27]).  
In this case, the law mandating data collection also spurred solutions using AI to collect and analyse the data in an efficient manner.60,61 
Interviewees also call on governments to foster collaboration and resource-sharing between actors who might need access to the same kind of data to develop solutions. Governments could help foster the development of AI-powered solutions fostering employment of people with disability by providing public spaces for knowledge sharing amongst stakeholders in the field, i.e., "places where people working on similar innovations can come together and learn at a faster rate" (Hemphill, 2022[74]). For instance, JeanMarie Favreau, from Université Clermont Auvergne, explains that when it comes to using AI to produce or use accessibility data to foster mobility among people with disability, "there must be several dozen firms which internally can [do that in France], but they are small and scattered. They have the same needs and objectives (...) but they are competing in the same call for tenders".62 One idea, he suggests, would be to "create a place federating these different actors". "Instead of everyone developing its own small thing, everyone would pull resources together " (Favreau, 2022[26]). Such a collaborative logic is also at the heart of the Speech Accessibility Project, according to its initiator Mark Hasegawa-Johnson  
"I would like to have this dataset available to anyone who has a good idea for improving the science or the technology or the consumer products for people with disability, forever. (...) The University of Illinois will be the owner of the data and we will have the right to license the data to other people".  
In this model future researchers would present their research proposal to a committee in charge of ensuring that research goals are aligned with those that originally motivated the data collection; data use agreements will protect data privacy in the future (Hasegawa Johnson, 2022[82]). This open-source logic could apply not just to data collection, but also to algorithms, and foster the generalisation of inclusive algorithms. This is the idea behind the DeveloperSpace initiative already mentioned above - an opensource repository of accessible codes lowering the cost of building accessible algorithms.  
Foster the discoverability of accessibility-enhancing solutions 
Discoverability of innovations - or lack thereof - was identified in Chapter 2 as a key obstacle to making the most of AI to close the disability employment gap. Interviewees suggest that having a "public policy of communication around existing solutions" could help in that regard (Jeannel, 2022[38]). One suggestion was to have an official certification mechanism establishing quality standards, and a centralised repository of innovations meeting these quality standards, to provide visibility to innovations and facilitate user choice. "Something like a certification or a label, or a catalogue of approved assistive technologies that abide by a charter. That would help users, telling them that the technology has been tested and validated, with correct standards, following specific publicly approved criteria" (Cagnon, 2023[30]). Employers and social partners looking for assistive technology solutions could refer to this officially approved repository for workplace accommodation, which otherwise is akin to "chasing a needle in a stack of hay", according to TotalEnergies's Celine Cagnon, "even for firms with means like TotalEnergies" (Cagnon, 2023[30]). In addition, such a certification mechanism would help educate actors traditionally buying assistive technology on behalf of final users - such as insurance companies, social security administrations, disability rights associations, etc. This would also be beneficial to technology providers who would be able to label their solutions and gain visibility, explains Jonathan Parsy from TotalEnergies, who oversees digital accessibility in the firm. When "putting out tenders and selecting providers, buyers could focus on solutions that abide by regulations and are accessible. If there was a recognition of the efforts from these providers, I think everyone would win" (Parsy, 2023[122]).  
Address human resource challenges  
One of the biggest barriers identified by most interviewees, is the lack of user engagement in AI product design. This limits the relevance of solutions and their adoption by people with disability. According to disability policy expert Henry Claypool, engaging in inclusive AI design "requires people with lived experience of disability. I don't know if deep scientific knowledge of disability experience is possible without understanding the discrimination that is so subtly encountered in the dominant population sometimes" (Claypool, 2023[85]).  
A frequently mentioned solution to this challenge is to improve the representation of people with disability at all stages of the innovation process. For Nathan Cunningham from the US Office of Disability Employment Policy, "good equitable AI practices do require people with disability to be involved at every stage" (Cunningham, 2023[114]). Taking blindness as an example, Donal Fitzpatrick from the Irish Centre for Excellence in Universal Design explained that "sighted people shouldn't be given ownership of blind persons' needs. Involving people with disability in your user base, in code design processes, etc. is so important" (Fitzpatrick, 2023[68]). Similarly, Yonah Welker argues that "You can't develop technologies which address neurodivergent individuals without such individuals in your team, in your board, in your resource group" (Welker, 2023[75]). Further, Disability Rights UK CEO Kamran Mallick explains that "if nondisabled people design systems, they will often naturally create barriers for disabled people. Whereas if we get disabled people in those spaces to design inclusively, you naturally get better outcomes because of the diversity of experience and the different way of looking at a problem" (Mallick, 2023[43]). This means that disability representation in product development teams is particularly important: "We need to get those who understand accessibility thoroughly with people who understand the development cycles of AI in the same room" (Mazrui, 2023[49]). Although this might include hiring engineers with disabilities, disability representation could be improved beyond that. As explained by Henry Claypool, "Designing an accessible algorithm as part of a team doesn't require a computer science degree at all. It requires you to think and understand the disability experience and to contextualise it with a team of people working to solve a set of problems" (Claypool, 2023[85]). 
Governments could help address the lack of diversity in product development teams. For instance, one suggestion emerging from the interviews is the creation of "metrics, established by companies and monitored perhaps even by government entities" on disability representation, including in "the key jobs, the decision-making jobs, building algorithms, instead of just being hired to do other administrative tasks and count towards the hiring goals for diversity" (Claypool, 2023[85]). Another suggestion was to better tie public funding for accessibility-oriented research to the inclusion of people with disability, to encourage better representation and more user engagement (Fitzpatrick, 2023[68]). Governments could also, as recommended in the report from the UN Special Rapporteur on the Rights of People with disability, support capacity-building among disability rights organisations to help them to be more involved in the development and monitoring of AI alongside innovators (Quinn, 2021[15]). Finally, governments could help improve disability representation in the field, and help accessibility issues to be considered systematically in AI design, by facilitating collaboration between representative organisations and the industry. In that regard, the strategy adopted by Disability Rights UK, which physically relocated its offices inside an innovation hub for tech start-ups, might be a source of inspiration. Kamran Mallick explains that they "moved Disability Rights UK here because we want to try and influence start-up companies (...) to bring in that idea of inclusive design (...) and then we're working with universities to look at how we get more disabled people into this space" (Mallick, 2023[43]). 
Making the most of AI to reduce the disability employment gap will also entail working with universities to "create an academic and professional pipeline for students, scholars and designers" with disabilities to work in AI (Claypool et al., 2021[2]), as well as rethinking curricula (Scott-Parker, 2022[64]). The CEO of a firm using AI to produce an accessibility solution, interviewed for this research, argues that "AI-focused training programmes need to be developed even more, because they'll become vital in a few years". 
Interviewees insist on the importance of rethinking computer science training to include modules on user experience design, human-computer interactions, and accessibility. Bong-Keun Jung, from Seoul National University, calls on governments to create "specific education programmes on AI for people with disability, with support from the university sector as well as the industry" (Jung, 2023[70]). The Teach Access initiative (TeachAccess, 2023[123]) is an example of a project that aims to "infuse accessibility principles into mainstream courses" (Miller-Merrell, Goldberg and Sonka, 2018[124]). Led in partnership by actors in academia and the tech industry, the project aims to sensitise developers to accessibility issues, and to prepare "designers, engineers, and researchers to think and build future technologies inclusively". Through Teach Access, accessibility specialists in tech companies collaborate with computer science and innovation design academic programs to "better prepare students to address the needs of diverse populations" (Miller-Merrell, Goldberg and Sonka, 2018[124]).63  
This type of initiative might provide a solution to two different obstacles at once: the lack of attention paid to disability issues in mainstream AI - and related missed opportunities and exclusion risks - and the difficulty of firms specialising in AI for accessibility to recruit AI engineers. On that last point, the CEO of a firm using AI to produce an accessibility solution, interviewed for this research, calls for more cooperations between universities and firms in the "AI for good sector", to help attract candidates: "maybe if we were more present within training programmes, we'd manage to attract more talents, showcasing what we do".  
Promote better design practices 
Another avenue of policy action, related to both curricula update and improving disability representation, is the promotion of better design practices among innovators. One recurring concept in interviews was that of universal design, i.e., "the design and composition of an environment so that it can be accessed, understood, and used to the greatest extent possible by all people regardless of their age, size, ability or disability. An environment (or any building, product, or service in that environment) should be designed to meet the needs of all people who wish to use it" (Center for Excellence in Universal Design, 2023[125]). Other interviewees put forward the concept of inclusive design, which aims to include as big a diversity of stakeholders as possible at each stage of the design process, beyond "top-and-tail consultations of some groups" (Hemphill, 2022[74]). Jutta Treviranus from OCAD University's Inclusive Design Research Center uses the idea of edge-in design, which "unlike other notions that create this idea of full accessibility by virtue of a static set of guidelines or checkpoints", does not aim for full accessibility, which is  
"not possible because inevitably we've left somebody out. Instead, we need to constantly think about who is now facing a barrier", knowing that "things change and there are new barriers that are emerging all the time" (Treviranus, 2022[22]). The idea behind edge-in design is to "start from the person the most excluded from the current system, and work towards including them, to proactively ensure that emerging systems are designed to include everybody from the start. This 'most excluded' benchmark will change at each intervention, so this goes beyond a static set of guidelines or checkpoints for accessibility, the design needs to be flexible enough to include those previously excluded, as exclusions surface" (Treviranus, 2022[22]).64  
Accessibility specialists explain that these design practices have built-in incentives for innovators: these practices help detect risks early in the innovation process, they help build more adaptable and dynamically resilient products, and they help save costs in the long run (Treviranus, 2022[22]). Universal design is described as "a fundamental condition of good design. If an environment is accessible, usable, convenient and a pleasure to use, everyone benefits" (Center for Excellence in Universal Design, 2023[125]). In other words, "If you design for extreme users, systems work better for everyone" (Scott-Parker, 2022[64]) - see also Steil et al. (2023[117]). Designing inclusively might also help with the discoverability issue discussed earlier, since it means that in practice accessibility features are integrated by default. For example, as explained by Melissa Moran, if the image recognition solution provided by Google Lookout is integrated in Android phones' camera application, or preloaded into the accessibility settings, users don't have to download a separate application (Moran, 2022[35]). 
Here again, public policy might be helpful to encourage the take-up of these design practices and to encourage their inclusion into AI engineers' training. This could be done through a better enforcement of existing standards: for instance, the European Disability Forum calls on European governments to "promote the use of the European Standard EN 17161 on 'Design for All - Accessibility following a Design for All approach in products, goods and services - Extending the range of users'" (European Disability Forum, 2021[93]). This could also be done through financial and/or regulatory incentives encouraging user engagement and co-design, particularly for small firms with limited resources who might find it difficult to engage with the breadth of disability (Claypool, 2023[85]). Well-designed regulatory incentives could encourage mainstream companies to innovate for all, including people with disability, by following certain design principles. On that front, policies could be designed to encourage technology transfers between mainstream technology and accessibility-related applications of these technologies. According to AT&T's Susan Mazrui, when it comes to mainstream AI, "we're missing opportunities that could be extraordinarily beneficial. The work that's done on automating carts in warehouses could be incredible for people who are blind and/or in wheelchairs. We need to be able to transfer that technology as well" (Mazrui, 2023[49]). One idea suggested by Mazrui revolves around using patent regulation to encourage innovators to explain how their innovation could be beneficial to people with disability. "You are introducing a new technology to the market: what are the social benefits, whether it's disability or otherwise?" (Mazrui, 2023[49]).  
Orchestrate the better use of AI to help close the disability employment gap 
Finally, interviewees converged on the need for better coordination between both policies, on the one hand, and stakeholders, on the other. To make the most of AI to close the disability employment gap, they argue that governments could provide this overview and increase the relevance of scattered policies and stakeholders' initiatives.  
AI-powered solutions do not exist in a vacuum but need to fit into a pre-existing ecosystem of policies, actors, and practices. Governments could help ensure that this ecosystem is fit for purpose - for instance, by ensuring that reimbursement policies or workplace accommodation rules are flexible enough to include emerging solutions, or that government officials and health specialists supporting people with disability are adequately trained about these new technologies. Another element is ensuring that infrastructure is fit for purpose. For instance, most of the solutions discussed throughout this report are dependent on the existence of a large, reliable coverage broadband. This means that policies fostering equal access to the internet for people with disability are part of the arsenal of policy actions through which governments can help "make the most of AI for people with disability" (Cunningham, 2023[114]). 
Most interviewees also agreed that seizing the potential of AI called for increased cooperation between different kinds of actors. Governments' over-arching position means that they could take on the task of coordinating stakeholders. As Muriel Larrouy, from the Ministerial delegation to accessibility in the French Ministry of Ecological Transition and Territorial Cohesion recalls, her team brought stakeholders together in order to create a new common language to ensure interoperability between databases describing accessibility-relevant mobility features: "We had working groups with every type of actor: disability associations, people used to collecting transportation data, start-ups that were already specialised in the collection of accessibility data, a really mixed group to take into account all the viewpoints" (Larrouy, 2022[27]). Another example is that of the Partnership on Employment & Accessible Technology (PEAT), already mentioned above. PEAT is funded by the Office of Disability Employment Policy (ODEP) in the United States' Department of Labor "to foster collaborations in the technology space that build inclusive workplaces for people with disability". As explained by its co-director Bill Curtis-Davidson, "With PEAT, we convene the community to foster collaborations that make emerging workplace technologies accessible and support employers in using inclusively designed technologies to engage the skills of employees with disabilities" (Curtis-Davidson, 2023[71]). ODEP also plays that convening role: as explained by Nathan 
Cunningham, Senior Technology Policy Advisor at ODEP,  
"Not being a regulatory compliance agency is sometimes to our benefit in being able to meet with the private sector, to meet with disability communities, because we are not the ones with the stick at the end of the day, not the ones that they might be a little bit wary of. We find that very useful in our convenings and conversations". The same is true, he adds, "with regulators inside the government: we're able to work between them in some sense, to bring parties together in a productive way" (Cunningham, 2023[114]).  
This capacity of governments to provide the bird's eye view was summed up nicely by one policymaker in the field of disability employment interviewed for this report:  
"As policymakers", he explained, "if we see this potential for AI, maybe that's a role that we can play a part in, bringing [the world of AI and that of accessibility and disability rights advocacy] together, creating those linkages between experts in AI and experts in disability. Governments have a convener role, they can bring different people together".  
This was echoed by Muriel Larrouy: having governments take-up more of that coordinating role would help seize the opportunities of AI for people with disability. For instance, she explained that  
"The organisation of a working group gathering all actors using AI to collect, treat and use data about roads and transportation", from national research institutes to start-ups, "to cumulate their experience, learn from them, and enhance efforts on that front", would be helpful to the realisation of her policy objective (Larrouy, 2022[27]). "But for this you need dedicated staff, and we are not enough. What would be useful would be more resources for government agencies to be able to organise efficient experience and practices sharing among actors working on the same issues" (Larrouy, 2022[27]).  
 

References 
 
117th Congress (2021-2022) (2022), Algorithmic Accountability Act of 2022, S.3572, https://www.congress.gov/bill/117th-congress/senate-bill/3572. [93] Accessible Standards Canada (2023), "CAN-ASC-6.2: Accessible and Equitable Artificial Intelligence Systems - Notice of Intent", Accessible Canada, https://accessible.canada.ca/creating-accessibility-standards/can-asc-62-notice-intent. [103] aira.io (2023), , https://aira.io/. [141] Ajunwa, I. (2016), "Hiring by Algorithm", SSRN Electronic Journal, https://doi.org/10.2139/ssrn.2746078. [18] Alan Turing Institute (2021), New UK initiative to shape global standards for Artificial Intelligence, https://www.turing.ac.uk/news/new-uk-initiative-shape-global-standards-artificial-intelligence. [98] Allen QC, R. and D. Masters (2020), Regulating for an equal AI: a new role for equality bodies. Meeting the new challenges to equality and non-discrimination from increased digitisation and the use of Artificial Intelligence, https://equineteurope.org/wpcontent/uploads/2020/06/ai_report_digital.pdf. [10] Atleson, M. (2023), "Keep your AI claims in check", FTC Business blog, https://www.ftc.gov/business-guidance/blog/2023/02/keep-your-ai-claims-check. [48] Austin, V. (2023), Interview with Victoria Austin (Global Disability Innovation Hub). [104] Australian Human Rights Commission (2020), Using artificial intelligence to make decisions: Adressing the problem of algorithmic bias, https://humanrights.gov.au/sites/default/files/document/publication/ahrc_technical_paper_alg orithmic_bias_2020.pdf. [11] Autocrypt (2023), The State of Level 3 Autonomous Driving in 2023: Ready for the Mass Market?, https://autocrypt.io/the-state-of-level-3-autonomous-driving-in-2023/. [55] Banes, D. (2023), Interview with David Banes (accessibility expert and consultant). [27] Banes, D. (2022), Shaping an Identity for Digital Assistive Technologies, DATEurope, https://dateurope.com/wp-content/uploads/2023/01/Shaping-the-identity-of-DIgital-AT-Final-
2.pdf. [116] Barr, K. (2023), "Eating Disorder Helpline Takes Down Chatbot After Its Advice Goes Horribly Wrong", Gizmodo, https://gizmodo.com/ai-chatbot-eating-disorder-helpline-neda1850490751. [132] 
Bellan, R. (2022), Local Motors, the startup behind the Olli autonomous shuttle, has shut down, https://techcrunch.com/2022/01/13/local-motors-the-startup-that-created-the-olli-autonomousshuttle-has-shutdown/. [56]Bennett, C. and O. Keyes (2019), "What is the Point of Fairness? Disability, AI and The Complexity of Justice". [71]Bossewitch, J. et al. (2022), Digital futures in mind: reflecting on technological experiments in mental health & crisis support. [138] Broecke, S. (2023), "Artificial intelligence and labour market matching", OECD Social, Employment and Migration Working Papers, No. 284, OECD Publishing, Paris, https://doi.org/10.1787/2b440821-en. [8] Cagnon, C. (2023), Interview with Céline Cagnon (TotalEnergies). [28] Center for Democracy and Technology (2020), Algorithm-driven hiring tools: innovative recruitment or expedited disability discrimination?, https://cdt.org/wp-
content/uploads/2020/12/Full-Text-Algorithm-driven-Hiring-Tools-Innovative-Recruitment-orExpedited-Disability-Discrimination.pdf. [65] Center for Excellence in Universal Design (2023), , https://www.universaldesign.ie/what-isuniversal-design/. [124] Claypool, H. (2023), Interview with Henry Claypool (accessibility expert and consultant). [83] Claypool, H., A. Bin-Nun and J. Gerlach (2017), Self-driving cars: the impact on people with disabilities. [52] Claypool, H. et al. (2021), Centering Disability in Technology Policy. Issue Landscape and Potential Opportunities for Action, https://cdt.org/wp-content/uploads/2021/12/centeringdisability-120821-1326-final.pdf. [121] Cornell University (2023), Ignite Cornell Lab to Market, https://ctl.cornell.edu/ignite/. [135] Cunningham, N. (2023), Interview with Nathan Cunningham. [112] Curtis-Davidson, B. (2023), Interview with Bill Curtis-Davidson (Partnership on Employment and Accessible Technology). [69] Denoncin, S. (2022), Interview with Sylvain Denoncin (Okeenea). [127] Department of Labor, ODEP (2019), Autonomous Vehicles: Driving Employment for People with 
Disabilities. [50] Dodwell, E. et al. (2020), Towards Integrating Fairness Transparently in Industrial Applications, https://doi.org/10.48550/arXiv.2006.06082. [108] Draffan, E. (2019), Artificial Intelligence and Information Communication Technology Accessibility. [70] Duchemin, T. (2022), Interview with Thibaut Duchemin (Ava). [82] 
Duggin, A. (2016), "What we mean when we talk about accessibility", UK Government "Accessibility in government" blog, https://accessibility.blog.gov.uk/2016/05/16/what-wemean-when-we-talk-about-accessibility-2/. [125]EEOC (2022), The Americans with Disabilities Act and the Use of Software, Algorithms, and Artificial Intelligence to Assess Job Applicants and Employees, https://www.eeoc.gov/laws/guidance/americans-disabilities-act-and-use-software-algorithmsand-artificial-intelligence. [90]Engler, A. (2019), "For some employment algorithms, disability discrimination by default", Brookings, https://www.brookings.edu/articles/for-some-employment-algorithms-disabilitydiscrimination-by-default/ (accessed on 3 August 2023). [14] European Commission (2023), Proposal for a Regulation of the European Parliament and of the Council Laying Down Harmonised Rules on Artificial Intelligence (Artificial Intelligence Act) and Amending Certain Union Legislative Acts, https://eurlex.europa.eu/resource.html?uri=cellar:e0649735-a372-11eb-958501aa75ed71a1.0001.02/DOC_1&format=PDF. [60] European Commission (2022), New liability rules on products and AI to protect consumers and foster innovation, https://ec.europa.eu/commission/presscorner/detail/en/ip_22_5807. [126] European Disability Forum (2021), Disability perspective on Regulating Artificial Intelligence, https://www.edf-feph.org/publications/disability-perspective-on-regulating-artificialintelligence/. [91] EU-US Trade and Technology Council (2021), Inaugural Joint Statement, https://ec.europa.eu/commission/presscorner/detail/en/statement_21_4951. [97] Fabien, M. (2022), Interview with Maël Fabien (Biped). [75] Farahani, J. (2022), Interview with Javid Farahani (Cogmap). [19] Favreau, J. (2022), Interview with Jean-Marie Favreau (Université Clermont Auvergne). [24] Feghali, J. (2022), Interview with Jean-Marc Fhegali (WeWalk). [35] Fiol, O. and S. Weng (2022), "Shared autonomous vehicles could improve transit access for people with disabilities if regulated appropriately", Urban Institute, https://www.urban.org/urban-wire/shared-autonomous-vehicles-could-improve-transit-accesspeople-disabilities-if-regulated. [51] Fitzpatrick, D. (2023), Interview with Donal Fitzpatrick (Center for Excellence in Universal Design, Irish National Disability Authority). [66] Fonte, G. (2023), "Italy plans state-backed fund to promote AI startups", Reuters, https://www.reuters.com/technology/italy-plans-state-backed-fund-promote-ai-startups-202305-
30/#:~:text=ROME%2C%20May%2030%20(Reuters),Alessio%20Butti%20said%20on%20Tu esday. [114] ForHumanity (2023), ForHumanity University, https://forhumanity.center/forhumanity-university/. [111] Fruchterman, J. and J. Mellea (2018), Expanding Employment Success for People with 
Disabilities, https://benetech.org/about/resources/expanding-employment-success-for-peoplewith-disabilities-2/. [16]GARI (2023), Global Accessibility Reporting Initiative, https://www.gari.info/. [117]Gilligan, P. (2022), Interview with Patrick Gilligan (Zanmo). [38] Global Disability Innovation Hub (2021), Powering Inclusion: Artificial Intelligence and Assistive Technology, https://cdn.disabilityinnovation.com/uploads/images/AIATPolicyBrief_ToPublish.pdf?v=16197 74523. [37] Goldberg, L. (2023), Interview with Larry Goldberg (accessibility expert and consultant). [86] Goonewardhane, B. (2022), Interview with Bhagya Goonewardhane (Envision). [34] GPII (2023), Unified Listing, https://ul.gpii.net/. [118] GPII (2017), GPII Developer Space, https://ds.gpii.net/. [109] Guo, A. et al. (2020), "Toward fairness in AI for people with disabilities SBG@a research roadmap", ACM SIGACCESS Accessibility and Computing 125, pp. 1-1, https://doi.org/10.1145/3386296.3386298. [17] Hammersley, H. (2023), Interview with Haydn Hammersmith (European Disability Forum). [46] Hamot, C. (2023), Interview with Christine Hamot (TotalEnergies). [42] Hasegawa Johnson, M. (2022), Interview with Mark Hasegawa Johnson (University of Illinois). [80] Hataway, H. (2022), Interview with Haley Hataway (Mentra). [31] Hemphill, C. (2022), Interview with Christine Hemphill (Open Inclusion). [72] Höckner, K. (2023), Interview with Klaus Höckner (Austrian Association for the Blind and Visually Impaired). [88] House of Commons of Canada (2022), Bill C-27 - First Reading - Digital Charter Implementation Act, 2022, https://www.parl.ca/DocumentViewer/en/44-1/bill/C-27/first-reading. [94] Hutchinson, B. et al. (2016), Unintended Machine Learning Biases as Social Barriers for Persons with Disabilities. [67] IDRC (2021), Future of Work and Disability - Inclusion, artificial intelligence, maching learning and work. [139] IEEE SA (2023), IEEE CertifAIEd(tm), the Mark of AI EThics, https://engagestandards.ieee.org/ieeecertifaied.html?_gl=1*1hfa9bd*_ga*MTI2Nzc3Mjk1Mi4x Njg3OTQ1MDQ0*_ga_XDL2ME6570*MTY4Nzk0NTA0NC4xLjEuMTY4Nzk0NTM2NS4yMi4w
LjA. [106] IEEE SA (2023), The IEEE Global Initiative on Ethics of Autonomous and Intelligent Systems, [107] https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9084219. 
ISO (2017), ISO/IEC JTC 1/SC 42 Artificial Intelligence, https://www.iso.org/committee/6794475.html. [133]Jeannel, O. (2022), Interview with Olivier Jeannel (Rogervoice). [36] Jiang, P. (2022), Interview with Panpan Jiang (Google). [78] Ji, H. (2023), Interview with Hyeong Keun Ji (Korean Ministry of Employment and Labour). [95] Jones, M. (2023), Interview with Melanie Jones (Cardiff Business School). [22] Jung, B. (2023), Interview with Bong-Keun Jung (Seoul National University). [68] Kamikubo, R. et al. (2022), "Data Representativeness in Accessibility Datasets: A MetaAnalysis", The 24th International ACM SIGACCESS Conference on Computers and Accessibility, https://doi.org/10.1145/3517428.3544826. [23] Kanevsky, D. (2022), Interview with Dimitri Kanesky (Google). [32] Kim, J. (2023), "The iPad was meant to revolutionize accessibility. What happened?", MIT Technology Review. [137] Lane, M. and A. Saint-Martin (2021), "The impact of Artificial Intelligence on the labour market: What do we know so far?", OECD Social, Employment and Migration Working Papers, No. 256, OECD Publishing, Paris, https://doi.org/10.1787/7c895724-en. [6] Lane, M., M. Williams and S. Broecke (2023), "The impact of AI on the workplace: Main findings from the OECD AI surveys of employers and workers", OECD Social, Employment and Migration Working Papers, No. 288, OECD Publishing, Paris, https://doi.org/10.1787/ea0a0fe1-en. [3] Larrouy, M. (2022), Interview with Muriel Larrouy (Ministerial delegation to accessibility in the French Ministry of Ecological Transition and Territorial Cohesion). [25] Lee, J. (2022), Interview with Jun-Ho Lee. [76] Lorach, H. et al. (2023), "Walking naturally after spinal cord injury using a brain-spine interface", Nature, Vol. 618/7963, pp. 126-133, https://doi.org/10.1038/s41586-023-06094-5. [131] Mallick, K. (2023), Interview with Kamran Mallick, Disability Rights UK. [41] Marzin, C. (2018), Plug and Pray? A disability perspective on artificial intelligence, automated decision-making and emerging technologies. [40] Mazrui, S. (2023), Interview with Susan Mazrui (AT&T). [47] McConnell, R. (2022), Interview with Richard McConnell (Liopa). [74] McDonald, B. (2022), Bob McDonald (Google). [79] Milanez, A. (2023), "The impact of AI on the workplace: Evidence from OECD case studies of AI implementation", OECD Social, Employment and Migration Working Papers, No. 289, OECD [2] Publishing, Paris, https://doi.org/10.1787/2247ce58-en. 
Miller-Merrell, J., L. Goldberg and K. Sonka (2018), Podcast: Developing Talent to Make Workplace Technology Accessible, https://www.peatworks.org/podcast-developing-talent-tomake-workplace-technology-accessible/. [123]Modicamore, D. et al. (2022), Economic impacts of removing transportation barriers to employment for individuals with disabilities through autonomous vehicle adoption., https://www.nationaldisabilityinstitute.org/wp-content/uploads/2023/02/ndieconomicimpactsofremovingtransportationbarriers.pdf. [53] Moran, M. (2022), Interview with Melissa Moran (Google). [33] Musikanski, L., J. Haven and G. Gunsch (2019), IEEE P7010 Well-being Metrics Standard for Autonomous and Intelligent Systems: An Introduction, http://sagroups.ieee.org/7010/wpcontent/uploads/sites/275/2019/01/IEEE-
P7010_WellbeingMetricsforA_IS_ShortPaper_December272018For_Submission_reviewedby IEEELegal-1.pdf. [134] National Council on Disability (2015), Self-driving cars: mapping access to a technology revolution, https://ncd.gov/sites/default/files/NCD_AutomatedVehiclesReport_508-PDF.pdf. [59] Nichols, D. (2019), Making Artificial Intelligence Inclusive for Hiring and HR - Interview of Dan Nichols, founder of Candidit, https://www.peatworks.org/podcast-making-artificial-intelligenceinclusive-for-hiring-and-hr/. [21] NIST (2023), AI Fact Sheet, https://www.nist.gov/system/files/documents/2023/03/30/AI%20Fact%20Sheet%200615%20F INAL.pdf. [99] NIST (2023), Artificial Intelligence Risk Management Framework (AI RMF 1.0), https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf. [100] NIST (2022), Towards a Standard for Identifying and Managing Bias in AI, https://nvlpubs.nist.gov/NISTpubs/SpecialPublications/NIST.SP.1270.pdf. [101] Noori, K. (2023), Interview with Kave Noori (European Disability Forum). [39] NSF News (2022), NSF accelerates use-inspired solutions for persons with disabilities, https://new.nsf.gov/news/nsf-accelerates-use-inspired-solutions-persons. [140] Nugent, S. et al. (2020), Recruitment AI has a Disability Problem: questions employers should be asking to ensure fairness in recruitment.. [15] OECD (2023), "A blueprint for building national compute capacity for artificial intelligence", OECD Digital Economy Papers, No. 350, OECD Publishing, Paris, https://doi.org/10.1787/876367e3-en. [145] OECD (2023), Catalogue of Tools and Metrics for Trustworthy AI, https://oecd.ai/en/catalogue/tools. [144] OECD (2023), OECD Employment Outlook 2023: Artificial Intelligence and the Labour Market, OECD Publishing, Paris, https://doi.org/10.1787/08785bba-en. [113] OECD (2023), OECD.AI Database of national AI Policy & Strategies, [143] https://oecd.ai/en/dashboards/overview. 

OECD (2023), Reporting Gender Pay Gaps in OECD Countries: Guidance for Pay Transparency Implementation, Monitoring and Reform, Gender Equality at Work, OECD Publishing, Paris, https://doi.org/10.1787/ea13aa68-en. [119]OECD (2022), Disability, Work and Inclusion: Mainstreaming in All Policies and Practices, OECD Publishing, Paris, https://doi.org/10.1787/1eaa5e9c-en. [1] OECD (2022), "OECD Framework for the Classification of AI systems", OECD Digital Economy Papers, No. 323, OECD Publishing, Paris, https://doi.org/10.1787/cb6d9eca-en. [5] OECD (2019), Recommendation of the Council on Artificial Intelligence, https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449#mainText. [142] Orwat, C. (2020), Risks of Discrimination through the Use of Algorithms, https://www.antidiskriminierungsstelle.de/EN/homepage/_documents/download_diskr_risiken _verwendung_von_algorithmen.pdf?__blob=publicationFile&v=1. [12] Parsy, J. (2023), Interview with Jonathan Parsy (Total). [120] PEAT (2023), Autonomous Vehicles, Partnership on Employment & Accessible Technology 
(PEAT), https://www.peatworks.org/futureofwork/av/#:~:text=AV%20technology%20can%20alter%20t he,within%20the%20next%20few%20decades. (accessed on 16 October 2023). [58] Placencia Porrero, I. (2023), Intervention of Imaculada Placencia Porrero (European 
Commission) in the the session titled "Can AI approve access to the labour market for people with disability?" at the OECD International Conference on AI in Work, Innovation, Productivity and Skills.. [81] Quinn, G. (2021), Report of the Special Rapporteur on the rights of persons with disabilities, https://documents-ddsny.un.org/doc/UNDOC/GEN/G21/397/00/PDF/G2139700.pdf?OpenElement. [13] Reardon, C. (2021), "Disabled passengers were promised autonomous vehicles - they're still waiting", The Verge, https://www.theverge.com/22832657/autonomous-vehicles-disabledaccessible-challenges-design. [54] REC/CDEI (2021), Data-driven tools in recruitment guidance, https://www.rec.uk.com/ourview/research/practical-guides/data-driven-tools-recruitment-guidance. [105] Reinhardt, C. (2022), Interview with Conner Reinhardt (Mentra). [128] Robinson, J. (2022), Interview with John Robinson (Our Ability). [85] Rodgers, R. (2023), Interview with Rylin Rodgers (Microsoft). [7] Salvi del Pero, A. and A. Verhagen (2023), "Ensuring trustworthy artificial intelligence in the workplace: Countries' policy action", in OECD Employment Outlook 2023: Artificial Intelligence and the Labour Market, OECD Publishing, Paris, https://doi.org/10.1787/04b3d08d-en. [63] Scott-Parker, S. (2022), Interview with Susan Scott-Parker (accessibility expert and consultant). [62] Sharma, D. (2023), Interview with Dorodi Sharma (International Disability Alliance). [44] Siabi, N. (2022), Interview with Nasser Siobi (Microlink PC). [87]Smith, P. and L. Smith (2020), "Artificial intelligence and disability: too much promise, yet too little substance?", AI and Ethics 2020 1:1, Vol. 1/1, pp. 81-86, https://doi.org/10.1007/S43681020-00004-5. [84] Smolley, S. (2022), Interview with Sara Smolley (VoiceItt). [30] Standards Australia (2020), An Artificial Intelligence Standards Roadmap: Making Australia's Voice Heard, https://www.standards.org.au/documents/r-1515-an-artificial-intelligencestandards-roadmap-soft. [102] Stassun, K. (2023), Interview with Keivan Stassun (Vanderbilt University). [29] Steil, J., A. Bullinger-Hoffmann and E. André (2023), Mit KI zu mehr Teilhabe in der Arbeitswelt, https://www.plattform-lernendesysteme.de/files/Downloads/Publikationen/AG2_WP_KI_Teilhabe_in_der_Arbeitswelt.pdf. [115] Tanis, S. (2023), Interview with Shea Tanis (Kansas University). [26] TeachAccess (2023), What is Teach Access?, https://teachaccess.org/. [122] Templeton, B. (2022), Two self-driving shuttle companies fail in one week. What does it bode?, https://www.forbes.com/sites/bradtempleton/2022/01/18/two-self-driving-shuttle-companiesfail-in-one-week--what-does-it-bode/?sh=4ba127b41fb0. [57] The White House (2022), Blueprint for and AI Bill of Rights, https://www.whitehouse.gov/wpcontent/uploads/2022/10/Blueprint-for-an-AI-Bill-of-Rights.pdf. [92] Tordini, F. (2022), Interview with Francesco Tordini (Solar Ear). [136] Trace RERC (2023), Exploring the role of datasets sourced from people with disabilities, https://trace.umd.edu/projects-inclusive-ai/. [110] Treviranus, J. (2022), Interview of Jutta Treviranus (IDRC, OCAD University). [20] Trewin, S. (2018), "AI Fairness for People with Disabilities: Point of View". [64] Tschudi, Y. (2022), Interview with Yohann Tschudi (Okeenea). [49] UK Government (2023), A pro-innovation approach to AI regulation, https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_dat a/file/1176103/a-pro-innovation-approach-to-ai-regulation-amended-web-ready.pdf. [89] United Nations (2008), Convention on the Rights of Persons with Disabilities (CRPD), https://www.un.org/development/desa/disabilities/convention-on-the-rights-of-persons-withdisabilities/convention-on-the-rights-of-persons-with-disabilities-2.html. [4] Wald, M. (2022), Interview with Mike Wald (University of Southampton). [43] Walkowiak, E. (2023), "Digitalization and inclusiveness of HRM practices: The example of [9] neurodiversity initiatives", Human Resource Management Journal, https://doi.org/10.1111/1748-8583.12499. 
Walkowiak, E. (2021), "Neurodiversity of the workforce and digital transformation: The case of 	[129] inclusion of autistic workers at the workplace", Technological Forecasting and Social Change, Vol. 168, p. 120739, https://doi.org/10.1016/j.techfore.2021.120739. 
Wass, V. (2023), Interview with Victoria Wass (Cardiff Business School). [45] Weinstein, H. (2022), Interview with Howard Weinstein (Solar Ear). [77] Welker, Y. (2023), "AI Act and disability-centred policy: how can we stop perpetuating social exclusion?", OECD.AI - Policy Observatory, https://oecd.ai/en/wonk/eu-ai-act-disabilities. [96] Welker, Y. (2023), Interview with Yonah Welker. [73] Whittaker, M. (2019), "Disability, Bias, and AI". [61] Zimmerman, J. (2022), Interview with Jean-Louis Zimmermann (Open Street Map). [130]  
 
 
 

Annex A. Repository of AI-powered solutions 
Table A A.1. Repository of identified AI-powered solutions 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Cognitive  / Frist Center for 
Autism and 
Innovation at 
Vanderbilt 
University Academia VR and AI-powered job interview coaching system for neurodiverse individuals. Interview preparation First intent In use Enabling United States Disabilitycentred solution Cognitive  / Frist Center for 
Autism and 
Innovation at 
Vanderbilt 
University Academia VR and bio-feedback driving instruction system for neurodiverse individuals, using AI to personalise the instruction system.  Commuting First intent In use Enhancing United States Disabilitycentred solution Cognitive  Brainpower  Affectiva Medium-sized 
firm Wearable glasses with an inbuilt family of applications designed to help individuals with autism to teach themselves crucial social and cognitive skills including emotion recognition and eye contact.  General communication First intent In use Enabling United States Disabilitycentred solution Hearing Genesis AI Starkey Large firm Automatically adapting hearing aid with additional AI features such as help with tasks like translations and transcriptions. General independent 
living First intent In use Enhancing United States 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Hearing Moment 
Sheer Widex Large firm Automatically adapting hearing aid using real-time feedback from users and data from a companion app on what settings work well in various environments. General independent 
living First intent In use Enhancing Switzerland Disabilitycentred solution Hearing Oticon Real Oticon Large firm Hearing aid with algorithm trained on real-life sounds to respond to various sound scenes allowing for open soundscapes (birds, water sounds etc.) without losing speech clarity. General independent 
living First intent In use Enhancing Multiple Disabilitycentred solution Hearing Solar Ear AIpowered hearing aid Solar Ear Small firm Application using AI to automatically adapt frequencies on a smartphone to transform it into a hearing aid, based on the results from a companion hearing loss test application. General independent 
living First intent In 
development1 Enabling United States Disabilitycentred solution Mental health Happify Twill Large firm Mental health AI coach.  General wellbeing First intent In use Enhancing United States Disabilitycentred solution Mental health Woebot Woebot Health Medium-sized 
firm Mental health coaching chatbot using insights from cognitive behavioural therapy and natural language processing to relieve depression symptoms.  General wellbeing First intent In use Enabling United States Disabilitycentred solution Mental health Pyx Health Pyx Health Small firm Mental health application offering support through both human intervention and AIpowered chatbot conversation to address loneliness and social isolation.  General wellbeing First intent In use Enhancing Canada Disabilitycentred solution Mental health Amelia  XRHealth Small firm VR software for mental health professionals General wellbeing First intent In use Enhancing United States 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Mental health Wysa AI coach Wysa Small firm Mental health coaching chatbot combining a conversational AI and access 
to human therapists if required.  General wellbeing First intent In use Enhancing United States Disabilitycentred solution Motor / Harvard University Academia Wearable rehabilitation and assistance platform to restore arm function and independence for those with upper limb disability. General independent 
living First intent In development Enabling United 
Kingdom Disabilitycentred solution Motor / Northwell Health Academia Brain-computer interface decoding brain signals for movement and touch and translating it back into muscle movement and sensations in a paraplegic individual. General mobility First intent In development Enabling Korea Disabilitycentred solution Motor / Université de 
Lausanne Academia Brain-spine interface restoring the communication between the brain and the spinal cord, allowing a tetraplegic individual to naturally walk, stand, and climb stairs.  General mobility First intent In development Enabling United States Disabilitycentred solution Motor Brain.io Synchron Small firm Neuroprosthesis designed to bypass damaged neural pathways in patients with severe paralysis, allowing them to restore motor capabilities including control of digital devices. General independent 
living First intent In development Enabling United States Disabilitycentred solution Motor Neural 
Sleeve Cionic and 
Fuseproject Start-up Wearable solution combining a gait analysis and a learning gait correction algorithm for people who have difficulty walking. General mobility First intent In development Enabling United States 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Motor EvoWalk Evolution Devices Start-up Rehabilitation solution combining motion tracking and machine-learningpowered muscle stimulation that adapts to various gaits, to treat walking impairments through physical therapy remotely. General mobility First intent In development Enabling United States Disabilitycentred solution Multiple The Link Neuralink Medium-sized 
firm Brain-computer interface to control devices. General independent 
living First intent In development Enabling United States Disabilitycentred solution Visual eSight glasses eSight Medium-sized 
firm Vision enhancement glasses General independent 
living First intent In use Enhancing Canada Disabilitycentred solution Cognitive  ChatGPT OpenAI Big tech Generative AI producing text from prompts.  General communication Byproduct In use Enabling United States Disabilitycentred solution Cognitive  Grammarly Grammarly Large firm Writing enhancement software using generative AI.  General communication Byproduct In use Enabling United States Disabilitycentred solution Hearing GoVoBo Gallaudet University 
& Apptek Academia 
(partnership) Speech-to-text application for live captioning through automated speech recognition and multilingual transcriptions and translations, with an interface design driven by insights from the deaf community. General communication First intent In development Enabling United States Disabilitycentred solution Hearing Protosound University of 
Washington and 
Google Research Academia 
(partnership) Personalisable sound recognition algorithm for deaf and hard of hearing individuals. General independent 
living First intent In development Enabling United States Disabilitycentred solution Hearing Android LiveTranscri be Google  Big tech Speech-to-text application for live captioning through automated speech recognition.  General communication Byproduct In use Enabling United States Disabilitycentred solution Hearing Lipnet Deepmind and 
Oxford Big tech 
(partnership) Lip movement to text algorithm for people who cannot use their voice.  General communication First intent In development Enabling Multiple 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Hearing RogerVoice Rogervoice Medium-sized 
firm Live captioning solution for phone conversations (using speech recognition).  General communication First intent In use Enabling Multiple Disabilitycentred solution Hearing Ava Ava Medium-sized 
firm Live AI & professional captioning solution for inperson & online meetings.  General communication First intent In use Enabling Multiple Disabilitycentred solution Hearing Koda Imanyco Small firm Live captioning application for group conversations.  General communication First intent In development Enabling United States Disabilitycentred solution Hearing SignAll Chat Signall Small firm Application live translating sign-language into text using image recognition.  General communication First intent In development Enabling United States Disabilitycentred solution Hearing Speaksee 
Microphone 
Kit Speaksee Small firm Speech-to-text application using automated speech recognition and microphones for live captioning of group meetings.  Workplace accommodations First intent In use Enabling United States Disabilitycentred solution Hearing Nagish Nagish Start-up Live captioning solution for phone conversations (using speech recognition).  General communication First intent In use Enabling United States Disabilitycentred solution Hearing Slait Slait Start-up Live sign-language to text translation algorithm (using image recognition) General communication First intent In development Enabling Canada Disabilitycentred solution Motor / University consortium Academia Brain-computer interface to operate a wheelchair. General mobility First intent In development Enabling United States Disabilitycentred solution Motor ExoNet University of 
Waterloo Academia Self-walking exo-skeleton 
(using image recognition). General mobility First intent In development Enabling United States Disabilitycentred solution Motor / Northwestern 
University Academia Self-driving wheelchair (using image recognition) with an accessible interface. General mobility First intent In development Enabling France Disabilitycentred solution Motor / Imperial College 
London Academia Self-driving wheelchair (using image recognition) with an accessible interface (eye control). General mobility First intent In development Enabling United States Disabilitycentred solution Motor / University Busan Academia Self-driving wheelchair (using image recognition) General mobility First intent In development Enabling United States 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Motor / MIT Academia Self-driving wheelchair (using image recognition). General mobility First intent In development Enabling United States Disabilitycentred solution Motor Self-driving wheelchair Adventus Robotics Academia 
(spin-off) Self-driving wheelchair (using image recognition). General mobility First intent In development Enabling United States Disabilitycentred solution Motor The Wheelie Intel and Hoobox 
Robotics Big tech 
(partnership) Self-driving wheelchair (using image recognition) with an accessible interface (using facial expressions). General mobility First intent In development Enabling United States Disabilitycentred solution Motor Open 
Sesame Sesame Enable Free app2 Hand-free computer interface allowing to use technology with hand movements.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Motor May Mobility May Mobility Medium-sized 
firm On-demand wheelchairaccessible self-driving cars. General mobility Byproduct In use Enabling United States Disabilitycentred solution Motor Loro Loro Start-up Companion robot for wheelchair users integrating several technologies including text-to-speech, speech-totext, and user-friendly interface connected to Amazon Alexa. General independent 
living First intent In development Enabling United States Disabilitycentred solution Motor Bro Scewo Start-up Stair-climbing electric wheelchair using AI and sensors to adjust rider position based on terrain.  General mobility First intent In use Enhancing United States Disabilitycentred solution Motor Puffin Puffin Start-up Accessible interface to operate multiple devices (like smart home, communication, or convenience application) hands-free, using sip-and-puff gestures, that learns to adapt to users through machine learning. General independent 
living First intent In development Enhancing United States Disabilitycentred solution Multiple / Mississippi State 
University Academia VR driving instruction system incorporating adaptive equipment used by PWD.  Commuting First intent In development Enhancing United States 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Multiple Brain Magic Meta AI Big tech Brain-computer interface to decode text read by people in lockdown syndrome. General communication First intent In development Enabling United States Disabilitycentred solution Multiple Project 
Activate Google Research Big tech Accessible computer interface using facial gestures for people unable to speak or use technology with their hands.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Multiple Amazon 
Alexa and 
Echo Amazon Big tech Personal voice-activated virtual assistant.  General independent 
living Byproduct In use Enabling United States Disabilitycentred solution Multiple Siri Apple Big tech Personal voice-activated virtual assistant.  General independent 
living Byproduct In use Enabling United States Disabilitycentred solution Multiple Project 
Insight  Microsoft Research, 
Team Glason Big tech 
(partnership) Data collection of images of people with ALS looking at their computer and development of a hardwareagnostic gaze tracker to provide an accessible interface to technology for people with ALS. General independent living, improve data availability First intent In development Enabling United States Disabilitycentred solution Multiple Dragon  Nuance Large firm Speech-to-text software for dictation.  Workplace accommodations Byproduct In use Enabling United States Disabilitycentred solution Multiple Speechify Speechify Inc. Medium-sized 
firm Text-to-speech algorithm with natural sounding voices. Equal digital access Byproduct In use Enabling United 
Kingdom Disabilitycentred solution Multiple Natural 
Reader NaturalSoft Ltd. Small firm Text-to-speech algorithm with natural sounding voices. General 
communication, Skills acquisition First intent In use Enabling Brazil Disabilitycentred solution Speech / University consortium Academia Brain-computer interface to decode attempted handwriting for people who are paralysed. General communication First intent In development Enabling United States Disabilitycentred solution Speech / University of Texas at Austin Academia Brain-computer interface decoding language from noninvasive brain image recordings. General communication First intent In development Enabling United States 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Speech Echo 
Speech Cornell Smart Computer Interfaces 
for Future 
Interactions (Sci-Fi) Academia Accessible interface using acoustic sensing and AI to decode unvocalised commands based on lip and mouth movements. General independent 
living First intent In development Enabling United States Disabilitycentred solution Speech / University of 
California San 
Francisco Academia Brain-computer interface (neuroprosthesis) for decoding attempted speech in paralysed individuals. General communication First intent In development Enabling United 
Kingdom Disabilitycentred solution Speech Parrotron Google Research Big tech Speech conversion and synthesis for people with dysarthric speech.   General communication First intent In development Enabling Israel Disabilitycentred solution Speech Apple 
Personal 
Voice Apple Big tech Voice synthesis algorithm for people at risk of losing their voice.  General communication First intent In use Enabling United 
Kingdom Disabilitycentred solution Speech Apple 
LiveSpeech Apple Big tech Text-to-speech feature allowing non-speaking individuals to type to speak during calls or conversations.  General communication First intent In use Enabling United States Disabilitycentred solution Speech Project 
Euphonia/Re
late Google Research Big tech Data collection of speech samples and training of a speech recognition algorithm for people with dysarthric speech.  General communication, 
improve data availability First intent In development Enabling Spain Disabilitycentred solution Speech MyOwnVoice Acapela Medium-sized 
firm Voice synthesis algorithm for people at risk of losing their voice.  General communication First intent In use Enabling United States Disabilitycentred solution Speech VoiceItt Voiceitt Small firm Personalisable automated speech recognition algorithm for people with dysarthric speech.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Speech Speakprose 
3 Cognixion Small firm Augmentative and Alternative Communication device with a built-in chatbot (using natural language processing). General communication First intent In use Enhancing Denmark 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Visual VIS4ION for workplaces New York University Academia Backpack with sensors providing real-time feedback to people with vision impairment for real-time navigation, scene analysis, and obstacle avoidance within work environments.  Workplace accommodations First intent In development Enabling Denmark Disabilitycentred solution Visual Google 
Lookout Google Big tech Image recognition and text-tospeech application for blind or low-vision people.  General independent 
living First intent In use Enabling Japan Disabilitycentred solution Visual Seeing AI Microsoft Big tech Image recognition and text-tospeech application for blind or low-vision people.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Visual Detection mode in Apple 
Magnifier Apple Big tech Live description of surroundings through text or speech feedback using image recognition in the Magnifier app for low-vision people.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Visual Point and speak in Apple 
Magnifier Apple Big tech Feature identifying text users point to and reading it out loud through text-to-speech.   General communication First intent In use Enabling Israel Disabilitycentred solution Visual Aipoly vision Aipoly Free app2 Image recognition and text-tospeech application for blind or low-vision people.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Visual Braibook  Independent developer Independent developer Portable text-to-Braille converter. General communication First intent In development Enabling Israel Disabilitycentred solution Visual AI suitcase Firm consortium 
(Alps Alpine Co., 
OMRON 
Corporation, 
Shimizu 
Corporation, IBM 
Japan)  Large firm Portable image recognition device providing real-time feedback to people with vision impairment through haptic, speech and sound.  General mobility First intent In development Enabling Japan 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Visual MyEye 2 Orcam Large firm Wearable image recognition and text-to-speech application mounted on glasses for blind or low-vision people.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Visual Money 
Reader LookTel  Small firm Image recognition and text-tospeech application specialised in identifying currency for blind or lowvision people.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Visual Sullivan+ TUAT Corp. Small firm Image recognition and text-tospeech application for blind or low-vision people.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Visual Supersense Mediate.tech Small firm Image recognition and text-tospeech application for blind or low-vision people.  General independent 
living First intent In use Enabling United States Disabilitycentred solution Visual TapTapSee CloudSight Inc. Small firm Image recognition and text-tospeech application for blind or low-vision people.  General independent 
living First intent In use Enabling France Disabilitycentred solution Visual Envision 
Glasses Envision Small firm Wearable image recognition and text-to-speech application mounted on Google glasses for blind or low-vision people.  General independent living, Workplace accommodation First intent In use Enabling France Disabilitycentred solution Visual Be My AI Be My Eyes and 
OpenAI Small firm Digital visual assistant using image recognition.  General independent 
living First intent In development Enhancing United States Disabilitycentred solution Visual Alana Alana AI Start-up Accessible digital visual assistant for people who are blind or have low vision.  General independent 
living First intent In development Enabling France Disabilitycentred solution Visual Biped Biped Start-up Wearable harness with sensors providing real-time feedback to people with vision impairment for real-time navigation, scene analysis, and obstacle avoidance.  General mobility First intent In use Enhancing United States 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Disabilitycentred solution Visual LetsSee bank notes recogniser. LetSee Start-up Image recognition and text-tospeech application specialised in identifying currency for blind or lowvision people.  General independent 
living First intent In use E United 
Kingdom Disabilitycentred solution Visual Wayband 
and Haptic Nav app WearWorks Start-up Navigation algorithm and haptic feedback device for people who are blind or have low vision.  General mobility First intent In use Enhancing United 
Kingdom Environment adaptation solution Cognitive  EasyText AI Massachusetts 
Biomedical 
Initiatives  Academia 
(spin-off) Text simplification algorithm to translate documents into plain language, making them accessible to people with learning disabilities Equal digital access First intent In development Enhancing Japan Environment adaptation solution Cognitive  AI-powered document summarisati on feature in 
Microsoft 
Azure Microsoft, OpenAI Big tech Text simplification algorithm.  Equal digital access Byproduct In use Enabling United States Environment adaptation solution Cognitive  Capito digital Capito Small firm Text simplification algorithm making documents accessible to neurodiverse individuals (in German). Equal digital access First intent In use Enhancing United States Environment adaptation solution Cognitive  U31 U31 Small firm Text simplification algorithm making documents accessible to neurodiverse individuals and people with learning disabilities.  Equal digital access First intent In use Enhancing United States Environment adaptation solution Cognitive  As simple as that (ASAT) Asattec Start-up Text simplification algorithm making content accessible to neurodiverse individuals and people with learning disabilities.  Equal digital access First intent In use Enabling United States 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Environment adaptation solution Hearing / Rutgers University Academia Anonymisation system for videos in American Sign Language, and image recognition system to search for a sign in a dictionary using inputs from a webcam or a video clip. General communication First intent In development Enabling United States Environment adaptation solution Hearing Verbit Verbit Large firm Speech-to-text application offering live captioning to firms through automated speech recognition.  Equal digital access First intent In use Enhancing Brazil Environment adaptation solution Hearing RogerAcces
s Rogervoice Medium-sized 
firm Live captioning solution for phone conversations of organisations' client-facing services (using speech recognition).  Equal digital access First intent In use Enabling United States Environment adaptation solution Hearing AI Mimi SI-com Small firm Live captioning solution for medias (for TV, university settings, telephone calls...) General communication First intent In use Enabling United States Environment adaptation solution Hearing Authôt Authôt Small firm Live captioning solution for online material (video or audio).  Equal digital access, 
Skills acquisition Byproduct In use Enabling United States Environment adaptation solution Multiple / University of 
Southern California Academia Accessible, multimodal interface (e.g., speech, eye tracking, pedals) to facilitate access to coding for PWD. Equal digital access, create new work opportunities First intent In development Enabling United States Environment adaptation solution Multiple Amazon 
Polly Amazon Web 
Services Big tech Voice synthesis service for text-to-speech and speechactivated applications. Equal digital access Byproduct In use Enabling Korea Environment adaptation solution Multiple Intelligent 
Services in 
Microsoft 
Accessibility 
Checker Microsoft Big tech Automated suggestion for alttext using image recognition 
in Microsoft's built-in document accessibility checker Equal digital access First intent In use Enabling Israel 
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Environment adaptation solution Multiple Alexa Amazon Big Tech Voice-assistant API for businesses allowing them to improve the accessibility of their website.  Equal digital access Byproduct In use Enabling Hungary Environment adaptation solution Multiple Copilot Voice Github Large firm Accessible interface allowing to code with GitHub copilot through conversational voice commands. Equal digital access First intent In development Enabling United States Environment adaptation solution Multiple Otter Otter.ai Medium-sized 
firm Speech-to-text application using automated speech recognition for live captioning of meetings at work or among students; generation of meeting notes.  Skills acquisition, 
Workplace accommodation Byproduct In use Enabling Netherlands Environment adaptation solution Multiple Ziotag Ziotag Small firm Online platform to make videos accessible to people with visual, hearing, and neurological disabilities, through automated 
transcription generation, Key Concept detection, 
Segmentation & Titling, and Actionable Table of Contents generation.  Equal digital access First intent In use Enabling United States Environment adaptation solution Multiple Andyamo Andyamo Start-up Data collection of accessibility relevant features in urban settings, automated using AI. General mobility, 
improve data availability First intent In use Enabling United States Environment adaptation solution Speech / Michigan State 
University Academia Open-source training datasets and specialised automated speech recognition algorithms to make AI-powered voice recognition technology accessible to people who stutter. General communication, 
improve data availability First intent In development Enabling Japan Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Environment adaptation solution Speech Liopa lip 
movement to 
text algorithm Liopa Start-up Lip movement to text algorithm for people who cannot use their voice in hospital contexts. General communication First intent In development Enabling Northern Ireland
(United KingdomEnvironment adaptation solution Visual Natural voices in Microsoft 
Narrator Microsoft Big tech Speech synthesis with natural-sounding voices improving understandability in Microsoft's built-in screen reader.  Equal digital access First intent In use Enhancing France Environment adaptation solution Visual / Okeenea Digital Small firm Indoor positioning algorithm using data from smartphones' captors as inputs.  General mobility First intent In development Enabling France Environment adaptation solution Visual Zammo 
accessible chatbot Zammo.ai  Small firm Chatbot providing an accessible interface for blind and neurodiverse people to access online job boards.  Job search First intent In development Enabling United States Environment adaptation solution Visual Waymap Waymap Start-up Indoor positioning algorithm using data from smartphones' captors as inputs.  General mobility First intent In use Enabling United States Environment adaptation solution Cognitive  / Frist Center for 
Autism and 
Innovation at 
Vanderbilt 
University Academia Job-matching prediction algorithm using eye movement as input data. Job search First intent In development Enabling United States Environment adaptation solution Cognitive  Mentra Mentra Start-up Job-matching prediction algorithm using inclusive input data.  Job search First intent In development Enabling Israel Environment adaptation solution Multiple JobsAbility OurAbility Inc.  Small firm Job-matching prediction algorithm using self-declared abilities as input data.  Job search First intent In development Enabling United 
Kingdom Environment adaptation solution Multiple Cogmap Cogmap.ai Start-up Job matching prediction algorithm using brain reaction measurements as input data.  Job search Byproduct In development Enabling Belgium Environment adaptation solution Multiple Inclusively Inclusively Start-up Job-matching prediction algorithm using inclusive input data.  Job search First intent In use Enhancing Netherlands )


Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Environment adaptation solution Multiple Invisible 
Strengths Invisible Strengths Start-up Job-matching prediction algorithm using inclusive input data.  Job search First intent In development Enhancing United States Meta-level solutions improving accessibility Multiple / Wayne State 
University Academia AI prediction algorithm to provide near real-time paratransit services. Commuting First intent In development Enabling Korea Meta-level solutions improving accessibility Multiple / Microlink PC Medium-sized 
firm Workplace accommodation recommendation algorithm.  Workplace accommodations First intent In development Enhancing Canada Meta-level solutions improving accessibility Multiple Atvisor.ai Atvisor Small firm Assistive technology recommendation algorithm.   Workplace accommodations First intent In use Enabling France Meta-level solutions improving accessibility Mental health Ieso Ieso group Medium-sized 
firm Online typed cognitive behavioural therapy using AI to analyse data from typed sessions to inform individual care as well as research into cognitive behavioural therapy more generally.  General wellbeing First intent In use Enhancing United States Meta-level solutions improving accessibility Motor Lunaris Axiles bionics Small firm Ankle-foot prosthesis collecting data and using AI algorithms for predictive maintenance, optimisation analysis and future applications General mobility First intent In use Enhancing France Meta-level solutions improving accessibility Visual / WeWalk Small firm Prediction algorithm analysing data from sensors mounted on the WeWalk smart white cane to help Orientation and Mobility Specialists monitor the evolution of their blind and low vision patient's conditions and adapt care accordingly. General mobility First intent In development Enhancing Denmark Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Meta-level solutions improving accessibility Mental health Nevermind University consortium Academia Prediction algorithm using physiological data, body movements, speech and the 
recurrence of social interactions to predict the severity and onset of depression symptoms.                Disability prevention First intent In development Enabling United States Meta-level solutions improving accessibility Mental health Reach Vet US Department of 
Veterans Affairs Governmental programme Prediction algorithm modelling the onset of mental health issues and evaluating suicidal risks among veterans.  Disability prevention First intent In use Enabling United States Meta-level solutions improving accessibility Motor I-Prognosis University consortium Academia Prediction algorithm for early detection and intervention for 
Parkinson's disease Disability prevention First intent In development Enabling Israel Meta-level solutions improving accessibility Motor Brightday Brightday Small firm Posture-correction solution for desk workers, using image recognition to analyse images coming from the user's camera and alerting workers in case of bad positions.  Well-being at work / job retention, Disability prevention Byproduct In use Enabling United States Meta-level solutions improving accessibility Visual Eye-Risk 
Project University consortium Academia Risk prediction algorithm for eye diseases that can lead to blindness.  Disability prevention First intent In development Enabling Switzerland Solutions creating new 
jobs opportunities Cognitive  Ultranauts Ultranauts Medium-sized 
firm Data quality assessment services advertising its neurodiverse workforce.  Create new work opportunities Byproduct In use / United 
Kingdom Solutions creating new 
jobs opportunities Cognitive  Enabled 
Intelligence Enabled Intelligence Small firm Data labelling and AI testing services advertising its neurodiverse workforce. Create new work opportunities Byproduct In use / Switzerland   

Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Solutions creating new 
jobs opportunities Cognitive  Daivergent Daivergent Start-up "Job readiness" online platform linking neurodiverse candidates to work experience and opportunities in data labelling and AI annotation services Create new work opportunities First intent In use / Hungary Solutions creating new 
jobs opportunities Multiple EAS next Uluru Bpo.Co, Ltd Medium-sized 
firm Crowd-working platform providing work opportunities for PWD in the AI-powered document digitalisation field (data entry accuracy check)  Create new work opportunities Byproduct In use / Japan Solutions creating new 
jobs opportunities Hearing Quiet 
Mobility Co:Actus  Small firm Live conversation captioning solution designed to help deaf drivers work in the taxi trade.  Create new work opportunities First intent In development Enabling Germany Solutions creating new 
jobs opportunities Motor Phantom auto Phantom auto Medium-sized 
firm Remotely operated logistics vehicles and distanced driver training to allow PWD to work as remote drivers in the logistics industry.  Create new work opportunities First intent In use Enabling United States Inclusive data collection Speech Speech 
accessibility project University of Illinois with Amazon, Apple, 
Google, Meta, and 
Microsoft Academia 
(partnership) Data collection of speech samples for people with dysarthric speech (including those with Lou Gehrig's disease, ALS, Parkinson's disease, cerebral palsy, or Down Syndrome).  General communication First intent In development / United 
Kingdom Inclusive data collection Speech Project 
Understood Google Research, 
Canadian Down 
Syndrome Society Big tech 
(partnership) Data collection of speech samples for people with Down Syndrome.  General communication First intent In development / Israel Inclusive data collection Multiple Exonet database University of 
Waterloo Academia Dataset of high-resolution wearable camera images of legged locomotion environments to be used in training image recognition algorithms for self-walking devices.  General mobility, improve data availability First intent In use / United 
Kingdom Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Inclusive data collection Multiple / Utah State 
University Academia AI-powered tool to analyse accessibility and generate data about the quality of sidewalks, bus stops and roadways in the first/last mile of the journey of PWD.  General mobility, 
improve data availability First intent In development Enabling United 
Kingdom Inclusive data collection Multiple OpenSidewa
lks Taskar Center for 
Accessible 
Technology, 
University of 
Washington, G3iCT, 
Microsoft Big tech 
(partnership) Creation of datasets of pedestrian paths, using a standardised procedure to describe them consistently and unambiguously in global cities (including using AI for extraction of sidewalk data from aerial imagery at scale). General mobility, improve data availability First intent In development Enhancing United States Inclusive data collection Multiple Wegoto Wegoto Small firm Data collection of accessibility relevant features in urban settings, semi-automated using AI. General mobility, 
improve data availability First intent In use Enhancing United States Inclusive data collection Multiple Open Street 
Map Open Street Map Volunteer 
based non-
profit organisation Data collection of 
accessibility-relevant data (including using AI for automating data processing through image recognition). General mobility, 
improve data availability Byproduct In development Enhancing United States Inclusive data collection Visual MABLE Wichita State 
University Academia MABLE (Mapping for 
Accessibility in Built 
Environments).Communitydriven framework and prototypes for data collection, processing, analysis, and use towards accessible maps, navigating, and wayfinding for PWD within indoor 
environments (including using AI for semi-autonomous data collection).  General mobility, improve data availability First intent In development Enhancing United States   
Type of solution Disability Solution name Solution producer Type of actor Brief description Point of intervention on the labour market Accessibility is a... Advancement AI is... Country Inclusive data collection Visual VizWiz University of Texas with Microsoft and 
Amazon Mechanical 
Turk Academia 
(partnership) Dataset of captioned images taken by blind people General independent 
living First intent In use / France Inclusive data collection Visual ORBIT 
dataset  City University of 
London and 
Microsoft Research Big tech 
(partnership) Dataset of videos and pictures recorded by people who are blind/low vision to train teachable object recognition algorithm. General independent 
living First intent In use / Multiple Note: As stated in the main text, solutions listed here are examples of what exist in the field of AI-powered solutions fostering employment for people with disability, without any claim to exhaustivity. The field evolves rapidly, and this table is representative of the situation as of August 2023. Mentions in the table do not amount to endorsements or promotions of specific solutions by the author. "PWD" stands for "People With Disability". 
1: Solutions are marked "in development" if they are not yet widely commercially available (this includes cases in which research and development is still ongoing, and cases in which a version of the solution is ready but only available to beta testers).   
2: Solution producers marked as "Free app" correspond to cases in which innovations were originally developed by start-ups which could not monetise them and made them accessible for free.  
 
  

Annex B. Interview guide used with accessibility experts  
Note that the following guide was used as a support but not strictly followed, as is often the case in semistructured interviews.     
A. About the interviewee 
Q01. Can you tell me about your position, career history, and how you got to the subject of accessibility? 
Q02. In your work, are you involved in the issue of AI and accessibility? How so?  
B. About the assistive tech ecosystem 
Q03. Could you describe, from your experience, the general economic eco-system of the assistive tech (AT) sector?  
Q04. How do developments in AI fit within the already established AT ecosystem?  
Q05. What type of business model exist in the traditional field? In the new field? Are they the same?  
C. Typology of AI-powered innovations fostering accessibility  
Q06. As you see them, what are the main AI-powered innovations in the field of accessibility? Are they focused on specific disabilities?  
Q07. Do you think that AI in these innovations is enabling (meaning that the solution would not exist without AI) or mostly enhancing (meaning that AI makes the technology better but is not necessary to its existence)?   
Q08. What is, in your opinion, the direction of innovation and transmission, between generalist and specialised solutions?  
D. About the relevance of AI-powered innovations for accessibility 
Q09. Do you think that AI, as it currently stands, is advanced enough to help with accessibility?  
• If yes: what can it do in your opinion? What does it allow doing that wasn't possible to do before?  
• If no: what's lacking? Will it ever be ready?  
Q10. To what extent are the current applications of AI for accessibility opportune?  
• Do they respond to a need?  
• How connected with existing structures and support systems are they?  
Q11. If you think about AI and accessibility, what do you think is missing? What would be useful to do with the technology? What isn't there? 
Q12. In your opinion, how many of the barriers to employment faced by people with disability can AI help tear down?  
Q13. Do you think AI can help overcome some of the attitudinal barriers slowing down progress on labour market inclusion for people with disability?  
Q14. How could the opportunity of AI-powered innovations be improved in the R&D phase?    
Q15. In your opinion, once innovations are developed, provided they are adapted to needs, what might block their commercialisation/adoption in practice?  
E. Use of data and ethical issues arising when using AI for accessibility  
Q16. What are the potential ethical issues related to using AI to foster labour market accessibility?  
Q17. Considering the diversity and intersectionality characteristic of disability communities, to what extent can AI help to foster the inclusion of people with disability in your opinion?  
F. Government policy and regulation 
Q18. Do you reckon that government policies and regulations have had any impact on the development of AI-powered solutions for accessibility? On their opportunity and relevance?  
Q19. Are there any government policies or regulations you would like to see? How could governments support AI for accessibility at various phases, from research to product development, through adoption by users? How could they ensure that innovations are relevant and fit with existing support structures?  
G. Closing questions  
Q20. If you had to summarise, what would you say were, in your opinion, the main challenges and opportunities when using AI in the field of (labour market) accessibility?  
Q21. Is there anything else you would like to share? 
 
Annex C. List of participants 
This is the list of participants who agreed to be named.  
 
Ahmed Dhali Omor, Project Officer and Facilitator of Person-centred Technology Member Forum at the 
European Association of Service providers for Persons with Disabilities 
Austin Victoria, Associate Professor of Social Justice and Innovation at University College London, Co-
Founder of the Global Disability Innovation Hub  	 	 
Banes David, Director of David Banes Access and Inclusion Services  
Belsky Shea, Chief Technology Officer at Mentra 	 
Cagnon Céline, Disability Coordinator in Exploration and Production at TotalEnergies 	 
Claypool Henry, Technology Policy Consultant for the American Association of People with Disabilities, former Director of the Office on Disability in the US Department of Health and Human Services, former Executive Vice President of the American Association of People with Disabilities, Affiliated Faculty at the Institute for Health & Aging at UCSF and principal of Claypool Consulting.  
Cunningham Nathan, Senior Technology Policy Advisor at the Office of Disability Employment Policy in the US Department of Labor 
Curtis Davidson Bill, Co-Director of the Partnership on Employment & Accessible Technology (PEAT) 
De Witte Luc, Professor, Research Group Technology for Healthcare at The Hague University of Applied 
Sciences, President of the Global Alliance of Assistive Technology Organisations (GAATO) 
Défossez Alexandre, Research Scientist at Meta AI Research 
Denoncin Sylvain, CEO of Okeenea 
Duchemin Thibault, CEO of Ava 
Encarnaçao Pedro, President-elect of AAATE - Association for the Advancement of Assistive Technology in Europe, Deputy Academic Director of the MSc in Management and Senior Affiliate Professor at Universidade Católica Portuguesa (UCP).  
Fabien Maël, CEO of Biped.ai 
Farahani Javid, CEO of Cogmap.ai 
Favreau Jean-Marie, Lecturer in computer science at the Université Clermont-Auvergne  
Feghali Jean-Marc, CEO of WeWalk 
Fitzpatrick Donal, Senior ICT Design Advisor with the Centre for Excellence in Universal Design at the National Disability Authority in Ireland 
Gilligan Patrick, Director of Product at Zanmo.ai 
Goldberg Larry, Accessible Media and Technology consultant, Former Head of Accessibility at Yahoo 
Goonewardhane Bhagya, business development manager at Envision 
Hammersley Haydn, Social Policy Officer at the European Disability Forum  
Hamot Christine, Manager of the "Mission Handicap" at TotalEnergies 
Hasegawa Johnson Mark, Professor of Electrical and Computer Engineering at the University of Illinois 
Hataway Haley, Head of Product at Mentra 
Hemphill Christine, CEO of Open Inclusion 
Hockner Klaus, CEO of the Austrian Association for Blind People 
Jeannel Olivier, CEO of RogerVoice 
Jiang Panpan, Technical program manager at Google  
Jones Melanie, Professor of Economics at Cardiff Business School, Cardiff University 
Jung Bong-Keun, Professor of Rehabilitation Engineering, Department of Mechanical Engineering, Seoul National University.  
Kanevsky Dimitri, Research Scientist at Google 
Keun Ji Hyeong, Deputy Director of the Division of Employment for the Disabled at the Korean Ministry of Employment and Labour  
Larrouy Muriel, Project Manager in charge of transportation accessibility at the Ministerial delegation to accessibility in the French Ministry of Ecological Transition and Territorial Cohesion 
Lee Jun-ho, Leader of the Operations management team in Co:Actus 
Mallick Kamran, CEO of Disability Rights UK 
Mazrui Susan, Director of Public Policy at AT&T 
McConnell Richard, CEO of Liopa 
McDonald Bob, Technical Program Manager at Google 
Moran Melissa, Product Manager for the Lookout product development team at Google 
Noori Kave, AI Policy Officer at the European Disability Forum 
Oikawa Masashi, Program Manager of the Basic Research Institute at IBM Japan 
Parsy Jonathan, Digital Workplace Architect at TotalEnergies 
Placencia Porrero Inmaculada, Senior expert in the European Commission (DG Employment) on 
Disability and inclusion specialised on accessibility. 
Qi Haoran, Senior Research Engineer at Google 
Quinlan Mark, Research Fellow at University College London Interaction Centre  
Reinhardt Conner, COO of Mentra 
Robinson John, CEO of OurAbility 
Robinson Jerry, User Experience Researcher at Google 
Rodgers Rylin, Disability Policy Advisor at Microsoft 
Ruh Debra, CEO of Ruh Global Impact and Co-Founder of Billion Strong  
Scott Parker Susan, CEO of Business Disability International 
Sharma Dorodi, Senior Advisor Advocacy & Engagement at the International Disability Alliance 
Siabi Nasser, CEO of Microlink PC 
Smolley Sara, Vice President of Strategy at VoiceItt 
Stassun Keivan, Professor of Computer Science in the Vanderbilt School of Engineering and Director of the Frist Center for Autism & Innovation 
Tanis Shea, Associate Research Professor at the Kansas University Center on Excellence in Developmental Disabilities 
Tordini Francesco, CTO of SolarEar 
Treviranus Jutta, Director of the Inclusive Design Research Centre (IDRC) and professor in the faculty of Design at OCAD University in Toronto. 
Trömel Stefan, Senior Disability Specialist at the International Labour Organisation 
Tschudi Yohann, CTO of Okeenea 
Wald Mike, Professorial Fellow-Education at the University of Southampton 
Wass Victoria, Emerita Professor at Cardiff Business School, Cardiff University 
Weinstein Howard, CEO of Solar Ear 
Welker Yonah, Founder of Yonah.ai, Explorer and Board member 
Zimmerman Jean-Louis, Administrator and Vice-President at OpenStreetMap  
Glossary 
Ableist/Ableism: relating to policies, institutions, customs, behaviours, etc. that reflect the prejudiced assumption that people without disability represent a "norm", thereby leading to discrimination against people with disability, participating in their unfair or harmful treatment.   
Accessibility: in this report, the term accessibility is used in its widest sense possible, to refer to situations in which "people are not excluded from using something on the basis of experiencing a disability" (Duggin, 2016[1]). It includes digital accessibility (which refers to a set of rules establishing whether, e.g. a website is accessible) and physical accessibility (e.g. rules established to guarantee access to buildings to all) but it is not limited to these. In that sense, the present report aligns with the argument in a recent report by the American Association of People with Disabilities and Centre for Democracy and Technology, according to which "work on technology and disability justice must often start with accessibility [in its restrictive sense] but cannot end there" (Claypool et al., 2021[2]). Accordingly, labour market accessibility is defined here as the fact that people with disability can interact in the labour market (get educated, look for jobs, access interviews, get hired, gain promotions, change jobs, etc.) with a similar amount of time, effort and ease as people without disability. 
Alt text: short for "alternative text". The text that describes an image (its appearance and/or its function), making it accessible to people who cannot see it through screen reading technology. 
Disability employment gap: the difference between the employment rates of people with disability and people without disability (usually measured in percentage points).  
Dysarthria: speech disorder that can create difficulties to talk and/or be understood.   
"First-intent" tools: first-intent tools in this report are those tools intentionally developed to support people with disabilities, by opposition to those who were developed for a mainstream audience but turned out to have a useful specific application for people with disability as well.  
Inclusive data: data that includes people with disability. The latter tend to be outliers in mainstream datasets or to be left out altogether. Inclusive datasets can either focus specifically on persons with disabilities, or oversample people with disability to make sure they are made visible rather than relegated to the data margins. 
Neurodiversity describes the natural way that people think, learn, perceive the world, interact, and process information differently. Neurodivergent people include autistic people; people with attention deficit hyperactivity disorder (ADHD), post-traumatic stress disorder (PTSD) and other mental health conditions; and people with learning disabilities. This group also includes people with other intellectual and developmental disabilities and a wide range of conditions that can shape thinking, learning, and perceiving the world. (Employer Assistance and Resource Network on Disability Inclusion - EARN).  
Reasonable accommodation / workplace accommodation: as defined by the United Nations Convention on the Rights of People with Disability (UN CRPD), "reasonable accommodation means necessary and appropriate modification and adjustments not imposing a disproportionate or undue burden, where needed in a particular case, to ensure to persons with disabilities the enjoyment or exercise on an equal basis with others of all human rights and fundamental freedoms" (United Nations, 2008[3]). 

Notes 
 
1 While different sources use different phrases, including "persons with disability", "persons with disabilities", and "people with disabilities", this report follows previous work on the subject at the OECD and uses the phrase "people with disability" - see e.g. (OECD, 2022[4]). 
2 Following OECD (2022[4]), this report purposefully uses pre-Covid data, to avoid reporting results that might be driven by the pandemic and not reflecting normal times.  
3 For stylistic reasons, the report uses three phrases alternatively to describe the objective of the research. Namely, it is concerned with AI that (from most general to most specific): "supports people with disability in the labour market", "fosters employment of people with disability", or "reduces the disability employment gap". 
4 This longer phrase ("fostering employment of people with disability") is preferred to the shorter "fostering disability employment", to avoid any potential confusion with discussions of sheltered employment, and public policies designed to create specific "disability employment" - and which have since largely been decried as inefficient and offensive. 
5 However, this definition is included in the OECD AI principles (OECD, 2019[142]). It is accepted by 46 countries, with the Principles forming the basis for the G20 AI principles. The OECD's definition is also envisioned as the basis for the definition to be used in the EU AI Act.  
6 These solutions arguably enhance the employability prospects of future adults down the line. While they are not included in the scope of the present study, future research looking at ways in which the beneficial use of AI for children with disability could be maximised would be welcome.  
7 Since January 2022, six candidate countries have entered into accession discussions with the OECD to join the organisation: Argentina, Brazil, Bulgaria, Croatia, Peru and Romania.  
8 The topic guide used for interviews with accessibility specialists is included in Annex B, as an example.  
9 Considering the fast-paced nature of AI innovations, this list of examples cannot claim to be exhaustive but represents the state of the field, to the best of the author's knowledge, as of August 2023. In addition, although specific efforts were made to identify examples in countries where English was less likely to be used to describe AI-powered solutions (such as Korea and Japan), the list of examples is still likely to suffer from an Anglo-centric bias and should not be taken as representative of the field.  
 
10 Some of these solutions are the subject of controversy among experts in the field. For a thorough review of the benefits and risks of AI-powered innovations in the realm of mental health, see Bossewitch et al (2022[138]).  
11 The Partnership on Employment & Accessible Technology (PEAT) created a toolkit to help employers understand the value of using accessible extended reality (XR) technologies in hybrid work environments and, in particular: how to procure accessible XR technologies for the workplace and how to use these technologies in ways that include all employees equally (https://www.peatworks.org/inclusive-xr-toolkit/). 
12 Alternative text descriptions for pictures allow blind and low-vision individuals to access pictures through an audio description processed by a screen reader. These descriptions were traditionally entered manually by website developers or documents authors. The development of image recognition algorithms allows for the automation of that process by having algorithms automatically produce an alternative text description of any picture. According to Microsoft's Rylin Rodgers, progress in the image recognition field also bodes well when it comes to the quality of alt text: "We are going to have a transformation in the quality of alt-text because of AI. While too many people don't enter alt text, it will just happen automatically. It will transform the entire business ecosystem and empower people with disability" (Rodgers, 2023[9]). 
13 Some algorithms check more broadly whether documents and websites respect accessibility standards (e.g. whether alt text is included or whether colour contrasts are perceptible for people with visual impairments) and automatically suggest fixes. This type of solutions, sometimes referred to as "accessibility overlays", has drawn criticism from actors in the accessibility field, especially in cases where algorithms verifying that websites do comply with legal requirements regarding digital accessibility are used instead of rather than as a complement to human oversight, while they are prone to errors. Interviewees point out that these overlays can in fact lead to lower effective accessibility in some cases. Others, like accessibility specialist David Banes, argue that while accessibility overlays do not yield perfect results, they "might help improve website accessibility on a larger scale than the handmade approach of the last 30 years" (Banes, 2023[29]). For Klaus Höckner, from the Austrian Association for the Blind and Visually Impaired, accessibility overlays provide a potential solution in a context where he considers the expectation to "make all websites worldwide accessible by manually reprogramming them" to be "delusional" (Höckner, 
2023[90]) 
14 In that sense, these alternative job-matching tools operationalise the notion of "fairness through unawareness" developed by Trewin: "The simplest approach to fairness is 'fairness through unawareness', where no information about protected attributes (e.g. gender, age, disability) [or, indeed, information correlated to these protected attributes] is gathered and used in the decision-making" (Trewin, 2018[66]). 
15 "Automaticity" in this context refers to the ability to act "without really thinking", measured by your average time response between a prompt and an action (in that case, in a simple online game) (Farahani, 2022[21]). 
16 In that sense, the solution is not limited to people who identify as disabled. As explained by Microlink founder Nasser Siabi, an employee might "have a problem with their eyesight but not call themselves disabled". There are "many employees struggling with their health condition who do not consider themselves disabled and would not want to declare themselves disabled" and thus would not ask for reasonable accommodations. Microlink's algorithm is designed to "help identify what barriers they're facing and what solutions can be applied" (Siabi, 2022[89]). 
 
17 This is, for instance, the approach behind the AI for mobility (AIM) service added onto the WeWalk connected white cane for blind and low-vision individuals. As explained by WeWalk lead R&D scientist Jean-Marc Feghali, "Instead of using AI to deliver a service to the visually impaired person that aims to change the way they behave", WeWalk's approach has been to "use the AI as a diagnostics tool, as a system to aid the decision-makers in our community who already help visually impaired people make informed decisions. Orientation and mobility specialists are the pivotal points in society for a visually impaired person (...) they teach you how to adapt, how to use a cane, how to use sound shadows, and how to cope with the world. That is much more important than any technology. It is the most important thing to finding employment. (...) But O&M specialists never end up getting full insight into how someone is behaving over the long term" while in many cases the condition is degenerative. Therefore, WeWalk decided to use AI to "help these pivotal decision-makers" through using their white canes to collect data on, e.g. preferred walking speed, cane swipe width, cane angle to the ground, collisions, using AI to process this data, relating it to other data such as how the person is feeling or the environment they are travelling in, and "bringing out meaningful patterns for the O&M specialists" (Feghali, 2022[37]). 
18 Some scholars have indeed observed that "the digital transformation provides a context favourable to autistic workers", notably because their "performative abilities, cognitive differences and creativity" are increasingly valued in the labour market (Walkowiak, 2021[129]). Bong-Keun Jung from Seoul National University described a scheme co-ordinated by the Korean Employment Agency for the Disabled (KEAD) whereby data labeling companies specialised in producing the datasets used in deep learning can advertise jobs directly through KEAD to hire and train neurodivergent individuals for data labeling jobs (Jung, 2023[70]). This type of "neurodiversity management", targeting neurodivergent individuals for specific jobs, is in turn seen as contributing "to the digital transformation by closing the digital skills shortage, shaping algorithms of artificial intelligence and providing a competitive advantage for innovation" (Walkowiak, 2021[129]). However, this approach is questioned by some in the field, as this kind of targeting for a restricted list of jobs "flies in the face of many advocates who will say, I don't want neurodiversity to be my classification" (Tanis, 2023[28]). Instead, the approach of alternative job-matching tools such as that developed by Mentra, a start-up mentioned in Box 1.2 that focuses on neurodiversity, aims to get employers to "consider company-wide neuro-inclusion for all of their roles" rather than "stopping short at a handful of positions in a dedicated neurodiversity hiring program" (Reinhardt, 2022[128]). 
19 This is done, for instance, by researchers at the French National Geographic Institute (IGN) using highdefinition satellite photos (Larrouy, 2022[27]).  
20 For instance, live captioning algorithms facilitate general communication for deaf people, including but not only in labour market contexts. 
21 For instance, the AI add-on built into the WeWalk white cane, which helps orientation and mobility specialists to better support blind individuals in their everyday mobility (see endnote 17), might facilitate commuting down the line. However, as this is considered a second-order effect, the innovation is categorised under "general mobility" rather than under "commuting". Solutions that have "second-order effects" include tools designed to prevent the onset of disability as well as more "futuristic" examples with longer time horizons until full adoption by users. The latter include brain-computer interfaces projects (e.g. "The link" by Neuralink, the "Brain Magic project" by Meta) and AI-powered neuro-prostheses (e.g. "Brain.io" by Synchron) that aim to restore motor and/or communication abilities (including with digital devices) for people with severe paralysis, such as those in lockdown syndrome. The brain-spine interface developed by researchers at the University of Lausanne which allowed a paralysed man to walk naturally again after a spinal cord injury in May 2023 (Lorach et al., 2023[131]) is also part of that category.  
 
22 This includes academic research labs, partnerships between academic research labs and SMEs, or academic spin-offs in the private sector. The high prevalence of academia among actors identified is likely to reflect in part the fact that research in this area is still in its infancy. According to Jean-Marie Favreau, from Université Clermont Auvergne, "We're still in the early stages", with fundamental research still playing a very important role. "On the application science side, we are starting to see progress (...) but these are based on ideas that are still being explored upstream" (Favreau, 2022[26]). 
23 "Small firms" are distinguished from start-ups because they already have an established product and sustainable business model. In other words, they have passed the start-up phase. One could speculate that this higher concentration of small firms observed here may be intrinsic to the "AI for good" sector, in which value-driven individuals directly or indirectly affected by the issues at play might be more prominent than in other sectors. For instance, 40% of the "inventors" interviewed in this project disclosed a personal link to disability (i.e., they have disabilities themselves or regularly care for someone who does). Many others mentioned a desire to "use AI for good" more generally as their motivation.  
24 For instance, the small firms Zammo, OurAbility and WeWalk listed in Annex A received financial support through Microsoft's AI for Accessibility programme. Others were supported, e.g. by Verizon's Forward for Good Accelerator or the Google Play Accessibility Award. Smaller firms also often rely on big tech to access AI services. For instance, Liopa's co-founder Richard McConnell explained that as a start-up with limited means to develop their lip-reading algorithm, Liopa uses "as many start-up programs as we can. Amazon Web Services, Google, Microsoft: they all give you a certain amount of free computing power, as a startup. It's not a huge amount, but it gets you a certain amount of training" (McConnell, 2022[76]). Big tech companies also invest in smaller start-ups - for instance, Voiceitt, the company that has developed automatic speech recognition algorithms for people with a dysarthric speech counts Amazon Alexa Fund, M12 (Microsoft's venture capital fund), and Cisco Investments among its investors (Smolley, 2022[32]). 
25 In terms of geographical provenance, a large majority (61%) of the actors behind the solutions listed are based in the United States, while 8% of cases are based in the United Kingdom, with France and Israel respectively hosting 7 and 5% of solutions. Note that these results are likely to reflect in part the fact that the research behind this project was conducted primarily in English. 
26 However, 40% of the individuals in the "inventors" pool of interviewees disclosed a personal link to disability (i.e., they have disabilities themselves or regularly care for someone who does), while many others mentioned a desire to "use AI for good" more generally as their motivation behind using AI for people with disability. 
27 Paragraphs 18 to 20 refer to for-profit solutions. Yet it is important to note that in some cases solutions are not for profit. In addition to the numerous university-led projects which have not yet led to commercial endeavours, this is also the case of some projects led by firms. For instance, although the start-up Zammo itself is for profit, their project aiming to make job boards accessible to blind and neurodiverse individuals was designed primarily as an open-source project: "We never sought out to necessarily monetise it", explain Patrick Gilligan, who leads that project. "This is more of a passion project. It still helps our product because we want our interfaces to be accessible across the board (...) But the goal was always to provide it open source and see what we could do in the space that's valuable and that others can build upon" (Gilligan, 2022[40]).  
28 As explained by Howard Weinstein, the founder of Solar Ear, there are three types of barriers to selling a hearing aid in a developing country: administrative constraints linked to border crossing, affordability to end users, and a lack of local audiologists to conduct tests. Using AI helps Solar Ear to solve all three of these problems at the same time by building two smartphone-based apps, a hearing loss diagnosis one and a hearing aid one. "The hearing test might show that you need amplification in two different frequencies and three different decibels. The AI will then modify your cell phone to amplify the sounds that you're missing that you can't hear", without the need for any additional device (Weinstein, 2022[79]). The appbased test can be conducted by any secondary healthcare worker, while the hearing aid is dematerialised and cheaper than device-based ones. 
29 For instance, according to Francesco Tordini, who oversees the development of the Solar Ear AIpowered hearing aid, "The amount of data and the computing power that we need are smaller than what you typically need for image processing and other applications driving the wearables and assistive technologies market. I'm not concerned about computational power or data bottlenecks, we are not aiming to do any natural language recognition. The technical solutions we need are already there" (Tordini, 2022[136]). 
30 An interesting example in that regard is that of Aira.io, a live visual interpretation service connecting people who are blind or have low vision with seeing humans. Aira started as an AI-powered solution and started relying on humans instead of technology after assessing that the latter was not nuanced and precise enough. As stated on their website, "Initially, the AI in our name stood for Artificial Intelligence and the RA stood for Remote Assistance. Now with millions of calls to date, the importance of a human in the loop, providing access to information that is sometimes rather nuanced, is abundantly clear.  We have reinterpreted the meaning of our name, AI now stands for Access to Information" (aira.io, 2023[141]). 
31 As explained by Kave Noori from the European Disability Forum, a second issue under the "risks to privacy" category is related to "consideration for secondary users", for example, hearing users whose voice is analysed by the speech-to-text application used by a hard of hearing person whom they are conversing with. The secondary user's personal data is also processed, which might pose legal issues. "Unfortunately, if [secondary users] are not assured that the sensitive information they share will be treated securely, we may find ourselves in situations where the use of technology that improves accessibility is viewed with contempt or resistance" (Noori, 2023[41]). 
32 Several of the examples listed in Annex A are designed to improve mental health. For instance, Woebot is an application combining insights from traditional therapeutic approaches such as cognitive behavioural therapy with natural language processing to create a chatbot dedicated to relieving depression. Wysa AI is another example, that combines a conversational AI and access to human therapists if required. These tools have been described as a solution faced with the shortage of mental health care in some contexts. There have been cases, however, of mental health chatbots malfunctioning - as was the case of the Tessa chatbot used by the National Eating Disorder Association in the United States, before it offered harmful advice and was taken down (Barr, 2023[132]). 
33 For instance, Bossewitch et al (2022[138]) worry that the development of AI-powered mental health applications ends up "undercutting face-to-face encounters of care and support (...) particularly where governments are pursuing digital options as cheap alternatives to well-resourced forms of support".  
34 "Too often", argues accessibility specialist Larry Goldberg, "the technology world is enamoured with the possibilities long before the quality is ever considered" (Goldberg, 2023[88]), while cheap "lower-quality AI" supplanting human-powered high-quality solutions should not be rolled out. On the other side of this argument, David Banes explains that waiting for AI to be 100% accurate before using it for accessibility purposes would be counterproductive since people with disability need to engage with the technology to reveal its flaws and participate in correcting them. For instance, inaccuracies in speech recognition for 

 USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 
people with specific speech patterns can only be corrected if these individuals interact with the algorithm and help improve it by contributing their own speech data to the system. "What we now get through these automated AI-driven captions would have been hailed as unbelievably amazing progress five years ago. People's expectations increase year on year whilst the technology shifts and changes" (Banes, 2023[29]). 
35 The EU GDPR creates data rights for persons located in the EU and obligations for entities processing personal data that aim to protect individuals' personal data and increase transparency in how data are processed. These rights and obligations have "specific implications for AI". In particular, the rights to transparent information and communication, as well as the rights of access, rectification, erasure, and restriction of processing are likely to affect the way personal data can be used in AI solutions (Salvi del Pero and Verhagen, 2023[65]). 
36 For more on this issue, see the OECD's blueprint for building national compute capacity for AI (OECD, 2023[145]). 
37 In other cases, innovators decide to provide their solution for free: this is the story behind Open Sesame, the touch-free computer interface originally developed by the start-up Sesame Enable (listed in Annex A), which struggled to come up with a sustainable business model - and had to close down - but kept its solution available for free.  
38 On that point, Feghali gives the example of solutions designed to provide indoor navigation for blind people inside hospitals. "But when you interview visually impaired people, most want to go to the reception to ask for help. They don't want the hassle of having to try to navigate a whole hospital on their own. (...) We can't help visually impaired people access employment by just building a new radical technology that will suddenly change the way they behave. The point is, how do we help them access the services which we already have in place, like staff assistance, help points, for instance" (Feghali, 2022[37]).  
39 This issue predates the development of AI-powered mainstream solutions that have the potential of helping people with disabilities; for instance, Kim (2023[137]) showed how while the iPad could have been revolutionary for non-verbal speakers, the restrictive reimbursement rules around augmentative and alternative communication (AAC) devices have prevented that from happening.  
40 Ensuring the conditions of truly informed consent for people with disability might for instance imply making sure that notifications are provided in an accessible format and use plain language to be inclusive of people with cognitive disability.  
41 Note that legislation rooted in individual rights have been criticised as challenging and potentially insufficient to avoid the risks of AI for people with disability since they rely on "individuals having the knowledge and means to challenge discriminatory tools and practices" (IDRC, 2021[139]) 
42 This section reviews the most prominent emerging AI regulations. For a more thorough analysis of all emerging regulations in OECD countries, readers can refer to the OECD.AI database of national AI policies (OECD, 2023[143]). 
43 Although note that this proposal is still being discussed at the time of writing (July 2023), and most of the substance is still missing (Salvi del Pero and Verhagen, 2023[65]). 
44 The International Organization for Standardisation has launched a standardisation programme on artificial intelligence (ISO, 2017[133]), which already led to the publication of 18 ISO standards on AI. Of 
USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 
these 18 standards, 5 are potentially relevant to disability. However, they remain generalist and are not dedicated to the definition of disability-inclusive and accessible AI: ISO/IEC 23894:2023 on "Artificial intelligence - Guidance on risk management", ISO/IEC TR 24027:2021 on "Artificial intelligence (AI) - Bias in AI systems and AI aided decision making", ISO/IEC TR 24028:2020 on "Overview of trustworthiness in artificial intelligence", ISO/IEC TR 24368:2022 on "Overview of ethical and societal concerns", and ISO/IEC 25059:2023 on "Quality model for AI systems". 
45 For instance, IEEE Std 7010 (tm) -2020, on "IEEE Recommended Practice for Assessing the Impact of Autonomous and Intelligent Systems on Human Well-Being" does contain examples relating to people with disabilities (Musikanski, Haven and Gunsch, 2019[134]).  
46 For a detailed repository of existing risk mitigation initiatives and tools, see (OECD, 2023[144]).  
47 Starting from the premise that "companies have a responsibility to monitor machine learning processes for bias and mitigate any bias detected, ensure business product integrity, preserve customer loyalty, and protect brand image", SIFT "enables an industrial machine learning team to define, document, and maintain a project's bias history via mechanised and human components [and] lowers the cost for dealing with fairness through reuse of techniques and lessons learned from handling past fairness concerns" (Dodwell et al., 2020[110]). 
48 The September 2022 proposal from the European Commission for a targeted harmonisation of national liability rules for AI is a first step towards a definition of harm encompassing of discrimination. This proposal contains a review of the existing Directive on Product Liability, and a proposal for a new AI Liability Directive (European Commission, 2022[126]). The latter notably expands the definition of "harm" to include infringements on fundamental rights such as discrimination and breaches of privacy (Salvi del Pero and Verhagen, 2023[65]).  
49 Note that this corresponds to the interpretation given by the EEOC in its guidance on the ways in which the use of AI to assess job applicants and employees could violate the Americans with Disabilities Act (ADA):  the guidance explains that the responsibility to ensure compliance with the ADA lies with the user/deployer of the tool (i.e., the employer) even when that tool is developed by an external provider (EEOC, 2022[92]). 
50 This policy recommendation corresponds to Principle 2.1 in the OECD AI Principles, which calls on governments to "consider long-term public investment, and encourage private investment, in research and development, including interdisciplinary efforts, to spur innovation in trustworthy AI that focus on challenging technical issues and on AI-related social, legal and ethical implications and policy issues" (OECD, 2019[142]). 
51 Such programmes already exist (see for instance Cornell University's Ignite: lab to market gap funding initiative) - yet they tend to not be focused on solutions reducing the disability employment gap (Cornell University, 2023[135]). 
52 In December 2022, the National Science Foundation in the United States added a new track to its "Convergence Accelerator", designed to support the transition of multi-disciplinary research into practice. Track H, "Enhancing opportunities for people with disability" finances the development of "use-inspired solutions to enhance quality of life and employment access and opportunities for people with disability" (NSF News, 2022[140]). A budget of $11.8 million was divided into 16 projects, many of which use AI and are included in Annex A.  
 USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 
53 For instance, the Global Disability Innovation Hub in the United Kingdom, hosted by University College London, has recently put in a bid with the UK government to fund 15 new PhD scholarships on accessibilityenhancing solutions, and committed to allocating half of these to students with disabilities themselves - helping to finance innovation and increase disability representation in the field at the same time. While this program is not specifically earmarked for AI, other programs dedicated to AI for accessibility could be modelled on this one. 
54 In Australia, the NDIS can be used to fund "daily personal activities" and "basic assistive technology (...) including many aids to daily living (...) and accessible consumer technologies (...) where the person with a disability believes these to be the most efficient way of addressing their needs."  Items for less than $1,500 can be bought "without any professional assessment or any specialised assistance" and do not require quotations before purchase" (Banes, 2022[118]). 
55 For instance, Atvisor.ai is an algorithm recommending solutions to individuals with disabilities based on their self-declared ability profiles and on crowdsourced user feedback information. 
56 Note that this would be helpful for the development of accessible technology in general, including AIpowered examples. 
57 This measure would support the development of accessible technology in general, including AI-powered examples. 
58 This is another example of a measure that would favour the development of accessible technology in general (not specifically AI-powered ones, although including it).  
59 This policy recommendation corresponds to Principle 2.1 in the OECD AI Principles, which calls on governments to "consider public investment and encourage private investment in open datasets that are representative and respect privacy and data protection to support an environment for AI research and development that is free of inappropriate bias and to improve interoperability and use of standards", and Principle 2.2 which encourages governments to "consider promoting mechanisms, such as data trusts, to support the safe, fair, legal and ethical sharing of data" (OECD, 2019[142]). 
60 See for instance in Chapter 1 the discussion of the solution created by the start-up Andyamo or developed by OpenStreetMap.  
61 Beyond mandating data collection, governments can facilitate the production of accessibility-relevant data through standardisation efforts. For instance, following the enactment of the LOM in 2019, the French administration started working on the "standardisation of description of accessible mobility features", meaning the definition of standard glossaries to describe elevators, curb cuts, ramps, etc. in datasets, and the definition of "exchange formats (...) to ensure interoperability between different databases", i.e., the definition of translation models between co-existing glossaries (Larrouy, 2022[27]). The logic behind this was that once local authorities and transportation operators had been mandated to create accessibility databases, they needed methodological support to do this, so that "every local authority, irrespective of size, could do it", capitalising on each other rather than "reinventing the wheel every time" (Larrouy, 2022[27]). Such efforts typically help ensuring interoperability but also scaling efforts to generate accessibility data, for instance by defining a European-level standardised format to describe accessible mobility features (Zimmerman, 2022[130]). 
 
USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 
62 According to Favreau, these actors are now competing to develop a pedestrian guiding algorithm that accounts for accessibility needs, "but what everybody is missing is data. So, everybody uses what's available on OpenStreetMap with makeshifts internal solutions" (Favreau, 2022[26]). These solutions are not sustainable because, Favreau argues, creating an infrastructure to collect and maintain data is expensive and small actors often do not have the capacity to do so. 
63 TeachAccess was founded after accessibility specialists in tech companies realised that they were spending a lot of time repeatedly explaining the same notions of accessibility to new developers who had never heard about them. They realised that it would be more efficient down the line "if our new employees actually came to us with some of the basic knowledge about accessible design and development". This would allow them to "hit the ground running" and "start working on the higher order issues of innovation around the field of accessible technology" (Miller-Merrell, Goldberg and Sonka, 2018[124]). While this has been described as a "welcome initiative", other voices have called on academia to "address the accessibility knowledge gap" more systematically and on a larger scale (Marzin, 2018[42]). 
64 For instance, Sylvain Denoncin, CEO of Okeenea, explains that while focusing on able-bodied people to build a navigation solution will allow "providing a service to 80% of the population, but will make it very costly to get to the remaining 20%", starting from "the most complex situation" (in this case, a navigation solution for blind individuals in the metro, where there might not be reception) and thinking at the same time of mainstream applications, allows building an architecture that can "address all users from the start". Focusing on specific users only, however, is also short-sighted according to Denoncin: "We have some competitors that started focused on blind people and who are now trying to open their solution for mainstream use, but it's quite complicated" (Denoncin, 2022[127]). 
 












2  USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 

USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET  3 

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 

2  USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 

10  USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 

USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET  11 

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

10  USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

70  USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 

USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET  71 

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

70  USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

10  USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET 

USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET  11 

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

USING AI TO SUPPORT PEOPLE WITH DISABILITY IN THE LABOUR MARKET  11 

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

100 
 

 101 
 

OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

 
OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

100 
 

 
OECD ARTIFICIAL INTELLIGENCE PAPERS (c) OECD 2023 
  

