Revolutionizing Assistance: 
How States Can Improve Generative AI's Role in 
Disability Empowerment 
June 2024


Exploring a New Path for Digital Accessibility 
Current research suggests that people with at least one disability made up 13 percent of the total American population in 2023. Between 2022 and 2023, the number of disabled people in the American workforce increased from 21.3 to 22.5 percent. 

  
With both trends expected to continue rising, generative artificial intelligence (GenAI) has emerged as a tool that can greatly improve accessibility in the professional and personal lives of those with disabilities. This is particularly relevant for state chief information officers (CIOs) as the United States Department of Justice recently released a final rule detailing the guidelines state and local governments must follow to ensure accessible webpages and mobile apps. 
Deciding which GenAI products best improve accessibility for disabled employees and citizens at all levels of interaction begins with analyzing current use cases. Researchers at the University of Washington executed a three-month study exploring the use of generative AI among people with disabilities. While some findings did reiterate GenAI's usefulness, others characterized where it is lacking. One study participant with a cognitive disability used an AI tool to summarize a paper discussing the perspectives of people with chronic illnesses. While the tool was sometimes accurate, it also gave incorrect answers - including changing the paper's argument to favor discussion with caregivers instead of those with ailments. 
Other scenarios from the University of Washington study provided similarly mixed results. A participant with autism used GenAI to help write short messages, finding that although it helped relieve a cognitive burden, message recipients felt they were robotic. Three other participants with undisclosed disabilities used GenAI to improve accessibility for data visualizations commonly seen in academic papers and presentations. While the GenAI program provided guidelines on making these visualizations more accessible, it could not incorporate them into content creation. 
Another real-time example of a GenAI challenge faced by people with disabilities comes from a hard-of-hearing virtual conference attendee who heavily relied on captioning. The captioning for the live feed was severely delayed, and the captioning provided by the conference was not accurate. To overcome this, the attendee used captions provided by their internet browser in conjunction with a mobile app on their phone that transcribed the audio. Conclusively, the attendee relied on four different sets of captions while looking at the presentation and speaker. 
The above anecdotes highlight the potential of GenAI to revolutionize accessibility for people with disabilities. Yet, they also underscore its challenges - including exclusionary tendencies, inaccuracies and usability issues that can further complicate matters for those seeking its advantages. As state governments continue to leverage GenAI for people with disabilities both in the workforce and the public, here are four things state governments should consider when working with AI vendors throughout the procurement and implementation process. 
1. Engage All Stakeholders when Evaluating AI Tools 
Any GenAI tool used to aid individuals with disabilities should be tested and evaluated by the targeted stakeholder groups. As previously discussed in NASCIO's "Creating A Citizen-Centric Digital Experience: How Far Have We Come," delivering a citizen-centric digital experience depends on effectively engaging all stakeholders. Citizens with disabilities are a relevant stakeholder group, as some disabilities increase reliance on digital citizen services. Active participation from disabled people in GenAI tool evaluation can provide insights that support a more inclusive approach to human-centered design initiatives. When GenAI is used in the workplace to increase accessibility it can benefit all employees, not just those with disabilities, by automating repetitive tasks and streamlining document production for interagency work. 
When speaking with current and prospective vendors, ensure the product has been evaluated by people with disabilities. States should also leverage their workforce by intentionally engaging employees with seen and unseen disabilities. If employees with such disabilities are comfortable doing so, invite them to share their experiences on the job, to identify how GenAI can improve their work and to collaborate with the state to test and procure new AI products. 
2. Cultivate Inclusive Datasets to Combat AI Bias 
Like any other tool, GenAI will only be as effective as the data used to build the model. 
Some AI models are built on datasets that inaccurately reflect or completely exclude certain demographics of a population, including disabled people. GenAI tools built on non-inclusive datasets may favor non-disabled individuals, leading to biased outcomes. Inaccurate data labeling or excluding certain demographics from a dataset can perpetuate this bias. Combining all disabilities under one label in a dataset removes the model's ability to cater to individual needs. Further, datasets lacking disability representation result in models treating all users as non-disabled. 
To prevent bias, it is crucial to include diverse demographic data, including various disabilities, in datasets used for training GenAI models. Consider workforce expansion, for instance. If GenAI is used during the hiring process for resume screening, but the model was trained on a dataset that does not account for the underemployment of people with disabilities, it can perpetuate hiring disparities. Therefore, when procuring GenAI models for widespread adoption in standard tasks-such as workforce expansion-ensure that they were built using datasets that truly reflect the disabled population. 
3. Embrace Transparency in Developing AI Tools 
As many GenAI developers expand their technology, some provide information about their data sources, modeling and decision-making processes to increase trust among targeted stakeholder groups. Building confidence in GenAI is hampered by a lack of transparency in development. Disclosing this information allows end-users to hold companies accountable for AI shortcomings, fosters trust and improves relationships and collaborative efforts between stakeholder groups. Some companies use transparency notes and other accessible documents that detail GenAI models' intended use, capabilities and limitations. 
Ask current and prospective vendors about how, when and if they provide information about the development pipeline of their tools. State technology leaders should also stay informed regarding GenAI software updates for the platforms currently in use, report "bugs," and provide improvement recommendations to GenAI developers based on collaborative efforts with their employees. 
4. Confront and Navigate AI Limitations 
In addition to GenAI bias, GenAI also has significant limitations when considering people with disabilities. Standard web-based AI tools can lack customizability - a crucial element in tailoring AI use for any given disability. As highlighted in the University of Washington study, an image-generating AI tool was leveraged to assist a user with aphantasia (difficulty visualizing) in analyzing images from books. While this approach had some success, the AI also produced fragmented, unrealistic images with ableist bias when asked to depict people with disabilities enjoying a party. 
State governments should become familiar with these limitations to maximize the use of GenAI and choose the best products to increase accessibility. Generative AI excels at verification tasks such as reviewing, refining and editing user-written content. However, at this point, it's less reliable in tasks like summarizing lengthy pieces or extracting key points from diverse sources. Instead, it's more like a first-draft tool, with human oversight being crucial due to its confidence in often incorrect outputs. Strategies like comparing AI-generated summaries against manually summarized versions and applying detailed constraints during content creation can help mitigate these limitations. 

Charting New Territory in Accessibility 
More Things to Consider 
• Ensure any AI tools used are accessible. 
• Avoid AI tools that force its use - i.e., AI-based website overlays. Alternatively, provide users the option of using AI if it benefits them. 
• Develop AI policies that include inclusive LLMs/datasets, transparent functionality, stakeholder engagement, user choice/control, and use policy (when AI is allowed to make decisions and when it is not.) 
• When considering inclusive datasets, avoid "clean" datasets that highlight the mean at the expense of the outliers. The diverse demographic data needed, such as people with disabilities, are the outliers.The power of GenAI has yet to be fully realized, but people with disabilities are harnessing it for better, more accessible lives. Current research analyzing use cases of available GenAI tools increasing accessibility is promising. Recent speech-to-text tool research indicated that personalized GenAI speech models reduced word errors in atypical speech patterns for disabled people by approximately 26 percent, sometimes outperforming human transcribers. People with dyslexia, for example, benefit from GenAI platforms that declutter complex websites and read aloud the necessary text. Additionally, newly developed apps identify environmental sounds by displaying the name of the sound source for hard-of-hearing users using both pretrained sounds and sound inputs from the user. However, these products are just the beginning of the AI accessibility revolution. 
Future AI capabilities include models that mimic human intelligence and correct themselves based on user experiences and inputs. User personalization in AI is the missing piece for people with disabilities using generative AI. Early indicators suggest that human intelligence-mimicking AI tools can further benefit people with disabilities by expanding information access. For instance, it could help website creators develop interfaces that automatically adjust their layout based on user needs and simulate website interactions tailored to specific disabilities. Additionally, this concept has the potential to improve assistive technology by enabling more complex personalization and real-time enhancements. 
Early research suggests that human intelligence mimicking AI can address the current pitfalls of GenAI accessibility. Nevertheless, the same considerations discussed here will remain crucial in revolutionizing disability aid as this technology develops faster than rules and regulations. State technology leaders utilizing GenAI tools to aid people with disabilities-both within and outside the state workforce-must understand where GenAI thrives and where further development is needed. Key steps include involving people with disabilities in testing and evaluation processes, ensuring inclusivity in data to avoid promoting ableist bias, increasing transparency in the development pipeline and acknowledging the general limitations of AI. By taking these steps, state governments can significantly empower people with disabilities through generative AI. 

Sources 
Persons with a Disability: Labor Force Characteristics Summary 
Justice Department to Publish Final Rule to Strengthen Web and Mobile App Access for People with Disabilities Generative AI and the Public Sector 
Can AI be a force for inclusion? 
AI Accessibility: What Are AI Assistive Technology Examples? 
How Artificial General Intelligence Could Redefine Accessibility 
Can AI help boost accessibility? These researchers tested it for themselves 

AI for Accessibility: Opportunities and Challenges 
#Ableism 
Author & NASCIO Contact 
Kalea Young-Gibson, Policy Analyst, NASCIO kyoung-gibson@NASCIO.org 
Contributors and Reviewers 
Henry Quintal 
Digital Accessibility Coordinator 
State of Maine 
Jay Wyant 
Chief Information Accessibility Office State of Minnesota 

About NASCIO 
Founded in 1969, the National Association of State Chief Information Officers (NASCIO) represents state chief information officers (CIOs) and information technology (IT) executives and managers from the states, territories and District of Columbia. NASCIO's mission is to foster government excellence through quality business practices, information management and technology policy. NASCIO provides state CIOs and state members with products and services designed to support the challenging role of the state CIO, stimulate the exchange of information and promote the adoption of IT best practices and innovations. From national conferences to peer networking, research and publications, briefings and government affairs, NASCIO is the premier network and resource for state CIOs. For more information, visit www. NASCIO.org.
